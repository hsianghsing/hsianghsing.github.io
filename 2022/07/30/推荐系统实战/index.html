<!DOCTYPE html>
<html>
<head>
  <meta charset="utf-8">
  

  
  <title>推荐系统实战 | Hexo</title>
  <meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1">
  <meta name="description" content="推荐系统推荐系统开发实战常用数据集MovieLens数据集MovieLens数据集是一个关于电影评分的数据集。 以m1-1m.zip 为例，文件解压之后有四个文件夹：README ，ratings.dat， movies.dat，users.dat。  README 数据集的整体介绍。  ratings.dat 123456781::1193::5::9783007601::661::3::978">
<meta property="og:type" content="article">
<meta property="og:title" content="推荐系统实战">
<meta property="og:url" content="http://example.com/2022/07/30/%E6%8E%A8%E8%8D%90%E7%B3%BB%E7%BB%9F%E5%AE%9E%E6%88%98/index.html">
<meta property="og:site_name" content="Hexo">
<meta property="og:description" content="推荐系统推荐系统开发实战常用数据集MovieLens数据集MovieLens数据集是一个关于电影评分的数据集。 以m1-1m.zip 为例，文件解压之后有四个文件夹：README ，ratings.dat， movies.dat，users.dat。  README 数据集的整体介绍。  ratings.dat 123456781::1193::5::9783007601::661::3::978">
<meta property="og:locale" content="en_US">
<meta property="og:image" content="http://example.com/2022/07/30/%E6%8E%A8%E8%8D%90%E7%B3%BB%E7%BB%9F%E5%AE%9E%E6%88%98/image-20210705153804730.png">
<meta property="og:image" content="http://example.com/2022/07/30/%E6%8E%A8%E8%8D%90%E7%B3%BB%E7%BB%9F%E5%AE%9E%E6%88%98/image-20210705165736880.png">
<meta property="og:image" content="http://example.com/2022/07/30/%E6%8E%A8%E8%8D%90%E7%B3%BB%E7%BB%9F%E5%AE%9E%E6%88%98/image-20210705172934363.png">
<meta property="og:image" content="http://example.com/2022/07/30/%E6%8E%A8%E8%8D%90%E7%B3%BB%E7%BB%9F%E5%AE%9E%E6%88%98/image-20210705184536515.png">
<meta property="og:image" content="http://example.com/2022/07/30/%E6%8E%A8%E8%8D%90%E7%B3%BB%E7%BB%9F%E5%AE%9E%E6%88%98/image-20210705192448439.png">
<meta property="og:image" content="http://example.com/2022/07/30/%E6%8E%A8%E8%8D%90%E7%B3%BB%E7%BB%9F%E5%AE%9E%E6%88%98/image-20210705194746347.png">
<meta property="og:image" content="http://example.com/2022/07/30/%E6%8E%A8%E8%8D%90%E7%B3%BB%E7%BB%9F%E5%AE%9E%E6%88%98/image-20210705212631427.png">
<meta property="og:image" content="http://example.com/2022/07/30/%E6%8E%A8%E8%8D%90%E7%B3%BB%E7%BB%9F%E5%AE%9E%E6%88%98/image-20210716113841664.png">
<meta property="og:image" content="http://example.com/2022/07/30/%E6%8E%A8%E8%8D%90%E7%B3%BB%E7%BB%9F%E5%AE%9E%E6%88%98/image-20210716160451026.png">
<meta property="og:image" content="http://example.com/2022/07/30/%E6%8E%A8%E8%8D%90%E7%B3%BB%E7%BB%9F%E5%AE%9E%E6%88%98/image-20210717105706237.png">
<meta property="og:image" content="http://example.com/2022/07/30/%E6%8E%A8%E8%8D%90%E7%B3%BB%E7%BB%9F%E5%AE%9E%E6%88%98/image-20210717134651630.png">
<meta property="og:image" content="http://example.com/2022/07/30/%E6%8E%A8%E8%8D%90%E7%B3%BB%E7%BB%9F%E5%AE%9E%E6%88%98/image-20210717135315387.png">
<meta property="og:image" content="http://example.com/2022/07/30/%E6%8E%A8%E8%8D%90%E7%B3%BB%E7%BB%9F%E5%AE%9E%E6%88%98/image-20210718130132232.png">
<meta property="og:image" content="http://example.com/2022/07/30/%E6%8E%A8%E8%8D%90%E7%B3%BB%E7%BB%9F%E5%AE%9E%E6%88%98/image-20210718130604147.png">
<meta property="og:image" content="http://example.com/2022/07/30/%E6%8E%A8%E8%8D%90%E7%B3%BB%E7%BB%9F%E5%AE%9E%E6%88%98/image-20210718131954377.png">
<meta property="og:image" content="http://example.com/2022/07/30/%E6%8E%A8%E8%8D%90%E7%B3%BB%E7%BB%9F%E5%AE%9E%E6%88%98/image-20210719101453175.png">
<meta property="article:published_time" content="2022-07-30T07:30:17.000Z">
<meta property="article:modified_time" content="2022-07-30T07:31:35.541Z">
<meta property="article:author" content="John Doe">
<meta name="twitter:card" content="summary">
<meta name="twitter:image" content="http://example.com/2022/07/30/%E6%8E%A8%E8%8D%90%E7%B3%BB%E7%BB%9F%E5%AE%9E%E6%88%98/image-20210705153804730.png">
  
    <link rel="alternate" href="/atom.xml" title="Hexo" type="application/atom+xml">
  
  
    <link rel="icon" href="/favicon.png">
  
  
    <link href="//fonts.googleapis.com/css?family=Source+Code+Pro" rel="stylesheet" type="text/css">
  
  
<link rel="stylesheet" href="/css/style.css">

<meta name="generator" content="Hexo 5.4.2"></head>

<body>
  <div id="container">
    <div id="wrap">
      <header id="header">
  <div id="banner"></div>
  <div id="header-outer" class="outer">
    <div id="header-title" class="inner">
      <h1 id="logo-wrap">
        <a href="/" id="logo">Hexo</a>
      </h1>
      
    </div>
    <div id="header-inner" class="inner">
      <nav id="main-nav">
        <a id="main-nav-toggle" class="nav-icon"></a>
        
          <a class="main-nav-link" href="/">Home</a>
        
          <a class="main-nav-link" href="/archives">Archives</a>
        
      </nav>
      <nav id="sub-nav">
        
          <a id="nav-rss-link" class="nav-icon" href="/atom.xml" title="RSS Feed"></a>
        
        <a id="nav-search-btn" class="nav-icon" title="Search"></a>
      </nav>
      <div id="search-form-wrap">
        <form action="//google.com/search" method="get" accept-charset="UTF-8" class="search-form"><input type="search" name="q" class="search-form-input" placeholder="Search"><button type="submit" class="search-form-submit">&#xF002;</button><input type="hidden" name="sitesearch" value="http://example.com"></form>
      </div>
    </div>
  </div>
</header>
      <div class="outer">
        <section id="main"><article id="post-推荐系统实战" class="article article-type-post" itemscope itemprop="blogPost">
  <div class="article-meta">
    <a href="/2022/07/30/%E6%8E%A8%E8%8D%90%E7%B3%BB%E7%BB%9F%E5%AE%9E%E6%88%98/" class="article-date">
  <time datetime="2022-07-30T07:30:17.000Z" itemprop="datePublished">2022-07-30</time>
</a>
    
  </div>
  <div class="article-inner">
    
    
      <header class="article-header">
        
  
    <h1 class="article-title" itemprop="name">
      推荐系统实战
    </h1>
  

      </header>
    
    <div class="article-entry" itemprop="articleBody">
      
        <h2 id="推荐系统"><a href="#推荐系统" class="headerlink" title="推荐系统"></a>推荐系统</h2><h3 id="推荐系统开发实战"><a href="#推荐系统开发实战" class="headerlink" title="推荐系统开发实战"></a>推荐系统开发实战</h3><h4 id="常用数据集"><a href="#常用数据集" class="headerlink" title="常用数据集"></a>常用数据集</h4><h5 id="MovieLens数据集"><a href="#MovieLens数据集" class="headerlink" title="MovieLens数据集"></a><code>MovieLens</code>数据集</h5><p><code>MovieLens</code>数据集是一个关于电影评分的数据集。</p>
<p>以<code>m1-1m.zip</code> 为例，文件解压之后有四个文件夹：<code>README</code> ，<code>ratings.dat</code>， <code>movies.dat</code>，<code>users.dat</code>。</p>
<ul>
<li><p><code>README</code></p>
<p>数据集的整体介绍。</p>
</li>
<li><p><code>ratings.dat</code></p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">1::1193::5::978300760</span><br><span class="line">1::661::3::978302109</span><br><span class="line">1::914::3::978301968</span><br><span class="line">1::3408::4::978300275</span><br><span class="line">1::2355::5::978824291</span><br><span class="line">1::1197::3::978302268</span><br><span class="line">1::1287::5::978302039</span><br><span class="line">1::2804::5::978300719</span><br></pre></td></tr></table></figure>

<p>该文件是用户对电影的评分记录，包含1000209条记录。</p>
<p>对应的文件格式为：</p>
<p><code>UserID::MovieID::Rating::Timestamp</code></p>
<p><code>UserID</code>的范围是<code>1 ~ 6040</code></p>
<p><code>MovieID</code> 的范围是<code>1 ~ 3952</code></p>
<p><code>Rating</code> 最高分为 <code>5</code>分</p>
<p><code>Timestamp</code>以秒为单位</p>
<p>示例为： <code>ID</code>为 <code>1</code>的用户在时间戳为 <code>978300760</code>时对<code>ID</code>为<code>1193</code>这部电影打了<code>5</code></p>
<p>验证数据集：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> matplotlib.pyplot <span class="keyword">as</span> plt</span><br><span class="line"><span class="keyword">import</span> pandas <span class="keyword">as</span> pd</span><br><span class="line"><span class="comment"># 显示中文标签</span></span><br><span class="line">plt.rcParams[<span class="string">&quot;font.sans-serif&quot;</span>] = [<span class="string">&#x27;SimHei&#x27;</span>]</span><br><span class="line"><span class="comment"># 正常显示负号</span></span><br><span class="line">plt.rcParams[<span class="string">&quot;axes.unicode_minus&quot;</span>] = <span class="literal">False</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">getRatings</span>(<span class="params">file_path</span>):</span><br><span class="line">    rates = pd.read_table(</span><br><span class="line">        file_path,</span><br><span class="line">        header= <span class="literal">None</span>,</span><br><span class="line">        sep=<span class="string">&quot;::&quot;</span>,</span><br><span class="line">        names = [<span class="string">&quot;userID&quot;</span>,<span class="string">&quot;movieID&quot;</span>,<span class="string">&quot;rate&quot;</span>,<span class="string">&quot;timestamp&quot;</span>],</span><br><span class="line">    )</span><br><span class="line">    <span class="built_in">print</span>(<span class="string">&quot;userID的范围是：&lt;&#123;&#125;,&#123;&#125;&gt;&quot;</span>.<span class="built_in">format</span>(<span class="built_in">min</span>(rates[<span class="string">&quot;userID&quot;</span>]),<span class="built_in">max</span>(rates[<span class="string">&quot;userID&quot;</span>])))</span><br><span class="line">    <span class="built_in">print</span>(<span class="string">&quot;movieID的范围是：&lt;&#123;&#125;,&#123;&#125;&gt;&quot;</span>.<span class="built_in">format</span>(<span class="built_in">min</span>(rates[<span class="string">&quot;movieID&quot;</span>]),<span class="built_in">max</span>(rates[<span class="string">&quot;movieID&quot;</span>])))</span><br><span class="line">    <span class="built_in">print</span>(<span class="string">&quot;评分的范围是：&lt;&#123;&#125;,&#123;&#125;&gt;&quot;</span>.<span class="built_in">format</span>(<span class="built_in">min</span>(rates[<span class="string">&quot;rate&quot;</span>]),<span class="built_in">max</span>(rates[<span class="string">&quot;rate&quot;</span>])))</span><br><span class="line">    <span class="built_in">print</span>(<span class="string">&quot;数据总条数为：\n&#123;&#125;&quot;</span>.<span class="built_in">format</span>(rates.count()))</span><br><span class="line">    <span class="built_in">print</span>(<span class="string">&quot;数据前5条记录为:\n&#123;&#125;&quot;</span>.<span class="built_in">format</span>(rates.head(<span class="number">5</span>)))</span><br><span class="line">    df = rates[<span class="string">&quot;userID&quot;</span>].groupby(rates[<span class="string">&quot;userID&quot;</span>])</span><br><span class="line">    <span class="built_in">print</span>(<span class="string">&quot;用户评分记录最少条数为：&#123;&#125;&quot;</span>.<span class="built_in">format</span>(df.count().<span class="built_in">min</span>()))</span><br><span class="line"></span><br><span class="line">    scores = rates[<span class="string">&quot;rate&quot;</span>].groupby(rates[<span class="string">&quot;rate&quot;</span>]).count()</span><br><span class="line">    <span class="comment">#图上添加数字</span></span><br><span class="line">    <span class="keyword">for</span> x,y <span class="keyword">in</span> <span class="built_in">zip</span>(scores.keys(),scores.values):</span><br><span class="line">        plt.text(x, y + <span class="number">2</span>, <span class="string">&quot;%.0f&quot;</span> % y, ha=<span class="string">&quot;center&quot;</span>,va=<span class="string">&quot;bottom&quot;</span>, fontsize=<span class="number">12</span>)</span><br><span class="line">    plt.bar(scores.keys(), scores.values, fc=<span class="string">&quot;r&quot;</span>, tick_label=scores.keys())</span><br><span class="line">    plt.xlabel(<span class="string">&quot;评分参数&quot;</span>)</span><br><span class="line">    plt.ylabel(<span class="string">&quot;对应的人数&quot;</span>)</span><br><span class="line">    plt.title(<span class="string">&quot;评分分数对应人数统计&quot;</span>)</span><br><span class="line">    plt.show()</span><br><span class="line"></span><br><span class="line"><span class="keyword">if</span> __name__ == <span class="string">&quot;__main__&quot;</span>:</span><br><span class="line">    getRatings(<span class="string">&quot;C:\\Users\\要王冰冰抱抱\\Desktop\\MovieLens数据集\\ml-1m\\ratings.dat&quot;</span>)</span><br></pre></td></tr></table></figure>

<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><span class="line">userID的范围是：&lt;1,6040&gt;</span><br><span class="line">movieID的范围是：&lt;1,3952&gt;</span><br><span class="line">评分的范围是：&lt;1,5&gt;</span><br><span class="line">数据总条数为：</span><br><span class="line">userID       1000209</span><br><span class="line">movieID      1000209</span><br><span class="line">rate         1000209</span><br><span class="line">timestamp    1000209</span><br><span class="line">dtype: int64</span><br><span class="line">数据前5条记录为:</span><br><span class="line">   userID  movieID  rate  timestamp</span><br><span class="line">0       1     1193     5  978300760</span><br><span class="line">1       1      661     3  978302109</span><br><span class="line">2       1      914     3  978301968</span><br><span class="line">3       1     3408     4  978300275</span><br><span class="line">4       1     2355     5  978824291</span><br><span class="line">用户评分记录最少条数为：20</span><br></pre></td></tr></table></figure>

<p><img src="image-20210705153804730.png" alt="image-20210705153804730"></p>
</li>
<li><p><code>movies.dat</code></p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">1::Toy Story (1995)::Animation|Children<span class="string">&#x27;s|Comedy</span></span><br><span class="line"><span class="string">2::Jumanji (1995)::Adventure|Children&#x27;</span>s|Fantasy</span><br><span class="line">3::Grumpier Old Men (1995)::Comedy|Romance</span><br><span class="line">4::Waiting to Exhale (1995)::Comedy|Drama</span><br><span class="line">5::Father of the Bride Part II (1995)::Comedy</span><br><span class="line">6::Heat (1995)::Action|Crime|Thriller</span><br><span class="line">7::Sabrina (1995)::Comedy|Romance</span><br></pre></td></tr></table></figure>

<p>该文件是电影的相关信息。</p>
<p>列与列之间以<code>::</code>分割，第一列是电影ID，第二列为电影名字，第三列为电影类型，类型之间以<code>|</code>分割。</p>
<blockquote>
<p>如果出现<code>UnicodeDecodeError: &#39;utf-8&#39; codec can&#39;t decode byte 0xe9:invalid continuation byte</code>错误，则使用<code>Pycharm</code>打开<code>movies.dat</code>并进行转换为<code>ISO-8859-1</code> ，保存即可。</p>
</blockquote>
<p>查看数据总条数和电影类型统计分布图。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">def</span> <span class="title function_">getMovies</span>(<span class="params">file_path</span>):</span><br><span class="line">    movies = pd.read_table(</span><br><span class="line">        file_path,</span><br><span class="line">        header = <span class="literal">None</span>,</span><br><span class="line">        sep = <span class="string">&quot;::&quot;</span>,</span><br><span class="line">        names = [<span class="string">&quot;movieID&quot;</span>, <span class="string">&quot;title&quot;</span>, <span class="string">&quot;genres&quot;</span>],</span><br><span class="line">    )</span><br><span class="line">    <span class="built_in">print</span>(<span class="string">&quot;movieID的范围是：&lt;&#123;&#125;,&#123;&#125;&gt;&quot;</span>.<span class="built_in">format</span>(<span class="built_in">min</span>(movies[<span class="string">&quot;movieID&quot;</span>]),<span class="built_in">max</span>(movies[<span class="string">&quot;movieID&quot;</span>])))</span><br><span class="line">    <span class="built_in">print</span>(<span class="string">&quot;数据总条数为: \n&#123;&#125;&quot;</span>.<span class="built_in">format</span>(movies.count()))</span><br><span class="line">    moviesDict = <span class="built_in">dict</span>()</span><br><span class="line">    <span class="keyword">for</span> line <span class="keyword">in</span> movies[<span class="string">&quot;genres&quot;</span>].values:</span><br><span class="line">        <span class="keyword">for</span> one <span class="keyword">in</span> line.split(<span class="string">&quot;|&quot;</span>):</span><br><span class="line">            moviesDict.setdefault(one, <span class="number">0</span>)</span><br><span class="line">            moviesDict[one] += <span class="number">1</span></span><br><span class="line">    <span class="built_in">print</span>(<span class="string">&quot;电影类型总数为:&#123;&#125;&quot;</span>.<span class="built_in">format</span>(<span class="built_in">len</span>(moviesDict)))</span><br><span class="line">    <span class="built_in">print</span>(<span class="string">&quot;电影类型分别为:&#123;&#125;&quot;</span>.<span class="built_in">format</span>(moviesDict.keys()))</span><br><span class="line">    <span class="built_in">print</span>(moviesDict)</span><br><span class="line"></span><br><span class="line">    newMD = <span class="built_in">sorted</span>(moviesDict.items(), key=<span class="keyword">lambda</span>  x:x[<span class="number">1</span>], reverse=<span class="literal">True</span>)</span><br><span class="line">    <span class="comment"># 设置标签</span></span><br><span class="line">    labels = [newMD[i][<span class="number">0</span>] <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(<span class="built_in">len</span>(newMD))]</span><br><span class="line">    values = [newMD[i][<span class="number">1</span>] <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(<span class="built_in">len</span>(newMD))]</span><br><span class="line">    explode = [x * <span class="number">0.01</span> <span class="keyword">for</span> x <span class="keyword">in</span> <span class="built_in">range</span>(<span class="built_in">len</span>(newMD))]</span><br><span class="line">    plt.axes(aspect=<span class="number">1</span>)</span><br><span class="line">    <span class="comment"># autopct表示百分比的格式  shadow表示阴影 labeldistance 表示标签离中心距离  pctdistance表示百分百数据离中心区距离</span></span><br><span class="line">    plt.pie(</span><br><span class="line">        x = values,</span><br><span class="line">        labels = labels,</span><br><span class="line">        explode = explode,</span><br><span class="line">        autopct = <span class="string">&quot;%3.1f  %%&quot;</span>,</span><br><span class="line">        shadow = <span class="literal">False</span>,</span><br><span class="line">        labeldistance = <span class="number">1.1</span>,</span><br><span class="line">        startangle = <span class="number">0</span>,</span><br><span class="line">        pctdistance = <span class="number">0.8</span>,</span><br><span class="line">        center = (-<span class="number">1</span>, <span class="number">0</span>),</span><br><span class="line">    )</span><br><span class="line">    <span class="comment"># 控制位置： 在bbox_to_anchor数组中，前者控制左右移动，后者控制上下移动</span></span><br><span class="line">    <span class="comment"># ncol控制图例所列的列数，默认为 1</span></span><br><span class="line">    plt.legend(loc=<span class="number">7</span>, bbox_to_anchor=(<span class="number">1.3</span>, <span class="number">1.0</span>), ncol=<span class="number">3</span>, fancybox=<span class="literal">True</span>, shadow=<span class="literal">True</span>, fontsize=<span class="number">6</span>)</span><br><span class="line">    plt.show()</span><br><span class="line"><span class="keyword">if</span> __name__ == <span class="string">&quot;__main__&quot;</span>:</span><br><span class="line">    <span class="comment">#getRatings(&quot;C:\\Users\\要王冰冰抱抱\\Desktop\\MovieLens\\ml-1m\\ratings.dat&quot;)</span></span><br><span class="line">    getMovies(<span class="string">&quot;C:\\Users\\要王冰冰抱抱\\Desktop\\MovieLens\\ml-1m\\movies.dat&quot;</span>)</span><br></pre></td></tr></table></figure>

<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line">movieID的范围是：&lt;1,3952&gt;</span><br><span class="line">数据总条数为: </span><br><span class="line">movieID    3883</span><br><span class="line">title      3883</span><br><span class="line">genres     3883</span><br><span class="line">dtype: int64</span><br><span class="line">电影类型总数为:18</span><br><span class="line">电影类型分别为:dict_keys([<span class="string">&#x27;Animation&#x27;</span>, <span class="string">&quot;Children&#x27;s&quot;</span>, <span class="string">&#x27;Comedy&#x27;</span>, <span class="string">&#x27;Adventure&#x27;</span>, <span class="string">&#x27;Fantasy&#x27;</span>, <span class="string">&#x27;Romance&#x27;</span>, <span class="string">&#x27;Drama&#x27;</span>, <span class="string">&#x27;Action&#x27;</span>, <span class="string">&#x27;Crime&#x27;</span>, <span class="string">&#x27;Thriller&#x27;</span>, <span class="string">&#x27;Horror&#x27;</span>, <span class="string">&#x27;Sci-Fi&#x27;</span>, <span class="string">&#x27;Documentary&#x27;</span>, <span class="string">&#x27;War&#x27;</span>, <span class="string">&#x27;Musical&#x27;</span>, <span class="string">&#x27;Mystery&#x27;</span>, <span class="string">&#x27;Film-Noir&#x27;</span>, <span class="string">&#x27;Western&#x27;</span>])</span><br><span class="line">&#123;<span class="string">&#x27;Animation&#x27;</span>: 105, <span class="string">&quot;Children&#x27;s&quot;</span>: 251, <span class="string">&#x27;Comedy&#x27;</span>: 1200, <span class="string">&#x27;Adventure&#x27;</span>: 283, <span class="string">&#x27;Fantasy&#x27;</span>: 68, <span class="string">&#x27;Romance&#x27;</span>: 471, <span class="string">&#x27;Drama&#x27;</span>: 1603, <span class="string">&#x27;Action&#x27;</span>: 503, <span class="string">&#x27;Crime&#x27;</span>: 211, <span class="string">&#x27;Thriller&#x27;</span>: 492, <span class="string">&#x27;Horror&#x27;</span>: 343, <span class="string">&#x27;Sci-Fi&#x27;</span>: 276, <span class="string">&#x27;Documentary&#x27;</span>: 127, <span class="string">&#x27;War&#x27;</span>: 143, <span class="string">&#x27;Musical&#x27;</span>: 114, <span class="string">&#x27;Mystery&#x27;</span>: 106, <span class="string">&#x27;Film-Noir&#x27;</span>: 44, <span class="string">&#x27;Western&#x27;</span>: 68&#125;</span><br><span class="line"></span><br></pre></td></tr></table></figure>

<p><img src="image-20210705165736880.png" alt="image-20210705165736880"></p>
</li>
<li><p><code>users.dat</code></p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">1::F::1::10::48067</span><br><span class="line">2::M::56::16::70072</span><br><span class="line">3::M::25::15::55117</span><br><span class="line">4::M::45::7::02460</span><br><span class="line">5::M::25::20::55455</span><br><span class="line">6::F::50::9::55117</span><br><span class="line">7::M::35::1::06810</span><br><span class="line">8::M::25::12::11413</span><br></pre></td></tr></table></figure>

<p>列数据以<code>::</code> 进行分割。第1列是用户<code>ID</code> ，第2列是用户性别（<code>F</code>为男性，<code>M</code>为女性），第3列为年龄，第4列是职业，第5列是压缩编码。</p>
<p>年龄<code>1</code>代表 <code>1 ~ 18岁</code>，年龄<code>18</code>代表<code>18 ~ 24岁</code>，年龄<code>25</code>代表<code>25 ~ 34岁</code>，年龄<code>35</code>代表<code>35 ~ 44岁</code>，年龄<code>45</code>代表<code>45 ~ 49岁</code>，年龄<code>50</code>代表<code>50 ~ 55岁</code>，年龄<code>56</code>代表大于等于<code>56</code>岁。</p>
<p>Occupation is chosen from the following choices:</p>
<ul>
<li> 0:  “other” or not specified</li>
<li> 1:  “academic/educator”</li>
<li> 2:  “artist”</li>
<li> 3:  “clerical/admin”</li>
<li> 4:  “college/grad student”</li>
<li> 5:  “customer service”</li>
<li> 6:  “doctor/health care”</li>
<li> 7:  “executive/managerial”</li>
<li> 8:  “farmer”</li>
<li> 9:  “homemaker”</li>
<li> 10:  “K-12 student”</li>
<li> 11:  “lawyer”</li>
<li> 12:  “programmer”</li>
<li> 13:  “retired”</li>
<li> 14:  “sales/marketing”</li>
<li> 15:  “scientist”</li>
<li> 16:  “self-employed”</li>
<li> 17:  “technician/engineer”</li>
<li> 18:  “tradesman/craftsman”</li>
<li> 19:  “unemployed”</li>
<li> 20:  “writer”</li>
</ul>
</li>
</ul>
<p>查看用户性别分布图。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">def</span> <span class="title function_">getUsers</span>(<span class="params">file_path</span>):</span><br><span class="line">    users = pd.read_table(</span><br><span class="line">        file_path,</span><br><span class="line">        header=<span class="literal">None</span>,</span><br><span class="line">        sep=<span class="string">&quot;::&quot;</span>,</span><br><span class="line">        names=[<span class="string">&quot;userID&quot;</span>,<span class="string">&quot;gender&quot;</span>,<span class="string">&quot;age&quot;</span>,<span class="string">&quot;Occupation&quot;</span>,<span class="string">&quot;zip-code&quot;</span>],</span><br><span class="line">    )</span><br><span class="line">    <span class="built_in">print</span>(<span class="string">&quot;userID的范围是：&lt;&#123;&#125;,&#123;&#125;&gt;&quot;</span>.<span class="built_in">format</span>(<span class="built_in">min</span>(users[<span class="string">&quot;userID&quot;</span>]),<span class="built_in">max</span>(users[<span class="string">&quot;userID&quot;</span>])))</span><br><span class="line">    <span class="built_in">print</span>(<span class="string">&quot;数据总条数为：\n&#123;&#125;&quot;</span>.<span class="built_in">format</span>(users.count()))</span><br><span class="line">    usersGender = users[<span class="string">&quot;gender&quot;</span>].groupby(users[<span class="string">&quot;gender&quot;</span>]).count()</span><br><span class="line">    <span class="built_in">print</span>(usersGender)</span><br><span class="line"></span><br><span class="line">    plt.axes(aspect=<span class="number">1</span>)</span><br><span class="line">    plt.pie(x=usersGender.values,labels=usersGender.keys(),autopct=<span class="string">&quot;3.1f %%&quot;</span>)</span><br><span class="line">    plt.legend(bbox_to_anchor=(<span class="number">1.0</span>,<span class="number">1.0</span>))</span><br><span class="line">    plt.show()</span><br><span class="line"><span class="keyword">if</span> __name__ == <span class="string">&quot;__main__&quot;</span>:</span><br><span class="line">    <span class="comment">#getRatings(&quot;C:\\Users\\要王冰冰抱抱\\Desktop\\MovieLens\\ml-1m\\ratings.dat&quot;)</span></span><br><span class="line">    <span class="comment">#getMovies(&quot;C:\\Users\\要王冰冰抱抱\\Desktop\\MovieLens\\ml-1m\\movies.dat&quot;)</span></span><br><span class="line">    getUsers(<span class="string">&quot;C:\\Users\\要王冰冰抱抱\\Desktop\\MovieLens\\ml-1m\\users.dat&quot;</span>)</span><br></pre></td></tr></table></figure>

<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line">userID的范围是：&lt;1,6040&gt;</span><br><span class="line">数据总条数为：</span><br><span class="line">userID        6040</span><br><span class="line">gender        6040</span><br><span class="line">age           6040</span><br><span class="line">Occupation    6040</span><br><span class="line">zip-code      6040</span><br><span class="line">dtype: int64</span><br><span class="line">gender</span><br><span class="line">F    1709</span><br><span class="line">M    4331</span><br><span class="line">Name: gender, dtype: int64</span><br><span class="line"></span><br></pre></td></tr></table></figure>

<p><img src="image-20210705172934363.png" alt="image-20210705172934363"></p>
<p>查看用户年龄分布图。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br></pre></td><td class="code"><pre><span class="line">usersAge = users[<span class="string">&quot;age&quot;</span>].groupby(users[<span class="string">&quot;age&quot;</span>]).count()</span><br><span class="line"><span class="built_in">print</span>(usersAge)</span><br><span class="line"></span><br><span class="line">plt.plot(usersAge.keys(),</span><br><span class="line">         usersAge.values,</span><br><span class="line">         label=<span class="string">&quot;用户年龄信息展示&quot;</span>,</span><br><span class="line">         linewidth=<span class="number">3</span>,</span><br><span class="line">         color=<span class="string">&quot;r&quot;</span>,</span><br><span class="line">         marker=<span class="string">&quot;o&quot;</span>,</span><br><span class="line">         markerfacecolor=<span class="string">&quot;blue&quot;</span>,</span><br><span class="line">         markersize=<span class="number">12</span>,</span><br><span class="line">         )</span><br><span class="line"><span class="comment"># 图上添加文字</span></span><br><span class="line"><span class="keyword">for</span> x,y <span class="keyword">in</span> <span class="built_in">zip</span>(usersAge.keys(),usersAge.values):</span><br><span class="line">    plt.text(x, y + <span class="number">10</span>, <span class="string">&quot;%.0f&quot;</span> %y, ha = <span class="string">&quot;center&quot;</span>, va=<span class="string">&quot;bottom&quot;</span>, fontsize=<span class="number">12</span> )</span><br><span class="line">plt.xlabel(<span class="string">&quot;用户年龄&quot;</span>)</span><br><span class="line">plt.ylabel(<span class="string">&quot;年龄段对应的人数&quot;</span>)</span><br><span class="line">plt.title(<span class="string">&quot;用户年龄段人数统计&quot;</span>)</span><br><span class="line">plt.show()</span><br></pre></td></tr></table></figure>

<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">age</span><br><span class="line">1      222</span><br><span class="line">18    1103</span><br><span class="line">25    2096</span><br><span class="line">35    1193</span><br><span class="line">45     550</span><br><span class="line">50     496</span><br><span class="line">56     380</span><br><span class="line">Name: age, dtype: int64</span><br></pre></td></tr></table></figure>

<p><img src="image-20210705184536515.png" alt="image-20210705184536515"></p>
<h5 id="Book-Crossings数据集"><a href="#Book-Crossings数据集" class="headerlink" title="Book-Crossings数据集"></a><code>Book-Crossings</code>数据集</h5><p><code>Book-Crossings</code>数据集是一个图书评分数据集。</p>
<p><code>Book-Crossings</code>数据集解压之后有三个<code>csv</code>文件：<code>BX-Book-Ratings.csv</code>，<code>BX-Books.csv</code>，<code>BX-Users.csv</code>。</p>
<ul>
<li><p><code>BX-Book-Ratings.csv</code></p>
<p>该文件的内容是用户对图书的评分。</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="string">&quot;User-ID&quot;</span>;<span class="string">&quot;ISBN&quot;</span>;<span class="string">&quot;Book-Rating&quot;</span></span><br><span class="line"><span class="string">&quot;276725&quot;</span>;<span class="string">&quot;034545104X&quot;</span>;<span class="string">&quot;0&quot;</span></span><br><span class="line"><span class="string">&quot;276726&quot;</span>;<span class="string">&quot;0155061224&quot;</span>;<span class="string">&quot;5&quot;</span></span><br><span class="line"><span class="string">&quot;276727&quot;</span>;<span class="string">&quot;0446520802&quot;</span>;<span class="string">&quot;0&quot;</span></span><br><span class="line"><span class="string">&quot;276729&quot;</span>;<span class="string">&quot;052165615X&quot;</span>;<span class="string">&quot;3&quot;</span></span><br><span class="line"><span class="string">&quot;276729&quot;</span>;<span class="string">&quot;0521795028&quot;</span>;<span class="string">&quot;6&quot;</span></span><br><span class="line"><span class="string">&quot;276733&quot;</span>;<span class="string">&quot;2080674722&quot;</span>;<span class="string">&quot;0&quot;</span></span><br></pre></td></tr></table></figure>

<p>每一行都是一个用户对一本书的评分。列之间使用<code>;</code>分割。</p>
<p>查看用户评分的数据分布。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> matplotlib.pyplot <span class="keyword">as</span> plt</span><br><span class="line"><span class="keyword">import</span> pandas <span class="keyword">as</span> pd</span><br><span class="line"><span class="comment"># 显示中文标签</span></span><br><span class="line">plt.rcParams[<span class="string">&quot;font.sans-serif&quot;</span>] = [<span class="string">&#x27;SimHei&#x27;</span>]</span><br><span class="line"><span class="comment"># 正常显示负号</span></span><br><span class="line">plt.rcParams[<span class="string">&quot;axes.unicode_minus&quot;</span>] = <span class="literal">False</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">getRatings</span>(<span class="params">file_path</span>):</span><br><span class="line">    <span class="built_in">print</span>(<span class="string">&quot;file_path is &#x27;&#123;&#125;&#x27;&quot;</span>.<span class="built_in">format</span>(file_path))</span><br><span class="line">    ratings = pd.read_table(</span><br><span class="line">        file_path,</span><br><span class="line">        header= <span class="number">0</span>,</span><br><span class="line">        sep=<span class="string">&quot;;&quot;</span>,</span><br><span class="line">        encoding=<span class="string">&quot;ISO-8859-1&quot;</span>,</span><br><span class="line">    )</span><br><span class="line">    <span class="built_in">print</span>(<span class="string">&quot;数据前5条记录为:\n&#123;&#125;&quot;</span>.<span class="built_in">format</span>(ratings.head(<span class="number">5</span>)))</span><br><span class="line">    <span class="built_in">print</span>(<span class="string">&quot;数据总条数为：\n&#123;&#125;&quot;</span>.<span class="built_in">format</span>(ratings.count()))</span><br><span class="line">    <span class="built_in">print</span>(<span class="string">&quot;评分的范围是：&lt;&#123;&#125;,&#123;&#125;&gt;&quot;</span>.<span class="built_in">format</span>(ratings[<span class="string">&quot;Book-Rating&quot;</span>].<span class="built_in">min</span>(), ratings[<span class="string">&quot;Book-Rating&quot;</span>].<span class="built_in">max</span>()))</span><br><span class="line"></span><br><span class="line">    rateSer = ratings[<span class="string">&quot;Book-Rating&quot;</span>].groupby(ratings[<span class="string">&quot;Book-Rating&quot;</span>]).count()</span><br><span class="line">    plt.bar(rateSer.keys(), rateSer.values, fc=<span class="string">&quot;r&quot;</span>, tick_label=rateSer.keys())</span><br><span class="line">    <span class="keyword">for</span> x, y <span class="keyword">in</span> <span class="built_in">zip</span>(rateSer.keys(),rateSer.values):</span><br><span class="line">        plt.text(x ,y + <span class="number">1</span>, <span class="string">&quot;%.0f&quot;</span> % y, ha=<span class="string">&quot;center&quot;</span>, va=<span class="string">&quot;bottom&quot;</span>, fontsize=<span class="number">9</span>)</span><br><span class="line">    plt.xlabel(<span class="string">&quot;用户评分&quot;</span>)</span><br><span class="line">    plt.ylabel(<span class="string">&quot;评分对应的人数&quot;</span>)</span><br><span class="line">    plt.title(<span class="string">&quot;评分分数对应人数统计&quot;</span>)</span><br><span class="line">    plt.show()</span><br><span class="line"><span class="keyword">if</span> __name__ == <span class="string">&quot;__main__&quot;</span>:</span><br><span class="line">    getRatings(<span class="string">&quot;C:\\Users\\要王冰冰抱抱\\Desktop\\Book-Crossings\\Book reviews\\Book reviews\\BX-Book-Ratings.csv&quot;</span>)</span><br></pre></td></tr></table></figure>

<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line">file_path is <span class="string">&#x27;C:\Users\要王冰冰抱抱\Desktop\Book-Crossings\Book reviews\Book reviews\BX-Book-Ratings.csv&#x27;</span></span><br><span class="line">数据前5条记录为:</span><br><span class="line">   User-ID        ISBN  Book-Rating</span><br><span class="line">0   276725  034545104X            0</span><br><span class="line">1   276726  0155061224            5</span><br><span class="line">2   276727  0446520802            0</span><br><span class="line">3   276729  052165615X            3</span><br><span class="line">4   276729  0521795028            6</span><br><span class="line">数据总条数为：</span><br><span class="line">User-ID        1149780</span><br><span class="line">ISBN           1149780</span><br><span class="line">Book-Rating    1149780</span><br><span class="line">dtype: int64</span><br><span class="line">评分的范围是：&lt;0,10&gt;</span><br></pre></td></tr></table></figure>

<p><img src="image-20210705192448439.png" alt="image-20210705192448439"></p>
</li>
<li><p><code>BX-Books.csv</code></p>
<p>该文件记录的是图书信息。</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="string">&quot;ISBN&quot;</span>;<span class="string">&quot;Book-Title&quot;</span>;<span class="string">&quot;Book-Author&quot;</span>;<span class="string">&quot;Year-Of-Publication&quot;</span>;<span class="string">&quot;Publisher&quot;</span>;<span class="string">&quot;Image-URL-S&quot;</span>;<span class="string">&quot;Image-URL-M&quot;</span>;<span class="string">&quot;Image-URL-L&quot;</span></span><br><span class="line"><span class="string">&quot;0195153448&quot;</span>;<span class="string">&quot;Classical Mythology&quot;</span>;<span class="string">&quot;Mark P. O. Morford&quot;</span>;<span class="string">&quot;2002&quot;</span>;<span class="string">&quot;Oxford University Press&quot;</span>;<span class="string">&quot;http://images.amazon.com/images/P/0195153448.01.THUMBZZZ.jpg&quot;</span>;<span class="string">&quot;http://images.amazon.com/images/P/0195153448.01.MZZZZZZZ.jpg&quot;</span>;<span class="string">&quot;http://images.amazon.com/images/P/0195153448.01.LZZZZZZZ.jpg&quot;</span></span><br><span class="line"><span class="string">&quot;0002005018&quot;</span>;<span class="string">&quot;Clara Callan&quot;</span>;<span class="string">&quot;Richard Bruce Wright&quot;</span>;<span class="string">&quot;2001&quot;</span>;<span class="string">&quot;HarperFlamingo Canada&quot;</span>;<span class="string">&quot;http://images.amazon.com/images/P/0002005018.01.THUMBZZZ.jpg&quot;</span>;<span class="string">&quot;http://images.amazon.com/images/P/0002005018.01.MZZZZZZZ.jpg&quot;</span>;<span class="string">&quot;http://images.amazon.com/images/P/0002005018.01.LZZZZZZZ.jpg&quot;</span></span><br><span class="line"><span class="string">&quot;0060973129&quot;</span>;<span class="string">&quot;Decision in Normandy&quot;</span>;<span class="string">&quot;Carlo D&#x27;Este&quot;</span>;<span class="string">&quot;1991&quot;</span>;<span class="string">&quot;HarperPerennial&quot;</span>;<span class="string">&quot;http://images.amazon.com/images/P/0060973129.01.THUMBZZZ.jpg&quot;</span>;<span class="string">&quot;http://images.amazon.com/images/P/0060973129.01.MZZZZZZZ.jpg&quot;</span>;<span class="string">&quot;http://images.amazon.com/images/P/0060973129.01.LZZZZZZZ.jpg&quot;</span></span><br><span class="line"><span class="string">&quot;0374157065&quot;</span>;<span class="string">&quot;Flu: The Story of the Great Influenza Pandemic of 1918 and the Search for the Virus That Caused It&quot;</span>;<span class="string">&quot;Gina Bari Kolata&quot;</span>;<span class="string">&quot;1999&quot;</span>;<span class="string">&quot;Farrar Straus Giroux&quot;</span>;<span class="string">&quot;http://images.amazon.com/images/P/0374157065.01.THUMBZZZ.jpg&quot;</span>;<span class="string">&quot;http://images.amazon.com/images/P/0374157065.01.MZZZZZZZ.jpg&quot;</span>;<span class="string">&quot;http://images.amazon.com/images/P/0374157065.01.LZZZZZZZ.jpg&quot;</span></span><br><span class="line"><span class="string">&quot;0393045218&quot;</span>;<span class="string">&quot;The Mummies of Urumchi&quot;</span>;<span class="string">&quot;E. J. W. Barber&quot;</span>;<span class="string">&quot;1999&quot;</span>;<span class="string">&quot;W. W. Norton &amp; Company&quot;</span>;<span class="string">&quot;http://images.amazon.com/images/P/0393045218.01.THUMBZZZ.jpg&quot;</span>;<span class="string">&quot;http://images.amazon.com/images/P/0393045218.01.MZZZZZZZ.jpg&quot;</span>;<span class="string">&quot;http://images.amazon.com/images/P/0393045218.01.LZZZZZZZ.jpg&quot;</span></span><br><span class="line"><span class="string">&quot;0399135782&quot;</span>;<span class="string">&quot;The Kitchen God&#x27;s Wife&quot;</span>;<span class="string">&quot;Amy Tan&quot;</span>;<span class="string">&quot;1991&quot;</span>;<span class="string">&quot;Putnam Pub Group&quot;</span>;<span class="string">&quot;http://images.amazon.com/images/P/0399135782.01.THUMBZZZ.jpg&quot;</span>;<span class="string">&quot;http://images.amazon.com/images/P/0399135782.01.MZZZZZZZ.jpg&quot;</span>;<span class="string">&quot;http://images.amazon.com/images/P/0399135782.01.LZZZZZZZ.jpg&quot;</span></span><br><span class="line"></span><br></pre></td></tr></table></figure>

<p>每一行表示一本图书的信息。列之间用<code>;</code>分割。</p>
<p>第<code>1</code>列为图书的唯一编号<code>ISBN</code>，第<code>2</code>列为图书名字<code>Book-Title</code>，第<code>3</code>列为作者<code>Book-Author</code>，第<code>4</code>列为初版时间<code>Year-Of-Publication</code>，第<code>5</code>列为出版社<code>Publisher</code>，第<code>6,7,8</code>列为图书封面图片<code>Image-URL-S,Image-URL-M，Image-URL-L</code>。</p>
</li>
<li><p><code>BX-Users.csv</code></p>
<p>该文件记录的是读者信息。</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="string">&quot;User-ID&quot;</span>;<span class="string">&quot;Location&quot;</span>;<span class="string">&quot;Age&quot;</span></span><br><span class="line"><span class="string">&quot;1&quot;</span>;<span class="string">&quot;nyc, new york, usa&quot;</span>;NULL</span><br><span class="line"><span class="string">&quot;2&quot;</span>;<span class="string">&quot;stockton, california, usa&quot;</span>;<span class="string">&quot;18&quot;</span></span><br><span class="line"><span class="string">&quot;3&quot;</span>;<span class="string">&quot;moscow, yukon territory, russia&quot;</span>;NULL</span><br><span class="line"><span class="string">&quot;4&quot;</span>;<span class="string">&quot;porto, v.n.gaia, portugal&quot;</span>;<span class="string">&quot;17&quot;</span></span><br><span class="line"><span class="string">&quot;5&quot;</span>;<span class="string">&quot;farnborough, hants, united kingdom&quot;</span>;NULL</span><br><span class="line"><span class="string">&quot;6&quot;</span>;<span class="string">&quot;santa monica, california, usa&quot;</span>;<span class="string">&quot;61&quot;</span></span><br></pre></td></tr></table></figure>

<p>每一行代表一个用户信息。列之间用<code>；</code>分割。</p>
<p>第<code>1</code>列为用户编号<code>User-ID</code>，第<code>2</code>列为用户位置<code>Location</code>，第<code>3</code>列为用户年龄<code>Age</code>。</p>
<p>用户相关信息。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">def</span> <span class="title function_">getUsers</span>(<span class="params">file_path</span>):</span><br><span class="line">    users = pd.read_table(</span><br><span class="line">        file_path,</span><br><span class="line">        header=<span class="number">0</span>,</span><br><span class="line">        sep=<span class="string">&quot;;&quot;</span>,</span><br><span class="line">        encoding=<span class="string">&quot;ISO-8859-1&quot;</span>,</span><br><span class="line">    )</span><br><span class="line">    <span class="built_in">print</span>(<span class="string">&quot;数据前5条记录为:\n&#123;&#125;&quot;</span>.<span class="built_in">format</span>(users.head(<span class="number">5</span>)))</span><br><span class="line">    <span class="built_in">print</span>(<span class="string">&quot;数据总条数为：\n&#123;&#125;&quot;</span>.<span class="built_in">format</span>(users.count()))</span><br><span class="line">    <span class="built_in">print</span>(<span class="string">&quot;年龄的范围是：&lt;&#123;&#125;,&#123;&#125;&gt;&quot;</span>.<span class="built_in">format</span>(users[<span class="string">&quot;Age&quot;</span>].<span class="built_in">min</span>(), users[<span class="string">&quot;Age&quot;</span>].<span class="built_in">max</span>()))</span><br><span class="line"></span><br><span class="line">    usersAge = users[<span class="string">&quot;Age&quot;</span>].groupby(users[<span class="string">&quot;Age&quot;</span>]).count()</span><br><span class="line">    <span class="built_in">print</span>(usersAge)</span><br><span class="line"></span><br><span class="line">    plt.plot(usersAge.keys(),</span><br><span class="line">             usersAge.values,</span><br><span class="line">             label=<span class="string">&quot;用户年龄信息展示&quot;</span>,</span><br><span class="line">             linewidth=<span class="number">3</span>,</span><br><span class="line">             color=<span class="string">&quot;r&quot;</span>,</span><br><span class="line">             marker=<span class="string">&quot;o&quot;</span>,</span><br><span class="line">             markerfacecolor=<span class="string">&quot;blue&quot;</span>,</span><br><span class="line">             markersize=<span class="number">12</span>,</span><br><span class="line">             )</span><br><span class="line">    <span class="comment"># 图上添加文字</span></span><br><span class="line">    <span class="keyword">for</span> x,y <span class="keyword">in</span> <span class="built_in">zip</span>(usersAge.keys(),usersAge.values):</span><br><span class="line">        plt.text(x, y + <span class="number">10</span>, <span class="string">&quot;%.0f&quot;</span> %y, ha = <span class="string">&quot;center&quot;</span>, va=<span class="string">&quot;bottom&quot;</span>, fontsize=<span class="number">8</span> )</span><br><span class="line">    plt.xlabel(<span class="string">&quot;用户年龄&quot;</span>)</span><br><span class="line">    plt.ylabel(<span class="string">&quot;年龄段对应的人数&quot;</span>)</span><br><span class="line">    plt.title(<span class="string">&quot;用户年龄段人数统计&quot;</span>)</span><br><span class="line">    plt.show()</span><br><span class="line"><span class="keyword">if</span> __name__ == <span class="string">&quot;__main__&quot;</span>:</span><br><span class="line">    getUsers(<span class="string">&quot;C:\\Users\\要王冰冰抱抱\\Desktop\\Book-Crossings\\Book reviews\\Book reviews\\BX-Users.csv&quot;</span>)</span><br></pre></td></tr></table></figure>

<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br></pre></td><td class="code"><pre><span class="line">数据前5条记录为:</span><br><span class="line">   User-ID                            Location   Age</span><br><span class="line">0        1                  nyc, new york, usa   NaN</span><br><span class="line">1        2           stockton, california, usa  18.0</span><br><span class="line">2        3     moscow, yukon territory, russia   NaN</span><br><span class="line">3        4           porto, v.n.gaia, portugal  17.0</span><br><span class="line">4        5  farnborough, hants, united kingdom   NaN</span><br><span class="line">数据总条数为：</span><br><span class="line">User-ID     278858</span><br><span class="line">Location    278858</span><br><span class="line">Age         168096</span><br><span class="line">dtype: int64</span><br><span class="line">年龄的范围是：&lt;0.0,244.0&gt;</span><br><span class="line">Age</span><br><span class="line">0.0      416</span><br><span class="line">1.0      288</span><br><span class="line">2.0      105</span><br><span class="line">3.0       45</span><br><span class="line">4.0       28</span><br><span class="line">        ... </span><br><span class="line">230.0      1</span><br><span class="line">231.0      1</span><br><span class="line">237.0      1</span><br><span class="line">239.0      1</span><br><span class="line">244.0      1</span><br><span class="line">Name: Age, Length: 165, dtype: int64</span><br></pre></td></tr></table></figure>

<p><img src="image-20210705194746347.png" alt="image-20210705194746347"></p>
</li>
</ul>
<p>通过观察发现，<code>Age</code>列和<code>User-ID,Location</code>列数据条数不一致；<code>Age</code>列的取值范围不符合事实。</p>
<h5 id="Last-fm数据集"><a href="#Last-fm数据集" class="headerlink" title="Last.fm数据集"></a><code>Last.fm</code>数据集</h5><p><code>Last.fm</code>数据集是一个音乐推荐的数据集，包含了用户与用户之间的朋友关系，因此<strong>该数据集是一个具有用户社交网络信息的数据集</strong>。</p>
<ul>
<li><p><code>artists.dat</code></p>
<p>该文件包含了艺术家的<code>ID编号</code>，<code>姓名</code>，<code>Last.fm首页地址</code>和<code>图片地址</code>。</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"><span class="built_in">id</span>	name	url	pictureURL</span><br><span class="line">1	MALICE MIZER	http://www.last.fm/music/MALICE+MIZER	http://userserve-ak.last.fm/serve/252/10808.jpg</span><br><span class="line">2	Diary of Dreams	http://www.last.fm/music/Diary+of+Dreams	http://userserve-ak.last.fm/serve/252/3052066.jpg</span><br><span class="line">3	Carpathian Forest	http://www.last.fm/music/Carpathian+Forest	http://userserve-ak.last.fm/serve/252/40222717.jpg</span><br><span class="line">4	Moi dix Mois	http://www.last.fm/music/Moi+dix+Mois	http://userserve-ak.last.fm/serve/252/54697835.png</span><br><span class="line">5	Bella Morte	http://www.last.fm/music/Bella+Morte	http://userserve-ak.last.fm/serve/252/14789013.jpg</span><br><span class="line">6	Moonspell	http://www.last.fm/music/Moonspell	http://userserve-ak.last.fm/serve/252/2181591.jpg</span><br><span class="line">7	Marilyn Manson	http://www.last.fm/music/Marilyn+Manson	http://userserve-ak.last.fm/serve/252/2558217.jpg</span><br><span class="line">8	DIR EN GREY	http://www.last.fm/music/DIR+EN+GREY	http://userserve-ak.last.fm/serve/252/46968835.png</span><br></pre></td></tr></table></figure>

<p>数据共四列，使用<code>\t</code>分割。第<code>1</code>列为艺术家ID<code>id</code>，第<code>2</code>列为艺术家姓名<code>name</code>，第<code>3</code>列为用户Last.fm的个人首页<code>url</code>，第<code>4</code>列为图片链接<code>pictureURL</code>。示例：</p>
<p><code>ID为1的用户名字为MALICE MIZER，对应的Last.fm个人首页为http://www.last.fm/music/MALICE+MIZER，对应的图片链接为http://userserve-ak.last.fm/serve/252/10808.jpg</code></p>
</li>
<li><p><code>tags.dat</code></p>
<p>该文件包含了标签的ID和名字。</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">tagID	tagValue</span><br><span class="line">1	metal</span><br><span class="line">2	alternative metal</span><br><span class="line">3	goth rock</span><br><span class="line">4	black metal</span><br><span class="line">5	death metal</span><br><span class="line">6	industrial metal</span><br></pre></td></tr></table></figure>

<p>数据之间用<code>\t</code>分割。第<code>1</code>列为标签ID<code>tagID</code>，第<code>2</code>列为该ID对应的名字<code>tagValue</code>。</p>
</li>
<li><p><code>user_artists.dat</code></p>
<p>该文件包含了用户听过的艺术家音乐和对应的次数。</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line">userID	artistID	weight</span><br><span class="line">2	51	13883</span><br><span class="line">2	52	11690</span><br><span class="line">2	53	11351</span><br><span class="line">2	54	10300</span><br><span class="line">2	55	8983</span><br><span class="line">2	56	6152</span><br><span class="line">2	57	5955</span><br><span class="line">2	58	4616</span><br><span class="line">2	59	4337</span><br></pre></td></tr></table></figure>

<p>数据之间用<code>\t</code>分割，第<code>1</code>列为用户ID<code>userID</code>，第<code>2</code>列为艺术家ID<code>artistID</code>，第<code>3</code>列为次数<code>weight</code>。示例为：</p>
<p><code>ID为2的用户听过ID为51的艺术家的音乐13883次。</code></p>
</li>
<li><p><code>user_friends.dat</code></p>
<p>该文件包含了用户和对应用户的朋友关系。</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line">userID	friendID</span><br><span class="line">2	275</span><br><span class="line">2	428</span><br><span class="line">2	515</span><br><span class="line">2	761</span><br><span class="line">2	831</span><br><span class="line">2	909</span><br><span class="line">2	1209</span><br><span class="line">2	1210</span><br><span class="line">2	1230</span><br><span class="line">2	1327</span><br></pre></td></tr></table></figure>

<p>数据之间使用<code>\t</code>分割，第<code>1</code>列为用户ID<code>userID</code>，第<code>2</code>列为朋友的用户ID<code>friendID</code>。示例：</p>
<p><code>ID为2的用户的朋友的ID为275。</code></p>
</li>
<li><p><code>uses_taggedartists.dat</code></p>
<p>文件包含了用户为艺术家打标签的相关信息。</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line">userID	artistID	tagID	day	month	year</span><br><span class="line">2	52	13	1	4	2009</span><br><span class="line">2	52	15	1	4	2009</span><br><span class="line">2	52	18	1	4	2009</span><br><span class="line">2	52	21	1	4	2009</span><br><span class="line">2	52	41	1	4	2009</span><br><span class="line">2	63	13	1	4	2009</span><br><span class="line">2	63	14	1	4	2009</span><br><span class="line">2	63	23	1	4	2009</span><br><span class="line">2	63	40	1	4	2009</span><br></pre></td></tr></table></figure>

<p>数据之间用<code>\t</code>隔开，第<code>1</code>列为用户ID<code>userID</code>，第<code>2</code>列为艺术家ID<code>artistID</code>，第<code>3</code>列为标签ID<code>tagID</code>，第<code>4</code>列为日期<code>day</code>，第<code>5</code>列为月份<code>month</code>，第<code>6</code>列为年份<code>year</code>。示例：</p>
<p><code>ID为2的用户在2009年4月1日为ID为52的艺术家打上了ID为13的标签。</code></p>
</li>
<li><p><code>user_taggedartists-timestamps.dat</code></p>
<p>该文件与上个文件一致，只不过时间转换为时间戳的形式。</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">userID	artistID	tagID	timestamp</span><br><span class="line">2	52	13	1238536800000</span><br><span class="line">2	52	15	1238536800000</span><br><span class="line">2	52	18	1238536800000</span><br><span class="line">2	52	21	1238536800000</span><br><span class="line">2	52	41	1238536800000</span><br><span class="line">2	63	13	1238536800000</span><br><span class="line">2	63	14	1238536800000</span><br><span class="line">2	63	23	1238536800000</span><br></pre></td></tr></table></figure>

<p>数据之间用<code>\t</code>隔开，第<code>1</code>列为用户ID<code>userID</code>，第<code>2</code>列为艺术家ID<code>artistID</code>，第<code>3</code>列为标签ID<code>tagID</code>，第<code>4</code>列为时间戳<code>timestamp</code>。示例：</p>
<p><code>ID为2的用户在时间戳1238536800000为ID为52的艺术家打上了ID为13的标签。</code></p>
<blockquote>
<p>时间戳是从1970年1月1日开始经过的秒数。<code>user_taggedartists-timestamps.dat</code>中的时间戳为毫秒级，相当于秒级时间戳 × 1000。</p>
</blockquote>
<p>毫秒级时间戳<code>1238536800000</code>转换为秒级时间戳为<code>1238536800</code>，转换为时间是<code>2009-04-01 06:00:00</code>。</p>
<p>转换的代码为：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> datetime</span><br><span class="line">unix_ts = <span class="number">1238536800000</span></span><br><span class="line">t1 = datetime.datetime.fromtimestamp(unix_ts / <span class="number">1000</span>)</span><br><span class="line"><span class="built_in">print</span>(<span class="string">&quot;&#123;&#125; 转化为时间是：&#123;&#125;&quot;</span>.<span class="built_in">format</span>(unix_ts,t1))</span><br></pre></td></tr></table></figure>

<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">1238536800000 转化为时间是：2009-04-01 06:00:00</span><br></pre></td></tr></table></figure></li>
</ul>
<h5 id="FourSquare数据集"><a href="#FourSquare数据集" class="headerlink" title="FourSquare数据集"></a><code>FourSquare</code>数据集</h5><p><code>FourSquare</code>数据集是一家基于用户地理位置信息的手机服务网站，鼓励收集用户同他人分享自己当前所在地理位置等信息。</p>
<p>解压之后包含5个文件夹：<code>users.dat</code>，<code>venues.dat</code>，<code>chechins.dat</code>，<code>socialgraph.dat</code>和<code>ratings.dat</code>。</p>
<ul>
<li><p><code>users.dat</code></p>
<p>文件包含用户的家乡位置信息。</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">   <span class="built_in">id</span>    |      latitude      |      longitude      </span><br><span class="line">---------+--------------------+---------------------</span><br><span class="line">      19 |         46.7866719 |         -92.1004852</span><br><span class="line">  716344 |         29.7628844 |         -95.3830615</span><br><span class="line">       5 |          27.949436 |         -82.4651441</span><br><span class="line"> 1207670 |         32.7897222 |          35.5247222</span><br><span class="line"> 1076457 |          18.109581 |          -77.297508</span><br><span class="line">  175113 |         -6.9147444 |         107.6098111</span><br><span class="line">     322 |         45.6216318 |         -94.2069365</span><br></pre></td></tr></table></figure>

<p>第1行是列信息，第2行是分隔符，第3行开始是用户ID和对应的家乡位置。示例：</p>
<p><code>ID为19的用户家乡所在经度为46.7866719，纬度为-92.1004852</code>。</p>
</li>
<li><p><code>venues.dat</code></p>
<p>文件包含的是场馆的位置。</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line">   <span class="built_in">id</span>    |       latitude        |       longitude       </span><br><span class="line">---------+-----------------------+-----------------------</span><br><span class="line">  101759 |            45.5405832 |           -73.5965186</span><br><span class="line">  101762 |            45.5154736 |           -73.5643264</span><br><span class="line">  449060 |             38.962166 |            -94.604425</span><br><span class="line">   24869 |      41.8896190673815 |     -87.6258373260498</span><br><span class="line">     863 |            41.8857777 |            -87.627933</span><br><span class="line">  449061 |            39.2115262 |           -94.6466052</span><br><span class="line">  259886 |      53.3421225183013 |     -6.25521183013916</span><br><span class="line">  259885 |      53.3255418710418 |     -6.25190734863281</span><br><span class="line">  259884 |       53.349424158984 |     -6.33542060852051</span><br></pre></td></tr></table></figure>

<p>第1行是列信息，第2行是分隔符，第3行开始是场馆ID和对应的家乡位置。示例：</p>
<p><code>ID为101759、的用户家乡所在经度为45.5405832，纬度为-73.5965186</code>。</p>
</li>
<li><p><code>checkins.dat</code></p>
<p>文件包含的是用户在场馆的签到信息，每条签到消息都包含唯一的签到ID，用户ID和场馆ID。</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line">   <span class="built_in">id</span>    | user_id | venue_id |     latitude      |     longitude     |     created_at      </span><br><span class="line">---------+---------+----------+-------------------+-------------------+---------------------</span><br><span class="line">  984301 | 2041916 |     5222 |                   |                   | 2012-04-21 17:39:01</span><br><span class="line">  984222 |   15824 |     5222 |        38.8951118 |       -77.0363658 | 2012-04-21 17:43:47</span><br><span class="line">  984315 | 1764391 |     5222 |                   |                   | 2012-04-21 17:37:18</span><br><span class="line">  984234 |   44652 |     5222 |         33.800745 |         -84.41052 | 2012-04-21 17:43:43</span><br><span class="line">  984249 | 2146840 |     5222 |                   |                   | 2012-04-21 17:42:58</span><br><span class="line">  984268 | 2146843 |     5222 |                   |                   | 2012-04-21 17:42:38</span><br><span class="line">  984281 | 2146846 |     5222 |                   |                   | 2012-04-21 17:39:40</span><br><span class="line">  984291 |  105054 |     5222 |        45.5234515 |      -122.6762071 | 2012-04-21 17:39:22</span><br></pre></td></tr></table></figure>

<p>第1行是列信息，第2行是分隔符，第3行开始是签到信息。示例：</p>
<p><code>在2012-04-21 17:39:01，ID为2041916的用户在ID为5222的场馆进行了签到，签到ID为984301，签到的位置信息没有被记录。</code></p>
</li>
<li><p><code>socialgraph.dat</code></p>
<p>文件包含的是用户的社交关系信息。</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line"> first_user_id | second_user_id </span><br><span class="line">---------------+----------------</span><br><span class="line">             1 |             10</span><br><span class="line">            10 |              1</span><br><span class="line">             1 |             11</span><br><span class="line">            11 |              1</span><br><span class="line">             1 |             12</span><br><span class="line">            12 |              1</span><br><span class="line">             1 |             13</span><br><span class="line">            13 |              1</span><br><span class="line">             1 |             14</span><br><span class="line">            14 |              1</span><br><span class="line">             1 |             15</span><br></pre></td></tr></table></figure>

<p>第1行是列信息，第2行是分隔符，第3行开始是对应的社交关系信息。示例：</p>
<p><code>ID为19的用户的一个朋友是ID为10的用户</code>。</p>
</li>
<li><p><code>ratings.dat</code></p>
<p>文件包含用户对场馆的评分。</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line"> user_id | venue_id | rating </span><br><span class="line">---------+----------+--------</span><br><span class="line">       1 |        1 |      5</span><br><span class="line">       1 |       51 |      4</span><br><span class="line">       1 |       51 |      2</span><br><span class="line">       1 |       51 |      5</span><br><span class="line">       1 |       52 |      5</span><br><span class="line">       1 |       53 |      5</span><br><span class="line">       1 |       54 |      5</span><br><span class="line">       1 |       55 |      4</span><br><span class="line">       1 |       55 |      5</span><br><span class="line">       1 |       56 |      5</span><br></pre></td></tr></table></figure>

<p>第1行是列信息，第2行是分隔符，第3行开始是对应评分关系信息。示例：</p>
<p><code>ID为1的用户为ID为的场馆打了5分</code>。</p>
<p>查看评分的统计信息。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> matplotlib.pyplot <span class="keyword">as</span> plt</span><br><span class="line"><span class="keyword">import</span> pandas <span class="keyword">as</span> pd</span><br><span class="line"><span class="comment"># 显示中文标签</span></span><br><span class="line">plt.rcParams[<span class="string">&quot;font.sans-serif&quot;</span>] = [<span class="string">&#x27;SimHei&#x27;</span>]</span><br><span class="line"><span class="comment"># 正常显示负号</span></span><br><span class="line">plt.rcParams[<span class="string">&quot;axes.unicode_minus&quot;</span>] = <span class="literal">False</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">getRatings</span>(<span class="params">file_path</span>):</span><br><span class="line">    <span class="built_in">print</span>(<span class="string">&quot;file_path is : &#123;&#125;&quot;</span>.<span class="built_in">format</span>(file_path))</span><br><span class="line">    <span class="comment"># drop函数，删除第0行</span></span><br><span class="line">    events = pd.read_table(</span><br><span class="line">        file_path,</span><br><span class="line">        header=<span class="number">0</span>,</span><br><span class="line">        sep=<span class="string">&quot;|&quot;</span></span><br><span class="line">    ).drop([<span class="number">0</span>])</span><br><span class="line">    <span class="built_in">print</span>(<span class="string">&quot;前5条数据为:\n &#123;&#125;&quot;</span>.<span class="built_in">format</span>(events.head(<span class="number">5</span>)))</span><br><span class="line">    <span class="built_in">print</span>(<span class="string">&quot;events 的 key为： \n &#123;&#125;&quot;</span>.<span class="built_in">format</span>(events.keys()))</span><br><span class="line">    rateSer = events[<span class="string">&quot; rating &quot;</span>].groupby(events[<span class="string">&quot; rating &quot;</span>]).count()</span><br><span class="line">    <span class="built_in">print</span>(<span class="string">&quot;Event 的值有： \n &#123;&#125;&quot;</span>.<span class="built_in">format</span>(rateSer))</span><br><span class="line"></span><br><span class="line">    plt.axes(aspect=<span class="number">1</span>)</span><br><span class="line">    plt.pie(x=rateSer.values, labels=rateSer.keys(), autopct=<span class="string">&quot;%3.1f %%&quot;</span>)</span><br><span class="line">    plt.legend(bbox_to_anchor=(<span class="number">1.0</span>, <span class="number">1.0</span>))</span><br><span class="line">    plt.show()</span><br><span class="line"></span><br><span class="line"><span class="keyword">if</span> __name__ == <span class="string">&quot;__main__&quot;</span>:</span><br><span class="line">    getRatings(<span class="string">&quot;C:\\Users\\要王冰冰抱抱\\Desktop\\FourSquare\\ratings.dat&quot;</span>)</span><br></pre></td></tr></table></figure>

<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br></pre></td><td class="code"><pre><span class="line">file_path is : C:\Users\要王冰冰抱抱\Desktop\FourSquare\ratings.dat</span><br><span class="line">前5条数据为:</span><br><span class="line">     user_id    venue_id    rating </span><br><span class="line">1         1          1.0       5.0</span><br><span class="line">2         1         51.0       4.0</span><br><span class="line">3         1         51.0       2.0</span><br><span class="line">4         1         51.0       5.0</span><br><span class="line">5         1         52.0       5.0</span><br><span class="line">events 的 key为： </span><br><span class="line"> Index([<span class="string">&#x27; user_id &#x27;</span>, <span class="string">&#x27; venue_id &#x27;</span>, <span class="string">&#x27; rating &#x27;</span>], dtype=<span class="string">&#x27;object&#x27;</span>)</span><br><span class="line">Event 的值有： </span><br><span class="line">  rating </span><br><span class="line">2.0    1016504</span><br><span class="line">3.0     246642</span><br><span class="line">4.0     629216</span><br><span class="line">5.0     917218</span><br><span class="line">Name:  rating , dtype: int64</span><br><span class="line"></span><br><span class="line">Process finished with <span class="built_in">exit</span> code 0</span><br><span class="line"></span><br></pre></td></tr></table></figure>

<p><img src="image-20210705212631427.png" alt="image-20210705212631427"></p>
</li>
</ul>
<h4 id="第一个推荐系统"><a href="#第一个推荐系统" class="headerlink" title="第一个推荐系统"></a>第一个推荐系统</h4><h5 id="Netflix数据集"><a href="#Netflix数据集" class="headerlink" title="Netflix数据集"></a>Netflix数据集</h5><p>Netflix数据集解压之后包含以下文件：</p>
<ul>
<li><p>README</p>
<p>该文件是描述性文件，主要对数据集进行相关介绍，包括：包含哪些文件、每个文件表示的是什么内容、内容中的数据的含义。</p>
</li>
<li><p>movies_title.txt</p>
<p>该文件是电影的相关信息，文件有三列，每列之间以逗号隔开，数据形式如下：</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">#movies_title.txt</span></span><br><span class="line"></span><br><span class="line">1,2003,Dinosaur Planet</span><br><span class="line">2,2004,Isle of Man TT 2004 Review</span><br><span class="line">3,1997,Character</span><br><span class="line">4,1994,Paula Abdul<span class="string">&#x27;s Get Up &amp; Dance</span></span><br><span class="line"><span class="string">5,2004,The Rise and Fall of ECW</span></span><br><span class="line"><span class="string">6,1997,Sick</span></span><br><span class="line"><span class="string">7,1992,8 Man</span></span><br><span class="line"><span class="string">8,2004,What the #$*! Do We Know!?</span></span><br><span class="line"><span class="string">9,1991,Class of Nuke &#x27;</span>Em High 2</span><br><span class="line">10,2001,Fighter</span><br></pre></td></tr></table></figure>

<p>表示的含义是：电影ID，上映日期，电影名字。</p>
<p>数据集中包含的电影数目为：17770， 电影上映的日期范围是：1890 ~ 2005。</p>
</li>
<li><p>training_set.tar</p>
<p>该文件代表的是训练集，解压之后得到以每部电影 ID 为后缀命名的文件。</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># mv_0000001.txt</span></span><br><span class="line"></span><br><span class="line">1:</span><br><span class="line">1488844,3,2005-09-06</span><br><span class="line">822109,5,2005-05-13</span><br><span class="line">885013,4,2005-10-19</span><br><span class="line">30878,4,2005-12-26</span><br><span class="line">823519,3,2004-05-03</span><br><span class="line">893988,3,2005-11-17</span><br><span class="line">124105,4,2004-08-05</span><br><span class="line">1248029,3,2004-04-22</span><br><span class="line">1842128,4,2004-05-09</span><br><span class="line">2238063,3,2005-05-11</span><br><span class="line">1503895,4,2005-05-19</span><br><span class="line">2207774,5,2005-06-06</span><br><span class="line">2590061,3,2004-08-12</span><br><span class="line">2442,3,2004-04-14</span><br></pre></td></tr></table></figure>

<p>第一行代表电影的ID，以<code>:</code> 结尾。</p>
<p>从第二行开始，第一列表示的是用户 ID ，第二列表示用户评分， 第三列表示的是日期。</p>
<p><code>用户ID为1488844的用户对电影1的评分为3，评分日期为2005-09-06</code></p>
</li>
<li><p>qualifying.txt</p>
<p>该文件是Netflix提供的验证数据集，格式为电影ID 和其对应的用户ID及日期。</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># qualifying.txt</span></span><br><span class="line"></span><br><span class="line">1:</span><br><span class="line">1046323,2005-12-19</span><br><span class="line">1080030,2005-12-23</span><br><span class="line">1830096,2005-03-14</span><br><span class="line">368059,2005-05-26</span><br><span class="line">802003,2005-11-07</span><br><span class="line">513509,2005-07-04</span><br><span class="line">1086137,2005-09-21</span><br></pre></td></tr></table></figure>

<p>第一行为电影ID，从第二行开始为用户ID和日期。算法需要能够预测电影ID下对应用户对电影的评分。</p>
</li>
<li><p>probe.txt</p>
<p>该文件是Netflix提供的测试数据集，格式为电影ID和对应的用户ID。</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># probe.txt</span></span><br><span class="line"></span><br><span class="line">1:</span><br><span class="line">30878</span><br><span class="line">2647871</span><br><span class="line">1283744</span><br><span class="line">2488120</span><br><span class="line">317050</span><br><span class="line">1904905</span><br><span class="line">1989766</span><br></pre></td></tr></table></figure>

<p>可以使用该数据集测试算法。</p>
</li>
</ul>
<h5 id="第一个推荐系统-1"><a href="#第一个推荐系统-1" class="headerlink" title="第一个推荐系统"></a>第一个推荐系统</h5><p>获取所有用户并随机选取1000个。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> os</span><br><span class="line"><span class="keyword">import</span> json</span><br><span class="line"><span class="keyword">import</span> random</span><br><span class="line"><span class="keyword">import</span> math</span><br><span class="line"></span><br><span class="line"><span class="keyword">class</span> <span class="title class_">FirstRec</span>:</span><br><span class="line">    <span class="string">&quot;&quot;&quot;</span></span><br><span class="line"><span class="string">    初始化函数</span></span><br><span class="line"><span class="string">    filePath: 原始文件路径</span></span><br><span class="line"><span class="string">    seed: 产生随机数的种子</span></span><br><span class="line"><span class="string">    k: 选取的近邻用户个数</span></span><br><span class="line"><span class="string">    n_items: 为每个用户推荐的电影数</span></span><br><span class="line"><span class="string">    &quot;&quot;&quot;</span></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__init__</span>(<span class="params">self,file_path,seed,k,n_items</span>):</span><br><span class="line">        self.file_path = file_path</span><br><span class="line">        self.users_1000 = self.__select_1000_users()</span><br><span class="line">        self.seed = seed</span><br><span class="line">        self.k = k</span><br><span class="line">        self.n_items = n_items</span><br><span class="line">        self.train,self.test = self._load_and_split_data()</span><br><span class="line"></span><br><span class="line">    <span class="comment"># 获取所有用户并随机选取1000个</span></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__select_1000_users</span>(<span class="params">self</span>):</span><br><span class="line">        <span class="built_in">print</span>(<span class="string">&quot;随机选取1000个用户！&quot;</span>)</span><br><span class="line">        <span class="keyword">if</span> os.path.exists(<span class="string">&quot;data/train.json&quot;</span>) <span class="keyword">and</span> os.path.exists(<span class="string">&quot;data/test.json&quot;</span>) :</span><br><span class="line">            <span class="keyword">return</span> <span class="built_in">list</span>()</span><br><span class="line">        <span class="keyword">else</span>:</span><br><span class="line">            users = <span class="built_in">set</span>()</span><br><span class="line">            <span class="comment">#获取所有用户</span></span><br><span class="line">            <span class="keyword">for</span> file <span class="keyword">in</span> os.listdir(self.file_path):</span><br><span class="line">                one_path = <span class="string">&quot;&#123;&#125;/&#123;&#125;&quot;</span>.<span class="built_in">format</span>(self.file_path,file)</span><br><span class="line">                <span class="built_in">print</span>(<span class="string">&quot;&#123;&#125;&quot;</span>.<span class="built_in">format</span>(one_path))</span><br><span class="line">                <span class="keyword">with</span> <span class="built_in">open</span>(one_path, <span class="string">&quot;r&quot;</span>) <span class="keyword">as</span> fp:</span><br><span class="line">                    <span class="keyword">for</span> line <span class="keyword">in</span> fp.readlines():</span><br><span class="line">                        <span class="keyword">if</span> line.strip().endswith(<span class="string">&quot;:&quot;</span>):<span class="comment"># 删除line头尾的空格之后判断文件结尾是否为:</span></span><br><span class="line">                            <span class="keyword">continue</span></span><br><span class="line">                        userID, _, _ = line.split(<span class="string">&quot;,&quot;</span>)</span><br><span class="line">                        users.add(userID)</span><br><span class="line">            users_1000 = random.sample(<span class="built_in">list</span>(users),<span class="number">1000</span>)</span><br><span class="line">        <span class="built_in">print</span>(users_1000)</span><br><span class="line">        <span class="keyword">return</span> users_1000</span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">_load_and_split_data</span>(<span class="params">self</span>):</span><br><span class="line">        train = <span class="built_in">dict</span>()</span><br><span class="line">        test = <span class="built_in">dict</span>()</span><br><span class="line">        <span class="keyword">if</span> os.path.exists(<span class="string">&quot;data/train.json&quot;</span>) <span class="keyword">and</span> os.path.exists(<span class="string">&quot;data/test.json&quot;</span>):</span><br><span class="line">            <span class="built_in">print</span>(<span class="string">&quot;从文件中加载训练集和测试集&quot;</span>)</span><br><span class="line">            train = json.load(<span class="built_in">open</span>(<span class="string">&quot;data/train.json&quot;</span>))</span><br><span class="line">            test = json.load(<span class="built_in">open</span>(<span class="string">&quot;data/test.json&quot;</span>))</span><br><span class="line">            <span class="built_in">print</span>(<span class="string">&quot;从文件中加载数据完成&quot;</span>)</span><br><span class="line">        <span class="keyword">else</span>:</span><br><span class="line">            <span class="comment"># 设置产生随机数的种子，保证每次实验产生的随机结果一致</span></span><br><span class="line">            random.seed(self.seed)</span><br><span class="line">            <span class="keyword">for</span> file <span class="keyword">in</span> os.listdir(self.file_path):</span><br><span class="line">                one_path = <span class="string">&quot;&#123;&#125;/&#123;&#125;&quot;</span>.<span class="built_in">format</span>(self.file_path, file)</span><br><span class="line">                <span class="built_in">print</span>(<span class="string">&quot;&#123;&#125;&quot;</span>.<span class="built_in">format</span>(one_path))</span><br><span class="line">                <span class="keyword">with</span> <span class="built_in">open</span>(one_path, <span class="string">&quot;r&quot;</span>) <span class="keyword">as</span> fp:</span><br><span class="line">                    movieID = fp.readline().split(<span class="string">&quot;:&quot;</span>)[<span class="number">0</span>]</span><br><span class="line">                    <span class="keyword">for</span> line <span class="keyword">in</span> fp.readlines():</span><br><span class="line">                        <span class="keyword">if</span> line.endswith(<span class="string">&quot;:&quot;</span>):</span><br><span class="line">                            <span class="keyword">continue</span></span><br><span class="line">                        userID, rate, _ = line.split(<span class="string">&quot;,&quot;</span>)</span><br><span class="line">                        <span class="comment"># 判断用户是否在选择的1000个用户中</span></span><br><span class="line">                        <span class="keyword">if</span> userID <span class="keyword">in</span> self.users_1000:</span><br><span class="line">                            <span class="keyword">if</span> random.randint(<span class="number">1</span>,<span class="number">50</span>) == <span class="number">1</span>:</span><br><span class="line">                                test.setdefault(userID, &#123;&#125;)[movieID] = <span class="built_in">int</span>(rate)</span><br><span class="line">                            <span class="keyword">else</span>:</span><br><span class="line">                                train.setdefault(userID, &#123;&#125;)[movieID] = <span class="built_in">int</span>(rate)</span><br><span class="line">            <span class="built_in">print</span>(<span class="string">&quot;加载数据到 data/train.json 和 data/test.json&quot;</span>)</span><br><span class="line">            json.dump(train, <span class="built_in">open</span>(<span class="string">&quot;data/train.json&quot;</span>, <span class="string">&quot;w&quot;</span>))</span><br><span class="line">            json.dump(test, <span class="built_in">open</span>(<span class="string">&quot;data/test.json&quot;</span>, <span class="string">&quot;w&quot;</span>))</span><br><span class="line">            <span class="built_in">print</span>(<span class="string">&quot;加载数据完成&quot;</span>)</span><br><span class="line">        <span class="keyword">return</span> train,test</span><br></pre></td></tr></table></figure>

<p>选择相似用户。</p>
<ol>
<li><p>使用皮尔逊相关系数表示用户之间的相似度<br>$$<br>r=\frac{\sum_{i=1}^n (x_i-\overline{x})(y_i-\overline{y})}{\sqrt{\sum_{i=1}^n (x - x_i)^2}\sqrt{\sum_{i=1}^n (y - y_i)^2}}<br>$$</p>
<blockquote>
<p>皮尔逊相关系数是使用两个协方差除以两个变量的标准差得到的。当两个变量的方差都不为0时，相关系数才有意义。</p>
</blockquote>
<p>皮尔逊相关系数的取值范围是==[-1, 1]==。</p>
<p>当==r=1==时，两个变量完全正相关，当==r=-1==时，两个变量完全负相关。</p>
<p>由于直接计算皮尔逊相关系数需要对数据进行两次遍历，因此产生了能够近似计算皮尔逊相关系数的公式。<br>$$<br>r^{‘}=\frac{\sum_{i=1}^n x_iy_i-\frac{\sum_{i=1}^n x_i\sum_{i=1}^n y_i}{n}}{\sqrt{\sum_{i=1}^n x_i^2-\frac{(\sum_{i=1}^n x_i)^2}{n}}\sqrt{\sum_{i=1}^n y_i^2-\frac{(\sum_{i=1}^n y_i)^2}{n}}}<br>$$</p>
</li>
<li><p>代码实现</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">def</span> <span class="title function_">pearson</span>(<span class="params">self,rating1,rating2</span>):</span><br><span class="line">    sum_xy = <span class="number">0</span></span><br><span class="line">    sum_x = <span class="number">0</span></span><br><span class="line">    sum_y = <span class="number">0</span></span><br><span class="line">    sum_x2 = <span class="number">0</span></span><br><span class="line">    sum_y2 = <span class="number">0</span></span><br><span class="line">    num = <span class="number">0</span></span><br><span class="line">    <span class="keyword">for</span> key <span class="keyword">in</span> rating1.keys():</span><br><span class="line">        <span class="keyword">if</span> key <span class="keyword">in</span> rating2.keys():</span><br><span class="line">            num += <span class="number">1</span></span><br><span class="line">            x = rating1[key]</span><br><span class="line">            y = rating2[key]</span><br><span class="line">            sum_xy += x * y</span><br><span class="line">            sum_x += x</span><br><span class="line">            sum_y += y</span><br><span class="line">            sum_x2 += math.<span class="built_in">pow</span>(x,<span class="number">2</span>)</span><br><span class="line">            sum_y2 += math.<span class="built_in">pow</span>(y,<span class="number">2</span>)</span><br><span class="line">           <span class="comment">#print(sum_x,sum_y,sum_x2,sum_y2,sum_xy,num)</span></span><br><span class="line">    <span class="keyword">if</span> num == <span class="number">0</span>:</span><br><span class="line">        <span class="keyword">return</span> <span class="number">0</span></span><br><span class="line">    denominator = math.sqrt( sum_x2 - math.<span class="built_in">pow</span>(sum_x,<span class="number">2</span>) / num) * math.sqrt( sum_y2 - math.<span class="built_in">pow</span>(sum_y,<span class="number">2</span>) / num)</span><br><span class="line">    <span class="keyword">if</span> denominator == <span class="number">0</span>:</span><br><span class="line">        <span class="keyword">return</span> <span class="number">0</span></span><br><span class="line">    <span class="keyword">else</span>:</span><br><span class="line">        <span class="keyword">return</span> ( sum_xy - (sum_x * sum_y) / num ) / denominator</span><br></pre></td></tr></table></figure></li>
<li><p>为用户推荐</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">def</span> <span class="title function_">recommend</span>(<span class="params">self,userID</span>):</span><br><span class="line">    neighborUser = <span class="built_in">dict</span>()</span><br><span class="line">    <span class="keyword">for</span> user <span class="keyword">in</span> self.train.keys():</span><br><span class="line">        <span class="keyword">if</span> userID != user:</span><br><span class="line">            distance = self.pearson(self.train[userID],self.train[user])</span><br><span class="line">            neighborUser[user] = distance</span><br><span class="line">    newNU = <span class="built_in">sorted</span>(neighborUser.items(), key=<span class="keyword">lambda</span> k:k[<span class="number">1</span>],reverse=<span class="literal">True</span> )</span><br><span class="line">    <span class="comment"># 字典排序</span></span><br><span class="line">    movies = <span class="built_in">dict</span>()</span><br><span class="line">    <span class="keyword">for</span> (sim_user, sim) <span class="keyword">in</span> newNU[:self.k]:</span><br><span class="line">        <span class="keyword">for</span> movieID <span class="keyword">in</span> self.train[sim_user].keys():</span><br><span class="line">            movies.setdefault(movieID,<span class="number">0</span>)</span><br><span class="line">            movies[movieID] += sim * self.train[sim_user][movieID]</span><br><span class="line">    newMovies = <span class="built_in">sorted</span>(movies.items(), key= <span class="keyword">lambda</span>  k:k[<span class="number">1</span>],reverse=<span class="literal">True</span>)</span><br><span class="line">    <span class="keyword">return</span> newMovies</span><br></pre></td></tr></table></figure></li>
<li><p>分析效果</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br></pre></td><td class="code"><pre><span class="line">    <span class="keyword">def</span> <span class="title function_">evaluate</span>(<span class="params">self,num=<span class="number">300</span></span>):</span><br><span class="line">        <span class="built_in">print</span>(<span class="string">&quot;开始计算准确率&quot;</span>)</span><br><span class="line">        precisions = <span class="built_in">list</span>()</span><br><span class="line">        random.seed(<span class="number">10</span>)</span><br><span class="line">        <span class="keyword">for</span> userID <span class="keyword">in</span> random.sample(self.test.keys(),num):</span><br><span class="line">            hit = <span class="number">0</span></span><br><span class="line">            result = self.recommend(userID)[:self.n_items]</span><br><span class="line">            <span class="keyword">for</span> (item,rate) <span class="keyword">in</span> result:</span><br><span class="line">                <span class="keyword">if</span> item <span class="keyword">in</span> self.test[userID]:</span><br><span class="line">                    hit += <span class="number">1</span></span><br><span class="line">            precisions.append(hit/self.n_items)</span><br><span class="line">        <span class="keyword">return</span> <span class="built_in">sum</span>(precisions) / precisions.__len__()</span><br><span class="line"><span class="keyword">if</span> __name__ == <span class="string">&quot;__main__&quot;</span>:</span><br><span class="line">    file_path = <span class="string">&quot;./data/netflix/training_set&quot;</span></span><br><span class="line">    seed = <span class="number">30</span></span><br><span class="line">    k = <span class="number">15</span></span><br><span class="line">    n_items = <span class="number">20</span></span><br><span class="line">    f_rec = FirstRec(file_path,seed,k,n_items)</span><br><span class="line">    one = f_rec.train</span><br><span class="line">    result = f_rec.recommend(<span class="string">&quot;897417&quot;</span>)</span><br><span class="line">    <span class="built_in">print</span>(result)</span><br><span class="line"></span><br><span class="line">    <span class="built_in">print</span>(<span class="string">&quot;算法的推荐准确率为：&#123;&#125;&quot;</span>.<span class="built_in">format</span>(f_rec.evaluate()))</span><br></pre></td></tr></table></figure></li>
</ol>
<h4 id="数据预处理"><a href="#数据预处理" class="headerlink" title="数据预处理"></a>数据预处理</h4><h5 id="数据标准化"><a href="#数据标准化" class="headerlink" title="数据标准化"></a>数据标准化</h5><ol>
<li><p>==Min-Max标准化==</p>
<p>==Min-Max标准化==是指对原始数据进行线性变换，将值映射到[0,1]之间。</p>
<p>计算公式为：<br>$$<br>x^{‘}=\frac{x-x_{min}}{x_{max}-x_{xmin}}<br>$$</p>
</li>
<li><p>==Z-Score标准化==</p>
<p>==Z-Score==也叫==Standard Score，即标准分数==，==Z-Score标准化==是指对原始数据的均值和标准差进行数据的标准化。</p>
<p>计算公式为：<br>$$<br>x_{‘}=\frac{x-\mu}{\sigma}<br>$$</p>
</li>
<li><p>==小数定标（Decimal scaling）标准化==</p>
<p>==小数定标标准化==是指：通过移动小数点的位置进行数据的标准化。小数点移动的位数取决于原始数据中的最大绝对值。</p>
<p>计算公式为：<br>$$<br>x^{‘}=\frac{x}{10^j}<br>$$<br>==j==表示满足条件的最小整数。</p>
<p>例如，一组数据为[-309, -10, -43, 87, 344, 970]，绝对值最大的是970，因此令==j=3==即用==1000==除每个值。</p>
</li>
<li><p>==均值归一法==</p>
<p>==均值归一化==是指通过原始数据中的均值、最大值和最小值进行数据的标准化。</p>
<p>计算公式为：<br>$$<br>x^{‘}=\frac{x-\mu}{x_{max}-x_{min}}<br>$$</p>
</li>
<li><p>==向量归一法==</p>
<p>==向量归一法==是指通过原始数据的每个值除以所有数据之和来进行数据的标准化。</p>
<p>计算公式为：<br>$$<br>x^{‘}=\frac{x}{\sum_{i=1}^n x_i}<br>$$</p>
</li>
<li><p>==指数转换==</p>
<p>==指数转换==是指通过原始数据的值进行相应的指数函数变换来进行数据的标准化。</p>
<p>常见的指数转换常见的函数方法有==lg函数==，==Softmax函数==，==Sigmoid函数==。</p>
<p>==lg函数==对应的计算公式为：<br>$$<br>x_{‘}=\frac{lg(x)}{lg(x_{max})}<br>$$<br>==Softmax函数==对应的计算公式为：<br>$$<br>x_{‘}=\frac{e^x}{\sum_{i=1}^{x_i}}<br>$$<br>==Sigmoid函数==对应的计算公式为：<br>$$<br>x^{‘}=\frac{1}{1+e^{-x}}<br>$$</p>
</li>
</ol>
<p>代码实现上述的标准化。</p>
<ol start="7">
<li><p>dsafafafasf</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br><span class="line">101</span><br><span class="line">102</span><br><span class="line">103</span><br><span class="line">104</span><br><span class="line">105</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="keyword">import</span> math</span><br><span class="line"></span><br><span class="line"><span class="keyword">class</span> <span class="title class_">DataNorm</span>:</span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__init__</span>(<span class="params">self</span>):</span><br><span class="line">        self.arr = [<span class="number">1</span>, <span class="number">2</span>, <span class="number">3</span>, <span class="number">4</span>, <span class="number">5</span>, <span class="number">6</span>, <span class="number">7</span>, <span class="number">8</span>, <span class="number">9</span>]</span><br><span class="line">        self.x_max = <span class="built_in">max</span>(self.arr)</span><br><span class="line">        self.x_min = <span class="built_in">min</span>(self.arr)</span><br><span class="line">        self.x_mean = <span class="built_in">sum</span>(self.arr) / <span class="built_in">len</span>(self.arr) <span class="comment"># 均值</span></span><br><span class="line">        self.x_std = np.std(self.arr) <span class="comment">#标准差</span></span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">Min_Max</span>(<span class="params">self</span>):</span><br><span class="line">        arr_ = <span class="built_in">list</span>()</span><br><span class="line">        <span class="keyword">for</span> x <span class="keyword">in</span> self.arr:</span><br><span class="line">            <span class="comment"># round(x, 4) 表示对 x 保留 4 位小数</span></span><br><span class="line">            arr_.append(</span><br><span class="line">                <span class="built_in">round</span>(</span><br><span class="line">                (x-self.x_min) / (self.x_max - self.x_min) ,<span class="number">4</span></span><br><span class="line">                )</span><br><span class="line">            )</span><br><span class="line">        <span class="built_in">print</span>(<span class="string">&quot;经过Min_Max标准化的数据为：\n&#123;&#125;&quot;</span>.<span class="built_in">format</span>(arr_))</span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">Z_Score</span>(<span class="params">self</span>):</span><br><span class="line">        arr_ = <span class="built_in">list</span>()</span><br><span class="line">        <span class="keyword">for</span> x <span class="keyword">in</span> self.arr:</span><br><span class="line">            arr_.append(</span><br><span class="line">                <span class="built_in">round</span>(</span><br><span class="line">                    (x - self.x_mean) / self.x_std ,<span class="number">4</span></span><br><span class="line">                )</span><br><span class="line">            )</span><br><span class="line">        <span class="built_in">print</span>(<span class="string">&quot;经过Z-Score标准化的数据为：\n&#123;&#125;&quot;</span>.<span class="built_in">format</span>(arr_))</span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">Decimal_Scaling</span>(<span class="params">self</span>):</span><br><span class="line">        arr_ = <span class="built_in">list</span>()</span><br><span class="line">        j = <span class="number">1</span></span><br><span class="line">        x_max = <span class="built_in">max</span>([<span class="built_in">abs</span>(one) <span class="keyword">for</span> one <span class="keyword">in</span> self.arr])</span><br><span class="line">        <span class="keyword">while</span> x_max / <span class="number">10</span> &gt;=<span class="number">1.0</span>:</span><br><span class="line">            j += <span class="number">1</span></span><br><span class="line">            x_max = x_max /<span class="number">10</span></span><br><span class="line">        <span class="keyword">for</span> x <span class="keyword">in</span> self.arr:</span><br><span class="line">            arr_.append(</span><br><span class="line">                <span class="built_in">round</span>(</span><br><span class="line">                    x / math.<span class="built_in">pow</span>(<span class="number">10</span>, j) ,<span class="number">4</span></span><br><span class="line">                )</span><br><span class="line"></span><br><span class="line">            )</span><br><span class="line">        <span class="built_in">print</span>(<span class="string">&quot;经过Decimal Scaling标准化的数据为：\n&#123;&#125;&quot;</span>.<span class="built_in">format</span>(arr_))</span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">Mean</span>(<span class="params">self</span>):</span><br><span class="line">        arr_ = <span class="built_in">list</span>()</span><br><span class="line">        <span class="keyword">for</span> x <span class="keyword">in</span> self.arr:</span><br><span class="line">            arr_.append(</span><br><span class="line">                <span class="built_in">round</span>(</span><br><span class="line">                    (x - self.x_mean) / (self.x_max - self.x_min) ,<span class="number">4</span></span><br><span class="line">                )</span><br><span class="line">            )</span><br><span class="line">        <span class="built_in">print</span>(<span class="string">&quot;经过均值标准化的数据为：\n&#123;&#125;&quot;</span>.<span class="built_in">format</span>(arr_))</span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">Vector</span>(<span class="params">self</span>):</span><br><span class="line">        arr_ = <span class="built_in">list</span>()</span><br><span class="line">        <span class="keyword">for</span> x <span class="keyword">in</span> self.arr:</span><br><span class="line">            arr_.append(</span><br><span class="line">                <span class="built_in">round</span>(</span><br><span class="line">                x / <span class="built_in">sum</span>(self.arr) ,<span class="number">4</span></span><br><span class="line">                )</span><br><span class="line">            )</span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">exponential</span>(<span class="params">self</span>):</span><br><span class="line">        arr_1 = <span class="built_in">list</span>()</span><br><span class="line">        <span class="keyword">for</span> x <span class="keyword">in</span> self.arr:</span><br><span class="line">            arr_1.append(</span><br><span class="line">                <span class="built_in">round</span>(</span><br><span class="line">                    (math.log10(x)) / (math.log10(self.x_max)) ,<span class="number">4</span></span><br><span class="line">                )</span><br><span class="line">            )</span><br><span class="line">        <span class="built_in">print</span>(<span class="string">&quot;经过指数转换法（lg）标准化的数据为：\n&#123;&#125;&quot;</span>.<span class="built_in">format</span>(arr_1))</span><br><span class="line"></span><br><span class="line">        arr_2 = <span class="built_in">list</span>()</span><br><span class="line">        sum_e = <span class="built_in">sum</span>([math.exp(one) <span class="keyword">for</span> one <span class="keyword">in</span> self.arr] )</span><br><span class="line">        <span class="keyword">for</span> x <span class="keyword">in</span> self.arr:</span><br><span class="line">            arr_2.append(</span><br><span class="line">                <span class="built_in">round</span>(</span><br><span class="line">                    <span class="built_in">round</span>(</span><br><span class="line">                        math.exp(x) / sum_e ,<span class="number">4</span></span><br><span class="line">                    )</span><br><span class="line">                )</span><br><span class="line">            )</span><br><span class="line">        <span class="built_in">print</span>(<span class="string">&quot;经过指数转换法（SoftMax）标准化的数据为：\n&#123;&#125;&quot;</span>.<span class="built_in">format</span>(arr_2))</span><br><span class="line"></span><br><span class="line">        arr_3 = <span class="built_in">list</span>()</span><br><span class="line">        <span class="keyword">for</span> x <span class="keyword">in</span> self.arr:</span><br><span class="line">            arr_3.append(</span><br><span class="line">                <span class="built_in">round</span>(</span><br><span class="line">                <span class="number">1</span> / (<span class="number">1</span> + math.exp(-x)) ,<span class="number">4</span></span><br><span class="line">                )</span><br><span class="line">            )</span><br><span class="line">        <span class="built_in">print</span>(<span class="string">&quot;经过指数转换法（Sigmoid）标准化的数据为：\n&#123;&#125;&quot;</span>.<span class="built_in">format</span>(arr_3))</span><br><span class="line"></span><br><span class="line"><span class="keyword">if</span> __name__ == <span class="string">&quot;__main__&quot;</span>:</span><br><span class="line">    dn = DataNorm()</span><br><span class="line">    dn.Min_Max()</span><br><span class="line">    dn.Z_Score()</span><br><span class="line">    dn.Decimal_Scaling()</span><br><span class="line">    dn.Mean()</span><br><span class="line">    dn.Vector()</span><br><span class="line">    dn.exponential()</span><br></pre></td></tr></table></figure>

<p>标准化结果如下：</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line">经过Min_Max标准化的数据为：</span><br><span class="line">[0.0, 0.125, 0.25, 0.375, 0.5, 0.625, 0.75, 0.875, 1.0]</span><br><span class="line">经过Z-Score标准化的数据为：</span><br><span class="line">[-1.5492, -1.1619, -0.7746, -0.3873, 0.0, 0.3873, 0.7746, 1.1619, 1.5492]</span><br><span class="line">经过Decimal Scaling标准化的数据为：</span><br><span class="line">[0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9]</span><br><span class="line">经过均值标准化的数据为：</span><br><span class="line">[-0.5, -0.375, -0.25, -0.125, 0.0, 0.125, 0.25, 0.375, 0.5]</span><br><span class="line">经过指数转换法（lg）标准化的数据为：</span><br><span class="line">[0.0, 0.3155, 0.5, 0.6309, 0.7325, 0.8155, 0.8856, 0.9464, 1.0]</span><br><span class="line">经过指数转换法（SoftMax）标准化的数据为：</span><br><span class="line">[0, 0, 0, 0, 0, 0, 0, 0, 1]</span><br><span class="line">经过指数转换法（Sigmoid）标准化的数据为：</span><br><span class="line">[0.7311, 0.8808, 0.9526, 0.982, 0.9933, 0.9975, 0.9991, 0.9997, 0.9999]</span><br></pre></td></tr></table></figure></li>
</ol>
<h5 id="数据离散化（代码未吃透）"><a href="#数据离散化（代码未吃透）" class="headerlink" title="数据离散化（代码未吃透）"></a>数据离散化（代码未吃透）</h5><p>数据离散化（也叫数据分组）是指将连续的数据进行分组，使其变为一段离散化的区间。</p>
<p>离散化算法也分为有监督算法和无监督算法。</p>
<ol>
<li><p>等宽分组</p>
</li>
<li><p>等频分组</p>
</li>
<li><p>单变量分组</p>
</li>
<li><p>基于信息熵分组</p>
<p>香农（Shannon）被称为“信息论之父”，==信息是用来消除随机不确定性的东西==，即==衡量信息量的大小就看这个信息消除不确定性的程度==。</p>
<p>信息量的大小和事件发生的概率成反比，信息量可以表示为：<br>$$<br>l(x) = -log_2 p(x)<br>$$<br>==熵==是在结果出来之前对可能产生的信息量的期望——考虑该随机变量的所有可能的取值，即所有可能发生事件所带来的信息量的期望。<br>$$<br>E(x) = -\sum_{i=1}^n p(x_i)log_2 p(x_i)<br>$$<br>按照随机变量的所有可能取值划分数据的==总熵E==是所有事件的==熵==的加权平均：<br>$$<br>E = \sum_{i=1}^n w_iE_i<br>$$<br>==$w_i=m_i/m$是第$i$个事件出现的比例，$m_i$是第$i$个可能取值出现的次数，$m$是所有取值出现的总次数。==</p>
<blockquote>
<p>熵表示样本集合的不确定性。熵越大，则样本的不确定性越大。</p>
</blockquote>
<p>基于信息熵进行数据分组的具体做法是：</p>
<ol>
<li>对属性A的所有取值从小到大排序</li>
<li>遍历属性$A$的每个值$V_i$，将属性$A$的值分为两个区间$S_1$、$S_2$，使得将其作为分隔点划分数据集后的熵$S$最小，熵$S$的计算方式如上公式。</li>
<li>当划分后的熵大于设置的阈值且小于指定的数据分组个数时，递归对$S_1$、$S_2$执行步骤2中的划分。</li>
</ol>
<p> 基于信息熵的数据离散化算法是有监督学习算法。</p>
<p>==表1 用户最近点击的20个商品的价格与是否加入购物车对应关系==</p>
<table>
<thead>
<tr>
<th align="center">价格</th>
<th align="center">标签</th>
<th align="center">价格</th>
<th align="center">标签</th>
<th align="center">价格</th>
<th align="center">标签</th>
<th align="center">价格</th>
<th align="center">标签</th>
</tr>
</thead>
<tbody><tr>
<td align="center">56</td>
<td align="center">1</td>
<td align="center">641</td>
<td align="center">1</td>
<td align="center">10</td>
<td align="center">1</td>
<td align="center">2398</td>
<td align="center">1</td>
</tr>
<tr>
<td align="center">87</td>
<td align="center">1</td>
<td align="center">63</td>
<td align="center">0</td>
<td align="center">9</td>
<td align="center">0</td>
<td align="center">592</td>
<td align="center">1</td>
</tr>
<tr>
<td align="center">129</td>
<td align="center">0</td>
<td align="center">2764</td>
<td align="center">1</td>
<td align="center">88</td>
<td align="center">1</td>
<td align="center">561</td>
<td align="center">1</td>
</tr>
<tr>
<td align="center">23</td>
<td align="center">0</td>
<td align="center">2323</td>
<td align="center">0</td>
<td align="center">222</td>
<td align="center">0</td>
<td align="center">764</td>
<td align="center">0</td>
</tr>
<tr>
<td align="center">342</td>
<td align="center">1</td>
<td align="center">453</td>
<td align="center">1</td>
<td align="center">97</td>
<td align="center">0</td>
<td align="center">121</td>
<td align="center">1</td>
</tr>
</tbody></table>
<p>基于信息熵额数据离散化——新建类并加载数据</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="keyword">import</span> math</span><br><span class="line"></span><br><span class="line"><span class="keyword">class</span> <span class="title class_">DIscrete_By_Entropy</span>:</span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__init__</span>(<span class="params">self, group, threshold</span>):</span><br><span class="line">        self.max_group = group <span class="comment"># 最大分组数</span></span><br><span class="line">        self.min_info_threshold = threshold <span class="comment"># 停止划分的最小熵</span></span><br><span class="line">        self.result = <span class="built_in">dict</span>()</span><br><span class="line"></span><br><span class="line">    <span class="comment">#加载数据</span></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">load_data</span>(<span class="params">self</span>):</span><br><span class="line">        data = np.array(</span><br><span class="line">            [</span><br><span class="line">            [<span class="number">56</span>, <span class="number">1</span>],  [<span class="number">87</span>, <span class="number">1</span>], [<span class="number">129</span>, <span class="number">0</span>],  [<span class="number">23</span>, <span class="number">0</span>],   [<span class="number">342</span>, <span class="number">1</span>],</span><br><span class="line">            [<span class="number">641</span>, <span class="number">1</span>], [<span class="number">63</span>, <span class="number">0</span>], [<span class="number">2764</span>, <span class="number">1</span>], [<span class="number">2323</span>, <span class="number">0</span>], [<span class="number">453</span>, <span class="number">1</span>],</span><br><span class="line">            [<span class="number">10</span>, <span class="number">1</span>],  [<span class="number">9</span>, <span class="number">0</span>],  [<span class="number">88</span>, <span class="number">1</span>],   [<span class="number">222</span>, <span class="number">0</span>],  [<span class="number">97</span>, <span class="number">0</span>],</span><br><span class="line">            [<span class="number">2398</span>, <span class="number">1</span>], [<span class="number">592</span>, <span class="number">1</span>], [<span class="number">561</span>, <span class="number">1</span>], [<span class="number">764</span>, <span class="number">0</span>], [<span class="number">121</span>, <span class="number">1</span>],</span><br><span class="line">            ]</span><br><span class="line">        )</span><br><span class="line">        <span class="keyword">return</span> data</span><br></pre></td></tr></table></figure>

<p>计算数据的信息熵。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 计算按照数据指定数据分组后的香农熵</span></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">cal_Entropy</span>(<span class="params">self, data</span>):</span><br><span class="line">    numData = <span class="built_in">len</span>(data)</span><br><span class="line">    labelCounts = &#123;&#125;</span><br><span class="line">    <span class="keyword">for</span> feature <span class="keyword">in</span> data:</span><br><span class="line">        <span class="built_in">print</span>(feature)</span><br><span class="line">        oneLabel = feature[-<span class="number">1</span>]</span><br><span class="line">        labelCounts.setdefault(oneLabel, <span class="number">0</span>)</span><br><span class="line">        labelCounts[oneLabel] += <span class="number">1</span></span><br><span class="line">    shannoEnt = <span class="number">0.0</span></span><br><span class="line">    <span class="keyword">for</span> key <span class="keyword">in</span> labelCounts:</span><br><span class="line">        prob = <span class="built_in">float</span>(labelCounts[key]) / numData</span><br><span class="line">        shannoEnt -= prob * math.log(prob, <span class="number">2</span>)</span><br><span class="line">    <span class="keyword">return</span> shannoEnt</span><br></pre></td></tr></table></figure>

<p>分割数据集。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 按照调和信息熵最小化原则分割数据集</span></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">split</span>(<span class="params">self, data</span>):</span><br><span class="line">    <span class="comment"># inf为正无穷大</span></span><br><span class="line">    min_Entropy = np.inf</span><br><span class="line">    <span class="comment"># 记录最终分割索引</span></span><br><span class="line">    index = -<span class="number">1</span></span><br><span class="line">    <span class="comment"># 按照第一列对数据进行排序</span></span><br><span class="line">    sortData = data[np.argsort(data[:, <span class="number">0</span>])]</span><br><span class="line">    <span class="comment"># 初始化最终分割数据后的熵</span></span><br><span class="line">    lastE1, lastE2 = -<span class="number">1</span>, -<span class="number">1</span></span><br><span class="line">    <span class="comment"># 返回的数据结构，包含数据和对应的熵</span></span><br><span class="line">    S1 = <span class="built_in">dict</span>()</span><br><span class="line">    S2 = <span class="built_in">dict</span>()</span><br><span class="line">    <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(<span class="built_in">len</span>(sortData)):</span><br><span class="line">        <span class="comment"># 分割数据集</span></span><br><span class="line">        splitData1, splitData2 = sortData[: i +<span class="number">1</span>] ,sortData[i + <span class="number">1</span> :]</span><br><span class="line">        entropy1, entropy2 = (</span><br><span class="line">            self.cal_Entropy(splitData1),</span><br><span class="line">            self.cal_Entropy(splitData2),</span><br><span class="line">        )</span><br><span class="line">        <span class="comment"># 计算信息熵</span></span><br><span class="line">        entropy = entropy1 * <span class="built_in">len</span>(splitData1) / <span class="built_in">len</span>(sortData) + entropy2 * <span class="built_in">len</span>(splitData2) / <span class="built_in">len</span>(sortData)</span><br><span class="line">        <span class="comment"># 如果调和平均熵小于最小值</span></span><br><span class="line">        <span class="keyword">if</span> entropy &lt; min_Entropy:</span><br><span class="line">            min_Entropy = entropy</span><br><span class="line">            index = i</span><br><span class="line">            lastE1 = entropy1</span><br><span class="line">            lastE2 = entropy2</span><br><span class="line">    S1[<span class="string">&quot;entropy&quot;</span>] = lastE1</span><br><span class="line">    S1[<span class="string">&quot;data&quot;</span>] = sortData[: index + <span class="number">1</span>]</span><br><span class="line">    S2[<span class="string">&quot;entropy&quot;</span>] = lastE2</span><br><span class="line">    S2[<span class="string">&quot;data&quot;</span>] = sortData[index + <span class="number">1</span> :]</span><br><span class="line">    <span class="keyword">return</span> S1, S2, min_Entropy</span><br></pre></td></tr></table></figure>

<p>数据离散化。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br></pre></td><td class="code"><pre><span class="line">    <span class="comment"># 数据离散化</span></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">train</span>(<span class="params">self, data</span>):</span><br><span class="line">        <span class="comment"># 需要遍历的key</span></span><br><span class="line">        needSplitKey = [<span class="number">0</span>]</span><br><span class="line">        <span class="comment"># 将整个数据作为一组</span></span><br><span class="line">        self.result.setdefault(<span class="number">0</span>, &#123;&#125;)</span><br><span class="line">        self.result[<span class="number">0</span>][<span class="string">&quot;entropy&quot;</span>] = np.inf</span><br><span class="line">        self.result[<span class="number">0</span>][<span class="string">&quot;data&quot;</span>] = data</span><br><span class="line">        group = <span class="number">1</span></span><br><span class="line">        <span class="keyword">for</span> key <span class="keyword">in</span> needSplitKey:</span><br><span class="line">            S1, S2, entropy = self.split(self.result[key][<span class="string">&quot;data&quot;</span>])</span><br><span class="line">            <span class="comment"># 如果满足条件</span></span><br><span class="line">            <span class="keyword">if</span> entropy &gt; self.min_info_threshold <span class="keyword">and</span> group &lt; self.max_group:</span><br><span class="line">                self.result[key] = S1</span><br><span class="line">                newKey = <span class="built_in">max</span>(self.result.keys()) + <span class="number">1</span></span><br><span class="line">                self.result[newKey] = S2</span><br><span class="line">                needSplitKey.extend([key])</span><br><span class="line">                needSplitKey.extend([newKey])</span><br><span class="line">                group += <span class="number">1</span></span><br><span class="line">            <span class="keyword">else</span>:</span><br><span class="line">                <span class="keyword">break</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">if</span> __name__ == <span class="string">&quot;__main__&quot;</span>:</span><br><span class="line">    dbe = DIscrete_By_Entropy(group=<span class="number">6</span>, threshold=<span class="number">0.5</span>)</span><br><span class="line">    data = dbe.load_data()</span><br><span class="line">    dbe.train(data)</span><br><span class="line">    <span class="built_in">print</span>(<span class="string">&quot;result is \n&#123;&#125;&quot;</span>.<span class="built_in">format</span>(dbe.result))</span><br></pre></td></tr></table></figure>

<p>计算结果。</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br></pre></td><td class="code"><pre><span class="line">result is </span><br><span class="line">&#123;0: &#123;<span class="string">&#x27;entropy&#x27;</span>: 0.9910760598382222, <span class="string">&#x27;data&#x27;</span>: array([[  9,   0],</span><br><span class="line">       [ 10,   1],</span><br><span class="line">       [ 23,   0],</span><br><span class="line">       [ 56,   1],</span><br><span class="line">       [ 63,   0],</span><br><span class="line">       [ 87,   1],</span><br><span class="line">       [ 88,   1],</span><br><span class="line">       [ 97,   0],</span><br><span class="line">       [121,   1]])&#125;, 1: &#123;<span class="string">&#x27;entropy&#x27;</span>: 0.7642045065086203, <span class="string">&#x27;data&#x27;</span>: array([[ 342,    1],</span><br><span class="line">       [ 453,    1],</span><br><span class="line">       [ 561,    1],</span><br><span class="line">       [ 592,    1],</span><br><span class="line">       [ 641,    1],</span><br><span class="line">       [ 764,    0],</span><br><span class="line">       [2323,    0],</span><br><span class="line">       [2398,    1],</span><br><span class="line">       [2764,    1]])&#125;, 2: &#123;<span class="string">&#x27;entropy&#x27;</span>: 0.0, <span class="string">&#x27;data&#x27;</span>: array([[129,   0],</span><br><span class="line">       [222,   0]])&#125;&#125;</span><br></pre></td></tr></table></figure></li>
</ol>
<h5 id="数据抽样"><a href="#数据抽样" class="headerlink" title="数据抽样"></a>数据抽样</h5><p>数据抽样也叫数据采样。</p>
<p>在统计学中，抽样的目的是实现数据的调查和分析。</p>
<p>在数据挖掘中，抽样的目的是压缩数据量，减少数据挖掘算法的资源开销。</p>
<p>在数据挖掘中，抽样主要是从海量数据集中产生==训练集（Train Set）==、==测试集（Test Set）==、==验证集（Validation Set）==。</p>
<p>训练集、测试集和验证集的区别：</p>
<ul>
<li>训练集用来进行模型训练。</li>
<li>测试集用来衡量模型的一些统计指标，如==准确率==、==召回率==等。在训练模型过程中不允许使用测试集，否则会出现过拟合现象。</li>
<li>验证集用来验证模型、辅助构建模型。在使用机器学习算法时，验证集是可选的。、</li>
</ul>
<p>常见的数据采样的方法有：</p>
<ol>
<li>随机抽样</li>
<li>分层抽样</li>
<li>系统抽样</li>
<li>渐进抽样</li>
</ol>
<h5 id="数据降维"><a href="#数据降维" class="headerlink" title="数据降维"></a>数据降维</h5><p>当特征维度达到几千维时，模型训练将会耗费大量的时间。除此之外，特征过多还会出现==多重共线性==、==稀疏性==的问题。</p>
<p>降维分为线性降维和非线性降维。</p>
<p>线性降维：==主成分分析（PCA）==、==线性判别分析（LDA）==。</p>
<p>非线性降维：==基于核函数的KPCA、KICA、KDA==和==基于特征值的ISOMAP、LLE、LE、LPP、LTSA、MVU等==。</p>
<p>==主成分分析（PCA）==</p>
<p>主成分分析（Principal Component Analysis, PCA）是一种统计方法。通过正交变换，将一组可能存在相关性的变量转换为一组线性不相关的变量，转换后的这组变量称为==主成分==。</p>
<p>PCA的核心知识点是：==协方差矩阵==和==特征值分解==。</p>
<p>相关概念：</p>
<ul>
<li><p>均值：一组数据的平均水平。计算公式为：<br>$$<br>\overline{x}=\frac{\sum_{i=1}^{n} x_i}{n}<br>$$</p>
</li>
<li><p>标准差：一组数据的离散程度。计算公式为：<br>$$<br>S=\sqrt{\frac{\sum_{i=1}^n (x_i-\overline{x}^2)}{n-1}}<br>$$</p>
</li>
<li><p>方差：标准差的平方，表示的也是一组数据的离散程度。计算公式为：<br>$$<br>S^2=\frac{\sum_{i=1}^{n}(x_i-\overline{x}^2)}{n-1}<br>$$</p>
</li>
<li><p>协方差：表示的是两个随机变量x、y之间的相互关系。计算公式为：<br>$$<br>cov(x,y)=E([x-E(x)][y-E(y)])<br>$$</p>
<blockquote>
<p>其中，$E(x)$是变量$x$的数学期望，经常用变量$x$的平均值代替。</p>
</blockquote>
<p>协方差：大于0表示两个随机变量==正相关==，等于0表示两个随机变量==不相关==，小于0表示两个随机变量==负相关==。</p>
<p>协方差矩阵：协方差只能表示两个随机变量之间的关系。如果有多个随机变量，则需要使用协方差矩阵。</p>
<p>假设有三个随机变量$x,y,z$，那么对应的协方差矩阵为：<br>$$<br>C=\begin{pmatrix}cov(x,x) &amp;cov(x,y)&amp; cov(x,z)\ cov(y,x) &amp; cov(y,y) &amp;cov(y,z)\cov(z,x)&amp;cov(z,y)&amp;cov(z,z)   \end{pmatrix}<br>$$</p>
<p>PCA降维过程为：</p>
<ol>
<li>对特征进行标准化</li>
<li>计算协方差矩阵</li>
<li>计算协方差矩阵的特征值和特征向量</li>
<li>选取最大的k个特征值对应的特征向量，得到特征向量矩阵</li>
<li>将数据变换到k维，得到新的数据集。</li>
</ol>
<p>流程示例：</p>
<p>假设有一组特征数据==data==，数据如下。下面将对这组数据进行特征标准化，即对特征去中心化。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">data = np.array(</span><br><span class="line">[</span><br><span class="line">    [<span class="number">1</span>,<span class="number">2</span>],</span><br><span class="line">    [-<span class="number">2</span>,-<span class="number">3.5</span>],</span><br><span class="line">    [<span class="number">3</span>,<span class="number">5</span>],</span><br><span class="line">    [-<span class="number">4</span>,-<span class="number">7</span>]</span><br><span class="line">])</span><br></pre></td></tr></table></figure>

<ol>
<li><p>对特征进行标准化，这里才用的是每列特征的值减去该列特征的平均值。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">def</span> <span class="title function_">Standard</span>(<span class="params">self,data</span>):</span><br><span class="line">    <span class="comment">#axis = 0代表按列进行取值</span></span><br><span class="line">    mean_vector = np.mean(data, axis=<span class="number">0</span>)</span><br><span class="line">    <span class="keyword">return</span> data- mean_vector</span><br></pre></td></tr></table></figure>

<p>结果为：</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">标准化后的数据为：</span><br><span class="line">[[ 1.5    2.875]</span><br><span class="line"> [-1.5   -2.625]</span><br><span class="line"> [ 3.5    5.875]</span><br><span class="line"> [-3.5   -6.125]]</span><br></pre></td></tr></table></figure></li>
<li><p>计算协方差矩阵</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">def</span> <span class="title function_">get_CovMatrix</span>(<span class="params">self,new_data</span>):</span><br><span class="line">    <span class="comment"># 这里不太理解 rowvar=0表示数据的每一列代表一个feature</span></span><br><span class="line">    <span class="keyword">return</span> np.cov(new_data,rowvar=<span class="number">0</span>)</span><br></pre></td></tr></table></figure>

<p>结果为：</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">标准化后对应的协方差矩阵为：</span><br><span class="line">[[ 9.66666667 16.75      ]</span><br><span class="line"> [16.75       29.0625    ]]</span><br></pre></td></tr></table></figure></li>
<li><p>计算协方差矩阵的特征值和特征向量</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">def</span> <span class="title function_">get_Value_and_Vector</span>(<span class="params">self,cov_Matrix</span>):</span><br><span class="line">    Value, Vector = np.linalg.eig(cov_Matrix)</span><br><span class="line">    <span class="keyword">return</span> Value, Vector</span><br></pre></td></tr></table></figure>

<p>结果为：</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">协方差矩阵的特征值为:</span><br><span class="line">[9.68504702e-03 3.87194816e+01]</span><br><span class="line">协方差矩阵的特征值对应的特征向量为:</span><br><span class="line">[[-0.86633062 -0.49947098]</span><br><span class="line"> [ 0.49947098 -0.86633062]]</span><br></pre></td></tr></table></figure></li>
<li><p>根据指定的维数，求出方差最大的列对应的特征向量，并转化为$n×k$的特征向量矩阵。其中，n为数据长度，k为指定的维数。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">def</span> <span class="title function_">get_Vector_Matrix</span>(<span class="params">self,value,vector,k</span>):</span><br><span class="line">    valueSort = np.argsort(value)</span><br><span class="line">    value_top_n = valueSort[:-(k + <span class="number">1</span>):-<span class="number">1</span>]</span><br><span class="line">    <span class="keyword">return</span> vector[:, value_top_n]</span><br></pre></td></tr></table></figure>

<p>结果为：</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">对应的特征向量矩阵为：</span><br><span class="line">[[-0.49947098]</span><br><span class="line"> [-0.86633062]]</span><br></pre></td></tr></table></figure></li>
<li><p>降维后的数据</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">def</span> <span class="title function_">get_result</span>(<span class="params">self,data,vector_Matrix</span>):</span><br><span class="line">    <span class="keyword">return</span> np.dot(data, vector_Matrix)</span><br></pre></td></tr></table></figure>

<p>结果为：</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">最终结果为：</span><br><span class="line">[[-3.239907  ]</span><br><span class="line"> [ 3.02332434]</span><br><span class="line"> [-6.83784081]</span><br><span class="line"> [ 7.05442347]]</span><br></pre></td></tr></table></figure></li>
</ol>
<p>==对鸢尾花数据集特征进行降维==</p>
<p>鸢尾花数据集是一个多重变量分析的数据集，包含150个数据集，分为3类（Setosa，Versicolour，Virginica），每类50个数据。每个数据包含花萼长度、花萼宽度、花瓣长度、花瓣宽度四个属性。</p>
<p>数据集的格式为：</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">5.1,3.5,1.4,0.2,Iris-setosa</span><br><span class="line">4.9,3.0,1.4,0.2,Iris-setosa</span><br></pre></td></tr></table></figure>

<p>现在使用PCA将数据集中的特征从四维降到二维。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="keyword">from</span> sklearn <span class="keyword">import</span> datasets</span><br><span class="line"><span class="keyword">class</span> <span class="title class_">My_PCA</span>:</span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__init__</span>(<span class="params">self</span>):</span><br><span class="line">        <span class="keyword">pass</span></span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">loadIris</span>(<span class="params">self</span>):</span><br><span class="line">        data = datasets.load_iris()[<span class="string">&quot;data&quot;</span>]</span><br><span class="line">        <span class="keyword">return</span> data</span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">Standard</span>(<span class="params">self,data</span>):</span><br><span class="line">        <span class="comment">#axis = 0代表按列进行取值</span></span><br><span class="line">        mean_vector = np.mean(data, axis=<span class="number">0</span>)</span><br><span class="line">        <span class="keyword">return</span> mean_vector, data- mean_vector</span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">get_CovMatrix</span>(<span class="params">self,new_data</span>):</span><br><span class="line">        <span class="comment"># 这里不太理解 rowvar=0表示数据的每一列代表一个feature</span></span><br><span class="line">        <span class="keyword">return</span> np.cov(new_data,rowvar=<span class="number">0</span>)</span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">get_Value_and_vector</span>(<span class="params">self,cov_Matrix</span>):</span><br><span class="line">        Value, Vector = np.linalg.eig(cov_Matrix)</span><br><span class="line">        <span class="keyword">return</span> Value, Vector</span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">get_Vector_Matrix</span>(<span class="params">self,value,vector,k</span>):</span><br><span class="line">        valueSort = np.argsort(value)</span><br><span class="line">        value_top_n = valueSort[:-(k + <span class="number">1</span>):-<span class="number">1</span>]</span><br><span class="line">        <span class="keyword">return</span> vector[:, value_top_n]</span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">get_result</span>(<span class="params">self,data,vector_Matrix</span>):</span><br><span class="line">        <span class="keyword">return</span> np.dot(data, vector_Matrix)</span><br><span class="line"></span><br><span class="line"><span class="keyword">if</span> __name__ == <span class="string">&quot;__main__&quot;</span>:</span><br><span class="line">    frist = My_PCA()</span><br><span class="line">    data = frist.loadIris()</span><br><span class="line">    mean_vector, new_data = frist.Standard(data)</span><br><span class="line">    cov_Matrix = frist.get_CovMatrix(new_data)</span><br><span class="line">    <span class="built_in">print</span>(<span class="string">&quot;标准化后对应的协方差矩阵为：\n&#123;&#125;&quot;</span>.<span class="built_in">format</span>(cov_Matrix))</span><br><span class="line">    Value, Vector = frist.get_Value_and_vector(cov_Matrix)</span><br><span class="line">    <span class="built_in">print</span>(<span class="string">&quot;协方差矩阵的特征值为:\n&#123;&#125;&quot;</span>.<span class="built_in">format</span>(Value))</span><br><span class="line">    <span class="built_in">print</span>(<span class="string">&quot;协方差矩阵的特征值对应的特征向量为:\n&#123;&#125;&quot;</span>.<span class="built_in">format</span>(Vector))</span><br><span class="line">    f_Vector = frist.get_Vector_Matrix(Value,Vector,<span class="number">2</span>)</span><br><span class="line">    <span class="built_in">print</span>(<span class="string">&quot;对应的特征向量矩阵为：\n&#123;&#125;&quot;</span>.<span class="built_in">format</span>(f_Vector))</span><br><span class="line">    result = frist.get_result(new_data,f_Vector)</span><br><span class="line">    <span class="built_in">print</span>(<span class="string">&quot;最终降维结果为：\n&#123;&#125;&quot;</span>.<span class="built_in">format</span>(result))</span><br><span class="line">    <span class="built_in">print</span>(<span class="string">&quot;最终重构的结果为：\n&#123;&#125;&quot;</span>.<span class="built_in">format</span>(np.mat(result) * f_Vector.T + mean_vector))</span><br></pre></td></tr></table></figure>

<p>结果为：</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br></pre></td><td class="code"><pre><span class="line">标准化后对应的协方差矩阵为：</span><br><span class="line">[[ 0.68569351 -0.042434    1.27431544  0.51627069]</span><br><span class="line"> [-0.042434    0.18997942 -0.32965638 -0.12163937]</span><br><span class="line"> [ 1.27431544 -0.32965638  3.11627785  1.2956094 ]</span><br><span class="line"> [ 0.51627069 -0.12163937  1.2956094   0.58100626]]</span><br><span class="line">协方差矩阵的特征值为:</span><br><span class="line">[4.22824171 0.24267075 0.0782095  0.02383509]</span><br><span class="line">协方差矩阵的特征值对应的特征向量为:</span><br><span class="line">[[ 0.36138659 -0.65658877 -0.58202985  0.31548719]</span><br><span class="line"> [-0.08452251 -0.73016143  0.59791083 -0.3197231 ]</span><br><span class="line"> [ 0.85667061  0.17337266  0.07623608 -0.47983899]</span><br><span class="line"> [ 0.3582892   0.07548102  0.54583143  0.75365743]]</span><br><span class="line">对应的特征向量矩阵为：</span><br><span class="line">[[ 0.36138659 -0.65658877]</span><br><span class="line"> [-0.08452251 -0.73016143]</span><br><span class="line"> [ 0.85667061  0.17337266]</span><br><span class="line"> [ 0.3582892   0.07548102]]</span><br><span class="line">最终降维结果为：</span><br><span class="line">[[-2.68412563 -0.31939725]</span><br><span class="line"> [-2.71414169  0.17700123]</span><br><span class="line"> [-2.88899057  0.14494943]</span><br><span class="line"> [-2.74534286  0.31829898]</span><br><span class="line"> [-2.72871654 -0.32675451]</span><br><span class="line"> [-2.28085963 -0.74133045]</span><br><span class="line">...</span><br><span class="line">最终重构的结果为：</span><br><span class="line">[[5.08303897 3.51741393 1.40321372 0.21353169]</span><br><span class="line"> [4.7462619  3.15749994 1.46356177 0.24024592]</span><br><span class="line"> [4.70411871 3.1956816  1.30821697 0.17518015]</span><br><span class="line"> [4.6422117  3.05696697 1.46132981 0.23973218]</span><br><span class="line"> [5.07175511 3.52655486 1.36373845 0.19699991]</span><br><span class="line"> ...</span><br></pre></td></tr></table></figure></li>
</ul>
<h5 id="数据清理"><a href="#数据清理" class="headerlink" title="数据清理"></a>数据清理</h5><ol>
<li>不合格数据修正</li>
<li>缺失值填充</li>
<li>噪声值处理</li>
<li>离群点处理</li>
</ol>
<h5 id="相似度计算"><a href="#相似度计算" class="headerlink" title="相似度计算"></a>相似度计算</h5><p>相似度计算在数据挖掘和推荐系统中有着广泛的应用场景。如：</p>
<ul>
<li>协同过滤算法中，可以利用相似度计算用户之间或物品之间的相似度。</li>
<li>在利用<code>k-means</code>进行聚类时，利用相似度计算公式计算个体到簇类中心的距离，进而判别个体所属的类别。</li>
<li>利用<code>KNN</code>进行分类时，利用相似度计算个体与已知类别之间的相似性，从而判断个体所属的类别等。</li>
</ul>
<p>==欧式距离==</p>
<p>欧式距离也叫欧里几得距离，是在$m$维空间中两个点的真实距离。</p>
<p>在二维空间中，计算两个点a$(x_1,y_1)$ 和b $(x_2,y_2)$ 之间的欧式距离公式为：<br>$$<br>d_{ab}=\sqrt{(x_1-x_2)^2+(y_1-y_2)^2}<br>$$<br>实现代码为：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> numpy <span class="keyword">import</span> *</span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">EuclideanDistance</span>(<span class="params">a,b</span>):</span><br><span class="line">    <span class="keyword">return</span> sqrt( (a[<span class="number">0</span>] - b[<span class="number">0</span>]) ** <span class="number">2</span> + ( a[<span class="number">1</span>] - b[<span class="number">1</span>]) **<span class="number">2</span>)</span><br><span class="line"></span><br><span class="line"><span class="built_in">print</span>(<span class="string">&quot;&#123;&#125;,&#123;&#125; 两个点的欧式距离为&#123;&#125;&quot;</span>.<span class="built_in">format</span>((<span class="number">1</span>,<span class="number">2</span>),(<span class="number">2</span>,<span class="number">2</span>),EuclideanDistance((<span class="number">1</span>,<span class="number">2</span>),(<span class="number">2</span>,<span class="number">2</span>))))</span><br></pre></td></tr></table></figure>

<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">(1, 2),(2, 2) 两个点的欧式距离为1.0</span><br></pre></td></tr></table></figure>

<p>==曼哈顿距离==</p>
<p>曼哈顿距离又叫城市街区距离。两个街区的实际驾驶距离就是曼哈顿距离。</p>
<p>在二维空间，计算两个点a$(x_1,y_1)$ 和b $(x_2,y_2)$ 之间的哈曼顿距离公式为：<br>$$<br>d_{ab}=|x_1 - x_2| + |y_1 - y_2|<br>$$<br>实现代码为：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> numpy <span class="keyword">import</span> *</span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">ManhattanDistance</span>(<span class="params">a,b</span>):</span><br><span class="line">    <span class="keyword">return</span> <span class="built_in">abs</span>( a[<span class="number">0</span>] - b[<span class="number">0</span>]) + <span class="built_in">abs</span>( a[<span class="number">1</span>] - b[<span class="number">1</span>])</span><br><span class="line"></span><br><span class="line"><span class="built_in">print</span>(<span class="string">&quot;&#123;&#125;, &#123;&#125;两个点的曼哈顿距离是&#123;&#125;&quot;</span>.<span class="built_in">format</span>((<span class="number">1</span>,<span class="number">1</span>),(<span class="number">2</span>,<span class="number">2</span>),ManhattanDistance((<span class="number">1</span>,<span class="number">1</span>),(<span class="number">2</span>,<span class="number">2</span>))))</span><br></pre></td></tr></table></figure>

<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">(1, 1), (2, 2)两个点的曼哈顿距离是2</span><br></pre></td></tr></table></figure>

<p>==切比雪夫距离==</p>
<p>切比雪夫距离（Chebyshev Distance）的定义为：$max(|x_1-x_2|,|y_1-y_2|,…)$</p>
<p>在二维平面中，计算两个点a$(x_1,y_1)$ 和b $(x_2,y_2)$ 之间的切比雪夫距离公式为：<br>$$<br>d_{ab}= max( |x_1-y_1|,|x_2-y_2|)<br>$$</p>
<p>实现代码为：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> numpy <span class="keyword">import</span> *</span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">ChebyshevDistance</span>(<span class="params">a,b</span>):</span><br><span class="line">    <span class="keyword">return</span> <span class="built_in">max</span>( <span class="built_in">abs</span>(a[<span class="number">0</span>] - b[<span class="number">0</span>]), <span class="built_in">abs</span>(a[<span class="number">1</span>] - b[<span class="number">1</span>]))</span><br><span class="line"></span><br><span class="line"><span class="built_in">print</span>(<span class="string">&quot;&#123;&#125;, &#123;&#125;两个点的切比雪夫距离是&#123;&#125;&quot;</span>.<span class="built_in">format</span>((<span class="number">1</span>,<span class="number">1</span>),(<span class="number">2</span>,<span class="number">2</span>),ChebyshevDistance((<span class="number">1</span>,<span class="number">1</span>),(<span class="number">2</span>,<span class="number">2</span>))))</span><br></pre></td></tr></table></figure>

<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">(1, 1), (2, 2)两个点的切比雪夫距离是1</span><br></pre></td></tr></table></figure>

<p>==马氏距离==</p>
<p>马氏距离是数据的协方差距离。有$m$个样本向量$(X_1,…,X_,)$，协方差矩阵为$S$。其中向量$X_i$和$X_j$之间的马氏距离的公式如下：<br>$$<br>D(X_i,X_j)=\sqrt{(X_i-X_j)^TS^{-1}(X_i-X_j)}<br>$$<br>==夹角余弦距离==</p>
<p>几何中的夹角余弦用来衡量两个向量方向的差异。在机器学习中，用来衡量样本向量之间的差异。</p>
<p>在二维平面中，计算两个点a$(x_1,y_1)$ 和b $(x_2,y_2)$ 之间的夹角余弦距离公式为：<br>$$<br>cos(\theta)=\frac{x_1x_2+y_1y_2}{\sqrt{(x_1^2+y_1^2)}\sqrt{(x_2^2+y_2^2)}}<br>$$<br>实现代码为：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> numpy <span class="keyword">import</span> *</span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">CosineSimilarity</span>(<span class="params">a,b</span>):</span><br><span class="line">    cos = (a[<span class="number">0</span>] * b[<span class="number">0</span>] + a[<span class="number">1</span>] * b[<span class="number">1</span>]) / (sqrt(a[<span class="number">0</span>] ** <span class="number">2</span> + a[<span class="number">1</span>] ** <span class="number">2</span>) * sqrt(b[<span class="number">0</span>] ** <span class="number">2</span> + b[<span class="number">1</span>] ** <span class="number">2</span>))</span><br><span class="line">    <span class="keyword">return</span> cos</span><br></pre></td></tr></table></figure>

<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">(1, 1), (2, 2)两个点的夹角余弦距离是0.9999999999999998</span><br></pre></td></tr></table></figure>

<p>==杰卡德相似系数和杰卡德距离==</p>
<p>两个集合$A$和$B$的交集元素在$A$和$B$的并集中所占的比例，称为两个集合的杰卡德相似系数，用符号$J(A,B)$表示，对应的公式如下：<br>$$<br>J(A,B)=\frac{A\cap B}{A\cup B}<br>$$<br>杰卡德相似系数是衡量两个集合==相似度==的一种指标.</p>
<p>实现代码为：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> numpy <span class="keyword">import</span> *</span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">JaccardSimilarityCofficient</span>(<span class="params">a,b</span>):</span><br><span class="line">    set_a = <span class="built_in">set</span>(a)</span><br><span class="line">    set_b = <span class="built_in">set</span>(b)</span><br><span class="line">    dis = <span class="built_in">float</span>(<span class="built_in">len</span>(set_a &amp; set_b) / <span class="built_in">len</span>(set_a | set_b))</span><br><span class="line">    <span class="keyword">return</span> dis</span><br><span class="line"></span><br><span class="line"><span class="built_in">print</span>(<span class="string">&quot;&#123;&#125;, &#123;&#125;杰卡德相似系数是&#123;&#125;&quot;</span>.<span class="built_in">format</span>((<span class="number">1</span>,<span class="number">2</span>,<span class="number">3</span>),(<span class="number">2</span>,<span class="number">3</span>,<span class="number">4</span>),CosineSimilarity((<span class="number">1</span>,<span class="number">2</span>,<span class="number">3</span>),(<span class="number">2</span>,<span class="number">3</span>,<span class="number">4</span>))))</span><br></pre></td></tr></table></figure>

<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">(1, 2, 3), (2, 3, 4)杰卡德相似系数是0.9922778767136677</span><br></pre></td></tr></table></figure>

<p>与杰卡德相似系数相反的概念是杰卡德距离（Jaccard Distance）。杰卡德距离的公式如下：<br>$$<br>J_{\delta}(A,B)=\frac{|A\cup B|-|A\cap B|}{|A\cup B|}<br>$$<br>杰卡德距离即两个集合中不同元素占所有元素的比例，用来衡量两个集合的==区分度==。</p>
<p>实现代码为：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> numpy <span class="keyword">import</span> *</span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">JaccardSimilarityDistance</span>(<span class="params">a,b</span>):</span><br><span class="line">    set_a = <span class="built_in">set</span>(a)</span><br><span class="line">    set_b = <span class="built_in">set</span>(b)</span><br><span class="line">    dis = <span class="built_in">float</span>(<span class="built_in">len</span>((set_a | set_b) - (set_a &amp; set_b)) / <span class="built_in">len</span>(set_a | set_b))</span><br><span class="line">    <span class="keyword">return</span> dis</span><br><span class="line"></span><br><span class="line"><span class="built_in">print</span>(<span class="string">&quot;&#123;&#125;, &#123;&#125;杰卡德距离是&#123;&#125;&quot;</span>.<span class="built_in">format</span>((<span class="number">1</span>,<span class="number">2</span>,<span class="number">3</span>),(<span class="number">2</span>,<span class="number">3</span>,<span class="number">4</span>),JaccardSimilarityDistance((<span class="number">1</span>,<span class="number">2</span>,<span class="number">3</span>),(<span class="number">2</span>,<span class="number">3</span>,<span class="number">4</span>))))</span><br></pre></td></tr></table></figure>

<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">(1, 2, 3), (2, 3, 4)杰卡德距离是0.5</span><br></pre></td></tr></table></figure>

<p>==相关系数与相关距离==</p>
<p>相关系数是衡量随机变量$X$与$Y$相关程度的一种方法，相关系数的取值范围是$[-1,1]$。相关系数的绝对值越大，表明$X$与$Y$的相关度越高。</p>
<p>当$X$与$Y$线性相关时，相关系数取值为 1（正线性相关）或 -1（负线性相关）。</p>
<p>随机变量$X$与$Y$的相关系数为：<br>$$<br>\rho_{XY}=\frac{Cov(X,Y)}{\sqrt{D(X)}\sqrt{D(Y)}}=\frac{E((X-EX)(Y-EY))}{\sqrt{D(X)}\sqrt{D(Y)}}<br>$$<br>则随机变量$X$与$Y$的相关距离为：<br>$$<br>D_{XY}=1-\rho_{XY}<br>$$</p>
<h4 id="数据分类"><a href="#数据分类" class="headerlink" title="数据分类"></a>数据分类</h4><p>分类算法是数据挖掘中常用的基本算法之一，属于有监督学习算法。</p>
<h5 id="K最近邻算法"><a href="#K最近邻算法" class="headerlink" title="K最近邻算法"></a>K最近邻算法</h5><p>K最近邻算法（K-Nearest Neighbor, KNN）是最基本的分类算法，原理是：从最近的K个邻居（样本）中，选择出现次数最多的类别作为判定类别。</p>
<p>实现KNN算法的核心思路：</p>
<ol>
<li>计算未知样本和每个训练样本的距离 distance</li>
<li>按照 distance 的递增关系排序</li>
<li>得到距离最小的前K个样本</li>
<li>统计K最近邻样本中每个类标号出现的次数</li>
<li>选择出现频率最高的类标号作为未知样本的类标号</li>
</ol>
<p>==K值得选择会对KNN算法产生较大的影响。==</p>
<p>K值较小，意味着：只有当需要进行预测的样本和训练的样本集较接近时，才能具有好的效果。</p>
<p>K值较大，意味着：算法分类的近似误差增大。这时与输入样本距离较远的样本也会对结果产生影响。</p>
<p>在实际中，K值为==奇数==，一般选择一个较小的数，也可以通过交叉验证的方法寻找最优K值。</p>
<h5 id="用KNN算法实现性别判定"><a href="#用KNN算法实现性别判定" class="headerlink" title="用KNN算法实现性别判定"></a>用KNN算法实现性别判定</h5><ol>
<li><p>收集数据</p>
<table>
<thead>
<tr>
<th align="center">身高（cm）</th>
<th align="center">体重（kg）</th>
<th align="center">性别</th>
</tr>
</thead>
<tbody><tr>
<td align="center">180</td>
<td align="center">76</td>
<td align="center">男</td>
</tr>
<tr>
<td align="center">158</td>
<td align="center">43</td>
<td align="center">女</td>
</tr>
<tr>
<td align="center">176</td>
<td align="center">78</td>
<td align="center">男</td>
</tr>
<tr>
<td align="center">161</td>
<td align="center">49</td>
<td align="center">女</td>
</tr>
</tbody></table>
</li>
<li><p>准备数据</p>
<p>将数据格式化并保存到Python的数据结构中方便调用。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"></span><br><span class="line"><span class="keyword">class</span> <span class="title class_">KNN</span>:</span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__init__</span>(<span class="params">self,k</span>):</span><br><span class="line">        self.K = k</span><br><span class="line">        </span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">createData</span>(<span class="params">self</span>):</span><br><span class="line">        features = np.array(</span><br><span class="line">            [</span><br><span class="line">                [<span class="number">180</span>,<span class="number">76</span>], [<span class="number">157</span>,<span class="number">43</span>], [<span class="number">176</span>,<span class="number">78</span>], [<span class="number">161</span>,<span class="number">49</span>]</span><br><span class="line">            ]</span><br><span class="line">        )</span><br><span class="line">        labels = [<span class="string">&#x27;男&#x27;</span>, <span class="string">&#x27;女&#x27;</span>, <span class="string">&#x27;男&#x27;</span>, <span class="string">&#x27;女&#x27;</span>]</span><br><span class="line">        <span class="keyword">return</span> features, labels</span><br></pre></td></tr></table></figure></li>
<li><p>预处理数据</p>
<p>由于身高体重不在一个数量级上，所以需要对身高体重进行标准化。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 数据进行 Min-Max 标准化</span></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">Normalization</span>(<span class="params">self,data</span>):</span><br><span class="line">    maxs = np.<span class="built_in">max</span>(data, axis=<span class="number">0</span>)</span><br><span class="line">    mins = np.<span class="built_in">min</span>(data, axis=<span class="number">0</span>)</span><br><span class="line">    new_data = (data - mins) / (maxs - mins)</span><br><span class="line">    <span class="keyword">return</span> new_data, maxs, mins</span><br></pre></td></tr></table></figure>

<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line">原始数据为:</span><br><span class="line">[[180  76]</span><br><span class="line"> [157  43]</span><br><span class="line"> [176  78]</span><br><span class="line"> [161  49]]</span><br><span class="line">[<span class="string">&#x27;男&#x27;</span>, <span class="string">&#x27;女&#x27;</span>, <span class="string">&#x27;男&#x27;</span>, <span class="string">&#x27;女&#x27;</span>]</span><br><span class="line">Min-Max标准化之后的新数据为:</span><br><span class="line">[[1.         0.94285714]</span><br><span class="line"> [0.         0.        ]</span><br><span class="line"> [0.82608696 1.        ]</span><br><span class="line"> [0.17391304 0.17142857]]</span><br></pre></td></tr></table></figure></li>
<li><p>计算K最近邻用户性别</p>
<p>计算新数据到各个已知数据的距离，并从小到大排序。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">#计算K最近邻</span></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">classify</span>(<span class="params">self, one, data, labels</span>):</span><br><span class="line">    <span class="comment"># 采用欧式距离计算新样本与数据集中每个样本之间的距离</span></span><br><span class="line">    differenceData = data - one</span><br><span class="line">    squareData = (differenceData ** <span class="number">2</span>).<span class="built_in">sum</span>(axis=<span class="number">1</span>)</span><br><span class="line">    distance = squareData ** <span class="number">0.5</span></span><br><span class="line">    sortDistanceIndex = distance.argsort()</span><br><span class="line">    <span class="comment">#统计K最近邻的label</span></span><br><span class="line">    labelCount = <span class="built_in">dict</span>()</span><br><span class="line">    <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(self.K):</span><br><span class="line">        label = labels[sortDistanceIndex[i]]</span><br><span class="line">        labelCount.setdefault(label, <span class="number">0</span>)</span><br><span class="line">        labelCount[label] += <span class="number">1</span></span><br><span class="line">    <span class="comment">#计算结果</span></span><br><span class="line">    sortLabelCount = <span class="built_in">sorted</span>(labelCount.items(), key=<span class="keyword">lambda</span>  x: x[<span class="number">1</span>], reverse= <span class="literal">True</span>)</span><br><span class="line">    <span class="built_in">print</span>(sortLabelCount)</span><br><span class="line">    <span class="keyword">return</span> sortLabelCount[<span class="number">0</span>][<span class="number">0</span>]</span><br></pre></td></tr></table></figure>

<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">if</span> __name__ == <span class="string">&quot;__main__&quot;</span>:</span><br><span class="line">    kk = KNN(<span class="number">3</span>)</span><br><span class="line">    features, labels = kk.createData()</span><br><span class="line">    <span class="built_in">print</span>(<span class="string">&quot;原始数据为:\n&#123;&#125;\n&#123;&#125;&quot;</span>.<span class="built_in">format</span>(features, labels))</span><br><span class="line">    new_data, maxs, mins = kk.Normalization(features)</span><br><span class="line">    <span class="built_in">print</span>(<span class="string">&quot;Min-Max标准化之后的新数据为:\n&#123;&#125;&quot;</span>.<span class="built_in">format</span>(new_data))</span><br><span class="line">    one = np.array([<span class="number">174</span>,<span class="number">65</span>])</span><br><span class="line">    new_one = (one - mins) / (maxs - mins)</span><br><span class="line">    result = kk.classify(new_one, new_data, labels)</span><br><span class="line">    <span class="built_in">print</span>(<span class="string">&quot;数据 &#123;&#125;的预测性别为： &#123;&#125;&quot;</span>.<span class="built_in">format</span>(one, result))</span><br></pre></td></tr></table></figure>

<p>输出结果：</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">distance is [0.40844637 0.97026586 0.38147165 0.72694587]</span><br><span class="line">sortDistanceIndex is [2 0 3 1]</span><br><span class="line">[(<span class="string">&#x27;男&#x27;</span>, 2), (<span class="string">&#x27;女&#x27;</span>, 1)]</span><br><span class="line">数据 [174  65]的预测性别为： 男</span><br></pre></td></tr></table></figure></li>
</ol>
<h5 id="决策树算法"><a href="#决策树算法" class="headerlink" title="决策树算法"></a>决策树算法</h5><p>   决策树（Decision Tree）是根据一系列规则对数据进行分类的过程。</p>
<p>   决策树分为回归决策树和分类决策树。</p>
<p>   回归决策树是对连续变量构建决策树。</p>
<p>   分类决策树是对离散变量构建决策树。</p>
<p>   分类决策树的代表是==ID3算法==，==C4.5和CART==既可以构建分类决策树也可以构建回归决策树。</p>
<p>   在决策数据中使用==信息增益（Information Gain）==来决定使用哪个特征值作为节点进行分割。==信息增益==的计算公式为：<br>$$<br>   g(D,A)=E(D)-E(D|A)<br>$$</p>
<p>   决策树的构建过程为：</p>
<ol>
<li>树从代表训练样本的根节点开始。</li>
<li>如果样本都在同一个类中，则该节点为树叶，并用该类标记。</li>
<li>否则，算法选择最具有分类能力的属性作为决策树的当前节点。</li>
<li>根据当前决策绝点属性取值的不同，将训练样本数据集data分为若干子集，每个取值形成一个分支，有几个取值就有几个分支。</li>
<li>针对步骤4得到的每一个子集，重复1,2,3，递归形成每个划分样本上的决策树。一旦一个属性只出现在一个节点上，就不必再该节点的任何子节点考虑它。</li>
</ol>
<h5 id="构建是否举办活动的决策树"><a href="#构建是否举办活动的决策树" class="headerlink" title="构建是否举办活动的决策树"></a>构建是否举办活动的决策树</h5><ol>
<li><p>准备数据集</p>
<table>
<thead>
<tr>
<th align="center">天气</th>
<th align="center">温度</th>
<th align="center">湿度</th>
<th align="center">风速</th>
<th align="center">是否举办活动</th>
</tr>
</thead>
<tbody><tr>
<td align="center">晴</td>
<td align="center">炎热</td>
<td align="center">高</td>
<td align="center">弱</td>
<td align="center">是</td>
</tr>
<tr>
<td align="center">晴</td>
<td align="center">炎热</td>
<td align="center">高</td>
<td align="center">强</td>
<td align="center">否</td>
</tr>
<tr>
<td align="center">阴</td>
<td align="center">炎热</td>
<td align="center">高</td>
<td align="center">弱</td>
<td align="center">是</td>
</tr>
<tr>
<td align="center">雨</td>
<td align="center">寒冷</td>
<td align="center">正常</td>
<td align="center">弱</td>
<td align="center">否</td>
</tr>
<tr>
<td align="center">雨</td>
<td align="center">寒冷</td>
<td align="center">正常</td>
<td align="center">强</td>
<td align="center">是</td>
</tr>
<tr>
<td align="center">阴</td>
<td align="center">寒冷</td>
<td align="center">正常</td>
<td align="center">强</td>
<td align="center">否</td>
</tr>
<tr>
<td align="center">晴</td>
<td align="center">适中</td>
<td align="center">高</td>
<td align="center">弱</td>
<td align="center">是</td>
</tr>
<tr>
<td align="center">晴</td>
<td align="center">寒冷</td>
<td align="center">正常</td>
<td align="center">弱</td>
<td align="center">是</td>
</tr>
<tr>
<td align="center">雨</td>
<td align="center">适中</td>
<td align="center">正常</td>
<td align="center">弱</td>
<td align="center">是</td>
</tr>
<tr>
<td align="center">晴</td>
<td align="center">适中</td>
<td align="center">正常</td>
<td align="center">强</td>
<td align="center">是</td>
</tr>
<tr>
<td align="center">阴</td>
<td align="center">炎热</td>
<td align="center">正常</td>
<td align="center">弱</td>
<td align="center">否</td>
</tr>
<tr>
<td align="center">雨</td>
<td align="center">适中</td>
<td align="center">高</td>
<td align="center">强</td>
<td align="center">否</td>
</tr>
</tbody></table>
<p>将相应的属性值转换为数字。</p>
<p>天气：晴（2），阴（1），雨（0）</p>
<p>温度：炎热（2），适中（1），寒冷（0）</p>
<p>湿度：高（1），正常（0）</p>
<p>风速：强（1），弱（0）</p>
<p>举办活动：是（yes），否（no）</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> operator</span><br><span class="line"><span class="keyword">import</span> math</span><br><span class="line"></span><br><span class="line"><span class="keyword">class</span> <span class="title class_">DecisiconTree</span>:</span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__init__</span>(<span class="params">self</span>):</span><br><span class="line">        <span class="keyword">pass</span></span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">loadData</span>(<span class="params">self</span>):</span><br><span class="line">        <span class="comment">#天气：晴（2），阴（1），雨（0）</span></span><br><span class="line"></span><br><span class="line">        <span class="comment">#温度：炎热（2），适中（1），寒冷（0）</span></span><br><span class="line"></span><br><span class="line">        <span class="comment">#湿度：高（1），正常（0）</span></span><br><span class="line"></span><br><span class="line">        <span class="comment">#风速：强（1），弱（0）</span></span><br><span class="line"></span><br><span class="line">        <span class="comment">#举办活动：是（yes），否（no）</span></span><br><span class="line">        data = [</span><br><span class="line">            [<span class="number">2</span>, <span class="number">2</span>, <span class="number">1</span>, <span class="number">0</span>, <span class="string">&#x27;yes&#x27;</span>],</span><br><span class="line">            [<span class="number">2</span>, <span class="number">2</span>, <span class="number">1</span>, <span class="number">1</span>, <span class="string">&#x27;no&#x27;</span>],</span><br><span class="line">            [<span class="number">1</span>, <span class="number">2</span>, <span class="number">1</span>, <span class="number">0</span>, <span class="string">&#x27;yes&#x27;</span>],</span><br><span class="line">            [<span class="number">0</span>, <span class="number">0</span>, <span class="number">0</span>, <span class="number">0</span>, <span class="string">&#x27;yes&#x27;</span>],</span><br><span class="line">            [<span class="number">0</span>, <span class="number">0</span>, <span class="number">0</span>, <span class="number">1</span>, <span class="string">&#x27;no&#x27;</span>],</span><br><span class="line">            [<span class="number">1</span>, <span class="number">0</span>, <span class="number">0</span>, <span class="number">1</span>, <span class="string">&#x27;yes&#x27;</span>],</span><br><span class="line">            [<span class="number">2</span>, <span class="number">1</span>, <span class="number">1</span>, <span class="number">0</span>, <span class="string">&#x27;no&#x27;</span>],</span><br><span class="line">            [<span class="number">2</span>, <span class="number">0</span>, <span class="number">0</span>, <span class="number">0</span>, <span class="string">&#x27;yes&#x27;</span>],</span><br><span class="line">            [<span class="number">0</span>, <span class="number">1</span>, <span class="number">0</span>, <span class="number">0</span>, <span class="string">&#x27;yes&#x27;</span>],</span><br><span class="line">            [<span class="number">2</span>, <span class="number">1</span>, <span class="number">0</span>, <span class="number">1</span>, <span class="string">&#x27;yes&#x27;</span>],</span><br><span class="line">            [<span class="number">1</span>, <span class="number">2</span>, <span class="number">0</span>, <span class="number">0</span>, <span class="string">&#x27;no&#x27;</span>],</span><br><span class="line">            [<span class="number">0</span>, <span class="number">1</span>, <span class="number">1</span>, <span class="number">1</span>, <span class="string">&#x27;no&#x27;</span>],</span><br><span class="line">        ]</span><br><span class="line">        features = [<span class="string">&#x27;天气&#x27;</span>, <span class="string">&#x27;温度&#x27;</span>, <span class="string">&quot;湿度&quot;</span>, <span class="string">&#x27;风速&#x27;</span>]</span><br><span class="line">        <span class="keyword">return</span> data, features</span><br></pre></td></tr></table></figure></li>
<li><p>计算初始香农熵</p>
<p>熵的计算公式为：<br>$$<br>E(x)=-\sum_{i=1}^n p(x_i)log_2 p(x_i)<br>$$<br>在数据集中包含了12个训练样本集，其中，”是”的标签有7个，”否”的标签有5个，则</p>
<p>==熵的计算结果==为：<br>$$<br>E = -\frac{7}{12}×log_2(\frac{7}{12})-\frac{5}{12}×log_2(\frac{5}{12})=0.9799<br>$$<br>计算每个属性对应的==信息熵==。</p>
<ul>
<li><p>“天气”对应的信息熵</p>
<p>“天气”共有三个取值：</p>
<p>“晴”出现了5次，其中，”是”标签有3个，”否”标签有2个，则天气为==晴==对应的信息熵为：<br>$$<br>E(天气|晴)=\frac{5}{12}×[-\frac{3}{5}×log_2(\frac{3}{5})-\frac{2}{5}×log_2(\frac{2}{5})]=0.4046<br>$$<br>“阴”出现了3次，其中，”是”标签有2个，”否”标签有1个，则天气为==阴==对应的信息熵为：<br>$$<br>E(天气|阴)=\frac{3}{12}×[-\frac{2}{3}×log_2(\frac{2}{3})-\frac{1}{3}×log_2(\frac{1}{3})]=0.2296<br>$$<br>“雨”出现了4次，其中，”是”标签有2个，”否”标签有2个，则天气为==雨==对应的信息熵为：<br>$$<br>E(天气|雨)=\frac{4}{12}×[-\frac{2}{4}×log_2(\frac{2}{4})-\frac{2}{4}×log_2(\frac{2}{4})]=0.3333<br>$$<br>则基于”天气”划分数据集，对应==总的信息熵==为：<br>$$<br>E(天气)= E(天气|晴) + E(天气|阴) + E(天气|雨)=0.4046+0.2296+0.3333=0.9675<br>$$<br>==”天气”对应的信息增益==为：<br>$$<br>g(天气)=0.9799-0.9675=0.0124<br>$$</p>
</li>
<li><p>“温度”对应的信息熵。</p>
<p>“温度”共有3个取值：</p>
<p>“炎热”共出现了4次，其中，”是”标签有2个，”否”标签有2个，则温度为==炎热==对应的信息熵为：<br>$$<br>E(温度|炎热)=\frac{4}{12}×[-\frac{2}{4}×log_2(\frac{2}{4})-\frac{2}{4}×log_2(\frac{2}{4})]=0.3333<br>$$<br>“寒冷”共出现了4次，其中，”是”标签有3个，”否”标签有1个，则温度为==寒冷==对应的信息熵为：<br>$$<br>E(温度|寒冷)=\frac{4}{12}×[-\frac{3}{4}×log_2(\frac{3}{4})-\frac{1}{4}×log_2(\frac{1}{4})]=0.2704<br>$$<br>“适中”共出现了4次，其中，”是”标签有2个，”否”标签有2个，则温度为==适中==对应的信息熵为：<br>$$<br>E(温度|寒冷)=\frac{4}{12}×[-\frac{2}{4}×log_2(\frac{2}{4})-\frac{2}{4}×log_2(\frac{2}{4})]=0.3333<br>$$<br>则基于”温度”划分数据集，对应==总的信息熵==为：<br>$$<br>E(温度)=E(温度|炎热)+E(温度|寒冷)+E(温度|适中)=0.3333+0.2704+0.3333=0.9370<br>$$<br>==”温度”对应的信息增益==为：<br>$$<br>g(温度)=0.9799-0.9370=0.0429<br>$$</p>
</li>
<li><p>“湿度”对应的信息熵。</p>
<p>“湿度”共有2个取值：</p>
<p>“高”共出现了5次，其中，”是”标签有2个，”否”标签有3个，则湿度为==高==对应的信息熵为：<br>$$<br>E(湿度|高)=\frac{5}{12}×[-\frac{2}{5}×log_2(\frac{2}{5})-\frac{3}{5}×log_2(\frac{3}{5})]=0.4045<br>$$<br>“正常”共出现了7次，其中，”是”标签有5个，”否”标签有2个，则湿度为==正常==对应的信息熵为：<br>$$<br>E(湿度|正常)=\frac{7}{12}×[-\frac{5}{7}×log_2(\frac{5}{7})-\frac{2}{7}×log_2(\frac{2}{7})]=0.5034<br>$$<br>则基于”湿度”划分数据集，对应==总的信息熵==为：<br>$$<br>E(湿度)=E(湿度|高)+E(湿度|正常)=0.4045+0.5034=0.9079<br>$$<br>==”湿度”对应的信息增益==为：<br>$$<br>g(湿度)=0.9799-0.9079=0.0720<br>$$</p>
</li>
<li><p>“风速”对应的信息熵。</p>
<p>“风速”共有两个取值：</p>
<p>“强”共出现了5次，其中，”是”标签有2个，”否”标签有3个，则风速为==强==对应的信息熵为：<br>$$<br>E(风速|强)=\frac{5}{12}×[-\frac{2}{5}×log_2(\frac{2}{5})-\frac{3}{5}×log_2(\frac{3}{5})]=0.4045<br>$$</p>
<p>“弱”共出现了7次，其中，”是”标签有5个，”否”标签有2个，则风速为==弱==对应的信息熵为：<br>$$<br>E(风速|弱)=\frac{7}{12}×[-\frac{5}{7}×log_2(\frac{5}{7})-\frac{2}{7}×log_2(\frac{2}{7})]=0.5034<br>$$<br>则基于”风速”划分数据集，对应==总的信息熵==为：<br>$$<br>E(风速)=E(风速|强)+E(风速|弱)=0.4045+0.5034=0.9079<br>$$<br>==”风速”对应的信息增益==为：<br>$$<br>g(风速)=0.9799-0.9079=0.0720<br>$$</p>
</li>
</ul>
<p>则对比4个特征值下的信息增益可以看出：第一次决策应该以==湿度（或风速）==属性为参考，然后根据”湿度”属性将数据集划分为两个子数据集。之后，递归使用上述计算方法，进而求的第二次决策使用的属性。依次类推，最终可以得到一颗完整的决策树。</p>
<p>代码实现计算==初始香农熵==。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">def</span> <span class="title function_">ShannonEnt</span>(<span class="params">self,data</span>):</span><br><span class="line">    numData = <span class="built_in">len</span>(data)</span><br><span class="line">    labelCounts = &#123;&#125;</span><br><span class="line">    <span class="keyword">for</span> feature <span class="keyword">in</span> data:</span><br><span class="line">        oneLabel = feature[-<span class="number">1</span>]</span><br><span class="line">        labelCounts.setdefault(oneLabel, <span class="number">0</span>)</span><br><span class="line">        labelCounts[oneLabel] += <span class="number">1</span></span><br><span class="line">    shannonEnt = <span class="number">0.0</span></span><br><span class="line">    <span class="keyword">for</span> key <span class="keyword">in</span> labelCounts:</span><br><span class="line">        prob = <span class="built_in">float</span>(labelCounts[key]) / numData</span><br><span class="line">        shannonEnt -= prob * math.log2(prob)</span><br><span class="line">    <span class="keyword">return</span> shannonEnt</span><br></pre></td></tr></table></figure></li>
<li><p>选择最好的划分属性标签</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">def</span> <span class="title function_">splitData</span>(<span class="params">self, data, axis, value</span>):</span><br><span class="line">    retData = []</span><br><span class="line">    <span class="keyword">for</span> feature <span class="keyword">in</span> data:</span><br><span class="line">        <span class="keyword">if</span> feature[axis] == value:</span><br><span class="line">            reduceFeature = feature[:axis]</span><br><span class="line">            reduceFeature.extend(feature[axis + <span class="number">1</span> :])</span><br><span class="line">            retData.append(reduceFeature)</span><br><span class="line">    <span class="keyword">return</span> retData</span><br></pre></td></tr></table></figure>

<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">def</span> <span class="title function_">chooseBestFeatureToSplit</span>(<span class="params">self, data</span>):</span><br><span class="line">    numFeature = <span class="built_in">len</span>(data[<span class="number">0</span>]) - <span class="number">1</span></span><br><span class="line">    baseEntropy = self.ShannonEnt(data)</span><br><span class="line">    bestInfoGain = <span class="number">0.0</span></span><br><span class="line">    bestFeature = -<span class="number">1</span></span><br><span class="line">    <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(numFeature):</span><br><span class="line">        featureList = [result[i] <span class="keyword">for</span> result <span class="keyword">in</span> data]</span><br><span class="line">        uniqueFeatureList = <span class="built_in">set</span>(featureList)</span><br><span class="line">        newEntropy = <span class="number">0.0</span></span><br><span class="line">        <span class="keyword">for</span> value <span class="keyword">in</span> uniqueFeatureList:</span><br><span class="line">            splitDataSet = self.splitData(data, i ,value)</span><br><span class="line">            prob = <span class="built_in">len</span>(splitDataSet) / <span class="built_in">float</span>(<span class="built_in">len</span>(data))</span><br><span class="line">            newEntropy += prob * self.ShannonEnt(splitDataSet)</span><br><span class="line">        infoGain = baseEntropy - newEntropy</span><br><span class="line">      </span><br><span class="line">        <span class="keyword">if</span> infoGain &gt; bestInfoGain:</span><br><span class="line">            bestInfoGain = infoGain</span><br><span class="line">            bestFeature = i</span><br><span class="line">    <span class="keyword">return</span> bestFeature</span><br></pre></td></tr></table></figure></li>
<li><p>递归构建决策树</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">def</span> <span class="title function_">majorityCnt</span>(<span class="params">self, labelsList</span>):</span><br><span class="line">    labelCount = &#123;&#125;</span><br><span class="line">    <span class="keyword">for</span> vote <span class="keyword">in</span> labelsList:</span><br><span class="line">        <span class="keyword">if</span> vote <span class="keyword">not</span> <span class="keyword">in</span> labelCount.keys():</span><br><span class="line">            labelCount[vote] = <span class="number">0</span></span><br><span class="line">        labelCount[vote] += <span class="number">1</span></span><br><span class="line">    sortedLabelsCount = <span class="built_in">sorted</span>(labelCount.items(), key=operator.itemgetter(<span class="number">1</span>),reverse=<span class="literal">True</span>)</span><br><span class="line">    <span class="built_in">print</span>(sortedLabelsCount)</span><br><span class="line">    <span class="keyword">return</span> sortedLabelsCount[<span class="number">0</span>][<span class="number">0</span>]</span><br><span class="line">      </span><br><span class="line"><span class="keyword">def</span> <span class="title function_">createTree</span>(<span class="params">self, data, features</span>):</span><br><span class="line">    features = <span class="built_in">list</span>(features)</span><br><span class="line">    labelsList = [line[-<span class="number">1</span>] <span class="keyword">for</span> line <span class="keyword">in</span> data]</span><br><span class="line">    <span class="keyword">if</span> labelsList.count(labelsList[<span class="number">0</span>]) == <span class="built_in">len</span>(labelsList):</span><br><span class="line">        <span class="keyword">return</span> labelsList[<span class="number">0</span>]</span><br><span class="line">    <span class="keyword">if</span> <span class="built_in">len</span>(data[<span class="number">0</span>]) == <span class="number">1</span>:</span><br><span class="line">        <span class="keyword">return</span> self.majorityCnt(labelsList)</span><br><span class="line">    bestFeature = self.chooseBestFeatureToSplit(data)</span><br><span class="line">    bestFeatLabel = features[bestFeature]</span><br><span class="line">    myTree = &#123;bestFeatLabel: &#123;&#125;&#125;</span><br><span class="line">    <span class="keyword">del</span>(features[bestFeature])</span><br><span class="line">    featureValues = [example[bestFeature] <span class="keyword">for</span> example <span class="keyword">in</span> data]</span><br><span class="line">    uniqueFeatureValues = <span class="built_in">set</span>(featureValues)</span><br><span class="line">    <span class="keyword">for</span> value <span class="keyword">in</span> uniqueFeatureValues:</span><br><span class="line">        subFeatures = features[:]</span><br><span class="line">        myTree[bestFeatLabel][value] = self.createTree(self.splitData(data, bestFeature,value), subFeatures)</span><br><span class="line">    <span class="keyword">return</span> myTree</span><br></pre></td></tr></table></figure></li>
<li><p>预测新数据</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">def</span> <span class="title function_">predict</span>(<span class="params">self, tree, features, x</span>):</span><br><span class="line">    <span class="keyword">for</span> key1 <span class="keyword">in</span> tree.keys():</span><br><span class="line">        secondDict = tree[key1]</span><br><span class="line">        featIndex = features.index(key1)</span><br><span class="line">        <span class="keyword">for</span> key2 <span class="keyword">in</span> secondDict.keys():</span><br><span class="line">            <span class="keyword">if</span> x[featIndex] == key2:</span><br><span class="line">                <span class="keyword">if</span> <span class="built_in">type</span>(secondDict[key2]).__name__ == <span class="string">&quot;dict&quot;</span>:</span><br><span class="line">                    classLabel = self.predict(secondDict[key2], features, x)</span><br><span class="line">                <span class="keyword">else</span>:</span><br><span class="line">                    classLabel = secondDict[key2]</span><br><span class="line">    <span class="keyword">return</span> classLabel</span><br></pre></td></tr></table></figure></li>
<li><p>输出结果</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">if</span> __name__ == <span class="string">&quot;__main__&quot;</span>:</span><br><span class="line">    dtree = DecisiconTree()</span><br><span class="line">    data, features = dtree.loadData()</span><br><span class="line">    myTree = dtree.createTree(data, features)</span><br><span class="line">    <span class="built_in">print</span>(myTree)</span><br><span class="line">    label = dtree.predict(myTree, features, [<span class="number">1</span>, <span class="number">1</span>, <span class="number">1</span>, <span class="number">0</span>])</span><br><span class="line">    <span class="built_in">print</span>(<span class="string">&quot;新数据&#123;&#125;对应是否举办活动为:&#123;&#125;&quot;</span>.<span class="built_in">format</span>([<span class="number">1</span>,<span class="number">1</span>,<span class="number">1</span>,<span class="number">0</span>],label))</span><br></pre></td></tr></table></figure>

<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">&#123;<span class="string">&#x27;湿度&#x27;</span>: &#123;0: &#123;<span class="string">&#x27;温度&#x27;</span>: &#123;0: &#123;<span class="string">&#x27;天气&#x27;</span>: &#123;0: &#123;<span class="string">&#x27;风速&#x27;</span>: &#123;0: <span class="string">&#x27;yes&#x27;</span>, 1: <span class="string">&#x27;no&#x27;</span>&#125;&#125;, 1: <span class="string">&#x27;yes&#x27;</span>, 2: <span class="string">&#x27;yes&#x27;</span>&#125;&#125;, 1: <span class="string">&#x27;yes&#x27;</span>, 2: <span class="string">&#x27;no&#x27;</span>&#125;&#125;, 1: &#123;<span class="string">&#x27;天气&#x27;</span>: &#123;0: <span class="string">&#x27;no&#x27;</span>, 1: <span class="string">&#x27;yes&#x27;</span>, 2: &#123;<span class="string">&#x27;温度&#x27;</span>: &#123;1: <span class="string">&#x27;no&#x27;</span>, 2: &#123;<span class="string">&#x27;风速&#x27;</span>: &#123;0: <span class="string">&#x27;yes&#x27;</span>, 1: <span class="string">&#x27;no&#x27;</span>&#125;&#125;&#125;&#125;&#125;&#125;&#125;&#125;</span><br><span class="line">新数据[1, 1, 1, 0]对应是否举办活动为:<span class="built_in">yes</span></span><br></pre></td></tr></table></figure></li>
</ol>
<h5 id="朴素贝叶斯算法"><a href="#朴素贝叶斯算法" class="headerlink" title="朴素贝叶斯算法"></a>朴素贝叶斯算法</h5><p>特征独立性假设是指，假设每个特征之间是没有联系的。例如，天气，温度，湿度和风速这四类特征之间是没有联系的。</p>
<p>朴素贝叶斯算法</p>
<p>给定的训练数据集为<code>(x,y)</code>，其中，每个样本<code>x</code>都包含<code>n</code>维特征，即$x=(x_1,x_2,x_3,…,x_n)$，类别标记集合含有<code>m</code>种类别，即<code>y=(y_1,y_2,y_3,...,y_m)</code>。如果有一个新的样本<code>x</code>，该如何判断它的类别呢？</p>
<p>从概率论的角度来看，就是：判定<code>x</code>属于哪个类别的概率最大，即求$P(y_1|x),P(y_2|x),P(y_3|x),…,P(y_m|x)$中的最大值。</p>
<p>使用==贝叶斯定理==计算$P(y_k|x)$。<br>$$<br>P(y_k|x)=\frac{P(x|y_k)P(y_k)}{P(x)}<br>$$<br>又<br>$$<br>P(A)=\sum_{1}^{\infty}P(B_i)P(A|B_i)<br>$$<br><code>A</code>为某事件发生的概率，$B_i$是样本空间的一个划分。</p>
<p>则公式49的分母可以分解为：<br>$$<br>P(y_k|x)=\frac{P(x|y_k)P(y_k)}{\sum_{i=1}^{m}P(x|y_i)P(y_i)}<br>$$</p>
<p>公式51中，$P(y_i)$是先验概率，根据数据集的标签和数据总条目就可以进行计算；而条件概率$P(x|y_i)=P(x_1,x_2,x_3,…,x_n|y_i)$的参数规模都是指数量级的。</p>
<p>针对这个问题，朴素贝叶斯算法对条件概率分布做出了==独立性假设==。假设各个维度的特征$x_1,x_2,x_3,…,x_n$相互独立，在这个假设下，条件概率可以转化为：<br>$$<br>P(x|y_k)=P(x_1,x_2,x_3,…,x_n|y_k)=\prod_{i=1}^{n}P(x_i|y_k)<br>$$</p>
<p>将公式52代入公式51得到：<br>$$<br>P(y_k|X)=\frac{P(y_k)\prod_{i=1}^{n}P(x_i|y_k)}{\sum_{i=1}^{m}P(y_i)\prod_{i=1}^nP(x_i|y_i)}<br>$$<br>对于所有的$P(y_k|x)$，式子53中的分母部分都是一样的，所以求<code>x</code>所属类别的函数可以转化为：<br>$$<br>f(x)=max(P(y_k|x))=max(P(y_k)\prod_{i=1}^{n}P(x_i|y_k))<br>$$<br>式子54中的$P(y_k)$和$P(x_i|y_k)$都是可以根据数据集计算出来的。</p>
<p>三种常见的模型。</p>
<ol>
<li><p>==多项式模型==</p>
<p>当特征值是==离散值==时，采用多项式模型。多项式模型在计算先验概率$P(y_k)$和条件概率$P(x_i|y_k)$时做==平滑处理==。先验概率$P(y_k)$对应的平滑处理公式为：<br>$$<br>P(y_k)=\frac{n_{y_k}+a}{n+ma}<br>$$<br>其中，$n$是总的样本个数，$m$是总的类别个数，$a$是平滑值。</p>
<p>条件概率$P(x_i|y_k)$对应的平滑处理公式为：<br>$$<br>P(x_i|y_k)=\frac{n_{y_kx_i}+a}{n_{y_k}+na}<br>$$<br>其中，$n_{y_k}$是类别为$y_k$的样本个数，$n$是特征的维数，$n_{y_kx_i}$是类别为$y_k$的样本中第$i$维特征的值是$x_i$的样本个数，$a$是平滑值。</p>
<p>当$a=1$时，称作==Laplace平滑==；当$0&lt;a&lt;1$时，称作==Lidstone平滑==；当$a=0$时，不做平滑处理。</p>
<p>若不做平滑处理，当某一维特征的值$x_i$没在训练样本中出现过时，会导致$P(x_i|y_k)=0$，从而导致后验概率为0。加上平滑可以客服这个问题。</p>
</li>
<li><p>==高斯模型==</p>
<p>当特征值时==连续变量==时，运用多项式模型会导致很多$P(x_i|y_k)=0$（不做平滑处理的情况下），即使做了平滑处理，所得到的条件概率也难以描述真实情况。因此在处理连续变量时采用高斯模型。</p>
<p>高斯模型的前提是，==假设数据的每一特征都服从高斯分布==，则$P(x_i|y_k)$的计算公式如下：<br>$$<br>p(x_i|y_k)=\frac{1}{2\pi\sigma_{y_k,i}^2}e^{-\frac{(x_i-\mu_{y_{k,i}})^2}{2\sigma_{y_{k,i}}^2}}<br>$$<br>其中，$\mu_{y_{k,i}}$表示类别为$y_k$的样本中，第$i$维特征的均值，$\sigma_{y_{k,i}}^2$表示类别为$y_k$的样本中，第$i$维特征的方差。</p>
</li>
<li><p>==伯努利模型==</p>
<p>与多项式模型一样，伯努利模型适用于==离散特征==的情况。</p>
<p>不同的是，伯努利模型的==取值只能是 1 或 0==，以文本分类为例，某个单词在文档中出现过，则特征值为0，否则为0。</p>
<p>在伯努利模型中，条件概率$P(x_i|y_k)$的计算方式是：</p>
<p>当特征值$x_i$为$1$时，$P(x_i|y_k)=P(x_i=1|y_k)$；</p>
<p>当特征值$x_i$为$0$时，$P(x_i|y_k)=1-P(x_i=1|y_k)$。</p>
</li>
</ol>
<h5 id="基于朴素贝叶斯算法进行异常账户检测（存在一些疑问）"><a href="#基于朴素贝叶斯算法进行异常账户检测（存在一些疑问）" class="headerlink" title="基于朴素贝叶斯算法进行异常账户检测（存在一些疑问）"></a>基于朴素贝叶斯算法进行异常账户检测（存在一些疑问）</h5><p>在电商网站中，往往会存在一些异常用户，包括恶意刷单用户、爬虫爬取数据的用户等。在准备推荐算法相关数据时，应该过滤掉这些异常用户产生的数据。</p>
<ol>
<li><p>准备数据</p>
<table>
<thead>
<tr>
<th>注册天数</th>
<th>活跃天数</th>
<th>购物次数</th>
<th>点击商品个数</th>
<th>是否异常用户</th>
</tr>
</thead>
<tbody><tr>
<td>320</td>
<td>204</td>
<td>198</td>
<td>265</td>
<td>是</td>
</tr>
<tr>
<td>253</td>
<td>53</td>
<td>15</td>
<td>2243</td>
<td>否</td>
</tr>
<tr>
<td>53</td>
<td>32</td>
<td>5</td>
<td>325</td>
<td>否</td>
</tr>
<tr>
<td>63</td>
<td>50</td>
<td>42</td>
<td>98</td>
<td>是</td>
</tr>
<tr>
<td>1302</td>
<td>523</td>
<td>202</td>
<td>5430</td>
<td>否</td>
</tr>
<tr>
<td>32</td>
<td>22</td>
<td>5</td>
<td>143</td>
<td>否</td>
</tr>
<tr>
<td>105</td>
<td>85</td>
<td>70</td>
<td>322</td>
<td>是</td>
</tr>
<tr>
<td>872</td>
<td>730</td>
<td>840</td>
<td>2762</td>
<td>是</td>
</tr>
<tr>
<td>16</td>
<td>15</td>
<td>13</td>
<td>52</td>
<td>是</td>
</tr>
<tr>
<td>92</td>
<td>70</td>
<td>21</td>
<td>693</td>
<td>否</td>
</tr>
</tbody></table>
<p>本次实验中的数据为==连续型变量==，所以这里使用==高斯模型==进行计算。</p>
<p>建立<code>NavieBayesian</code>类并创建数据：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"></span><br><span class="line"><span class="keyword">class</span> <span class="title class_">NaiveBayesian</span>:</span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__init__</span>(<span class="params">self, alpha</span>):</span><br><span class="line">        self.classP = <span class="built_in">dict</span>()</span><br><span class="line">        self.classP_feature = <span class="built_in">dict</span>()</span><br><span class="line">        self.alpha = alpha <span class="comment"># 平滑值</span></span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">createData</span>(<span class="params">self</span>):</span><br><span class="line">        data = np.array(</span><br><span class="line">            [</span><br><span class="line">                [<span class="number">320</span>, <span class="number">204</span>, <span class="number">198</span>, <span class="number">265</span>],</span><br><span class="line">                [<span class="number">253</span>, <span class="number">53</span>, <span class="number">15</span>, <span class="number">2243</span>],</span><br><span class="line">                [<span class="number">53</span>, <span class="number">32</span>, <span class="number">5</span>, <span class="number">325</span>],</span><br><span class="line">                [<span class="number">63</span>, <span class="number">50</span>, <span class="number">42</span>, <span class="number">98</span>],</span><br><span class="line">                [<span class="number">1302</span>, <span class="number">523</span>, <span class="number">202</span>, <span class="number">5430</span>],</span><br><span class="line">                [<span class="number">32</span>, <span class="number">22</span>, <span class="number">5</span>, <span class="number">143</span>],</span><br><span class="line">                [<span class="number">105</span>, <span class="number">85</span>, <span class="number">70</span>, <span class="number">322</span>],</span><br><span class="line">                [<span class="number">872</span>, <span class="number">730</span>, <span class="number">840</span>, <span class="number">2762</span>],</span><br><span class="line">                [<span class="number">16</span>, <span class="number">15</span>, <span class="number">13</span>, <span class="number">52</span>],</span><br><span class="line">                [<span class="number">92</span>, <span class="number">70</span>, <span class="number">21</span>, <span class="number">693</span>],</span><br><span class="line">            ]</span><br><span class="line">        )</span><br><span class="line">        labels = np.array([<span class="number">1</span>, <span class="number">0</span>, <span class="number">0</span>, <span class="number">1</span>, <span class="number">0</span>, <span class="number">0</span>, <span class="number">1</span>, <span class="number">1</span>, <span class="number">1</span>, <span class="number">0</span>])</span><br><span class="line">        <span class="keyword">return</span> data, labels</span><br></pre></td></tr></table></figure></li>
<li><p>训练朴素贝叶斯算法模型</p>
<p>由于使用的数据为连续型变量，所以采用高斯模型。</p>
<p>遍历数据集，计算每种账户类型下的每列特征属性对应的均值和方差，并赋值给<code>self.classP_feature()</code>，为下一步预测做准备。</p>
<p><code>self.classP_feature()</code>对应一个字典数据结构，用来存放每个<code>label</code>下每个特征标签对应的高斯分布中的均值和方差，字典的数据结构为：<code>&#123;label:&#123;feature1:&#123;mean:0.2,var:0.8&#125;,feature2:&#123;mean:0.1,var:0.8&#125;&#125;,label2:&#123;....&#125;&#125;</code>。</p>
<p>实现代码为：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">def</span> <span class="title function_">calMuandSigma</span>(<span class="params">self,feature</span>):</span><br><span class="line">    mu = np.mean(feature)</span><br><span class="line">    sigma = np.std(feature)</span><br><span class="line">    <span class="keyword">return</span> (mu,sigma)</span><br><span class="line">   </span><br><span class="line"><span class="keyword">def</span> <span class="title function_">train</span>(<span class="params">self, data, labels</span>):</span><br><span class="line">    numData = <span class="built_in">len</span>(labels)</span><br><span class="line">    numFeatures = <span class="built_in">len</span>(data[<span class="number">0</span>])</span><br><span class="line">    <span class="comment">#异常用户，用1表示</span></span><br><span class="line">    self.classP[<span class="number">1</span>] = (</span><br><span class="line">        (<span class="built_in">sum</span>(labels) + self.alpha ) * <span class="number">1.0</span> / (numData + self.alpha * <span class="built_in">len</span>(<span class="built_in">set</span>(labels)))</span><br><span class="line">   </span><br><span class="line">    )</span><br><span class="line">   </span><br><span class="line">    self.classP[<span class="number">0</span>] = <span class="number">1</span> - self.classP[<span class="number">1</span>]</span><br><span class="line">   </span><br><span class="line">    <span class="keyword">for</span> c <span class="keyword">in</span> <span class="built_in">set</span>(labels):</span><br><span class="line">        self.classP_feature[c] = &#123;&#125;</span><br><span class="line">        <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(numFeatures):</span><br><span class="line">            feature = data[np.equal(labels, c)][:, i ]</span><br><span class="line">            self.classP_feature[c][i] = self.calMuandSigma(feature)</span><br></pre></td></tr></table></figure></li>
<li><p>实现对新用户的预测</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">def</span> <span class="title function_">gaussian</span>(<span class="params">self, mu, sigma, x</span>):</span><br><span class="line">     <span class="keyword">return</span> <span class="number">1.0</span>/ ( sigma * np.sqrt(<span class="number">2</span> * np.pi)) * np.exp(- (x - mu) ** <span class="number">2</span> / (<span class="number">2</span> * sigma ** <span class="number">2</span>))</span><br><span class="line">   </span><br><span class="line"> <span class="keyword">def</span> <span class="title function_">predict</span>(<span class="params">self, x</span>):</span><br><span class="line">     label  = -<span class="number">1</span></span><br><span class="line">     maxP = <span class="number">0</span></span><br><span class="line">   </span><br><span class="line">     <span class="keyword">for</span> key <span class="keyword">in</span> self.classP.keys():</span><br><span class="line">         label_p = self.classP[key]</span><br><span class="line">         currentP = <span class="number">1.0</span></span><br><span class="line">         feature_p = self.classP_feature[key]</span><br><span class="line">         j = <span class="number">0</span></span><br><span class="line">         <span class="keyword">for</span> fp <span class="keyword">in</span> feature_p.keys():</span><br><span class="line">             currentP *= self.gaussian(feature_p[fp][<span class="number">0</span>], feature_p[fp][<span class="number">1</span>], x[j])</span><br><span class="line">             j += <span class="number">1</span></span><br><span class="line">         <span class="keyword">if</span> currentP * label_p &gt; maxP:</span><br><span class="line">             maxP = currentP * label_p</span><br><span class="line">             label = key</span><br><span class="line">     <span class="keyword">return</span> label</span><br></pre></td></tr></table></figure></li>
<li><p>结果分析</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">if</span> __name__ == <span class="string">&quot;__main__&quot;</span>:</span><br><span class="line">    nb = NaiveBayesian(<span class="number">1.0</span>)</span><br><span class="line">    data, labels = nb.createData()</span><br><span class="line">    nb.train(data,labels)</span><br><span class="line">    new = np.array([<span class="number">134</span>, <span class="number">84</span>, <span class="number">235</span>, <span class="number">349</span>])</span><br><span class="line">    label = nb.predict(new)</span><br><span class="line">    <span class="built_in">print</span>(<span class="string">&quot;未知用户&#123;&#125;对应的行为数据为&#123;&#125;&quot;</span>.<span class="built_in">format</span>(new,label))</span><br></pre></td></tr></table></figure>

<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">未知用户[134  84 235 349]对应的行为数据为1</span><br></pre></td></tr></table></figure></li>
</ol>
<h5 id="分类器的评估"><a href="#分类器的评估" class="headerlink" title="分类器的评估"></a>分类器的评估</h5><p>分类算法的主要评估指标有==准确率（Accuracy）==，==精确率（Precision）==，==召回率（Recall）==和==F-Score==。</p>
<p><img src="image-20210716113841664.png" alt="image-20210716113841664"></p>
<p><code>True</code>和<code>False</code>代表判别结果是否正确，<code>Positive</code>和<code>Negative</code>代表被程序找出的结果。</p>
<ul>
<li>TP（True Positive）：实际为正样本，预测结果也为正样本</li>
<li>FP（False Positive）：实际为负样本，预测结果为正样本</li>
<li>TN（True Negative）：实际为正样本，预测结果为负样本</li>
<li>FN（False Negative）：实际为负样本，预测结果也为负样本</li>
</ul>
<ol>
<li><p>准确率</p>
<p>准确率是对于给定的测试数据集，分类器正确分类的样本数目与总样本数目之比。<br>$$<br>A=\frac{TN+TP}{TP+FP+TN+FN}<br>$$</p>
</li>
<li><p>精确率</p>
<p>精确率是预测结果中符合实际值的比例。即在判别结果中，被分类器判定为正样本中真正为正样本的比例。<br>$$<br>P=\frac{TP}{TP+FP}<br>$$</p>
</li>
<li><p>召回率</p>
<p>召回率是正确分类的数量与所有“应该”被正确分类的数量的比例。<br>$$<br>R=\frac{TP}{TP+FN}<br>$$</p>
</li>
<li><p>F-Score</p>
<p>F-Score是精确率和召回率的调和均值。<br>$$<br>F=(1+\beta^2)×\frac{Precision×Recall}{\beta^2×Precision+Recall}<br>$$<br>$\beta$用来权衡$Precision$和$Recall$在$F-Score$中的权重，取值有三种情况。</p>
<p>$\beta=1$：$Precision$和$Recall$一样重要</p>
<p>$\beta&lt;1$：$Precision$比$Recall$重要</p>
<p>$\beta&gt;1$：$Recall$比$Precision$重要</p>
</li>
</ol>
<p>举例：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> sklearn.metrics <span class="keyword">import</span> classification_report</span><br><span class="line"></span><br><span class="line">y_true = [<span class="number">0</span>,<span class="number">1</span>,<span class="number">2</span>,<span class="number">2</span>,<span class="number">2</span>]</span><br><span class="line">y_pred = [<span class="number">0</span>,<span class="number">0</span>,<span class="number">2</span>,<span class="number">2</span>,<span class="number">1</span>]</span><br><span class="line"></span><br><span class="line">target_names = [<span class="string">&#x27;class0&#x27;</span>, <span class="string">&#x27;class1&#x27;</span>, <span class="string">&#x27;class2&#x27;</span>]</span><br><span class="line"><span class="built_in">print</span>(classification_report(y_true,y_pred,target_names=target_names))</span><br></pre></td></tr></table></figure>

<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">              precision    recall  f1-score   support</span><br><span class="line"></span><br><span class="line">      class0       0.50      1.00      0.67         1</span><br><span class="line">      class1       0.00      0.00      0.00         1</span><br><span class="line">      class2       1.00      0.67      0.80         3</span><br><span class="line"></span><br><span class="line">    accuracy                           0.60         5</span><br><span class="line">   macro avg       0.50      0.56      0.49         5</span><br><span class="line">weighted avg       0.70      0.60      0.61         5</span><br></pre></td></tr></table></figure>

<h4 id="数据聚类"><a href="#数据聚类" class="headerlink" title="数据聚类"></a>数据聚类</h4><p>聚类算法也是数据挖掘中常用的算法之一，属于无监督学习算法（Unsupervised Learning）。</p>
<p>在实际中，会利用聚类算法对基础数据进行处理，或者做一些基础模型共推荐系统使用。</p>
<h5 id="KMeans算法"><a href="#KMeans算法" class="headerlink" title="KMeans算法"></a>KMeans算法</h5><h6 id="KMeans介绍及执行步骤"><a href="#KMeans介绍及执行步骤" class="headerlink" title="KMeans介绍及执行步骤"></a>KMeans介绍及执行步骤</h6><p>KMeans算法的==基本原理==：</p>
<p>（1）随机初始化K个初始簇类中心，对应K个初始簇类，按照“距离最近”原则，将每条数据都划分到最近的簇类；</p>
<p>（2）第一次迭代之后，更新各个簇类中心，然后进行第二次迭代，依旧按照“距离最近”原则原则进行数据归类；</p>
<p>（3）直至簇类中心不再改变，或者前后变化小于给定的误差值，或者达到迭代次数，才停止迭代。</p>
<p>具体的==执行步骤==：</p>
<p>（1）在数据集中初始K个簇类中心，对应K个初始簇类；</p>
<p>（2）计算给定数据集中每条数据到K个簇类中心的距离；</p>
<p>（3）按照“距离最近”原则，将每条数据都划分到最近的簇类中；</p>
<p>（4）更新每个簇类的中心；</p>
<p>（5）迭代执行步骤（2）~步骤（4），直至簇类中心不再改变，或者变化小于给定的误差区间，或者达到迭代次数；</p>
<p>（6）结束算法，输出最后的簇类中心和对应的簇类。</p>
<h6 id="初始簇类中心的选择"><a href="#初始簇类中心的选择" class="headerlink" title="初始簇类中心的选择"></a>初始簇类中心的选择</h6><p>（1）随机选取</p>
<p>随机选取是最简单的方法，但是也有技巧的。</p>
<p>对于二维平面上的点，可以==可视化到二维平面上==，然后用肉眼进行判断，从而确定。</p>
<p>对于一些利用特征值进行聚类的数据，可以将其量化到二维或三维空间中，通过肉眼判断（高维数据，可以先降维，再可视化）。</p>
<p>随机选择法，假设有M行数据，可以使用<code>random</code>模块来随机选取K行作为初始簇类中心。</p>
<p>（2）初始聚类</p>
<p>首先选用==层次聚类法==或==Canopy==算法进行初始聚类，然后将这些簇类中心作为KMeans算法初始簇类中心。常用的层次聚类算法有<code>Birch</code>、<code>Rock</code>、<code>Canopy</code>。</p>
<p>层次聚类的思想是：一层一层地进行聚类，可以自下而上地把小的<code>cluster</code>合并聚集，也可以从上而下地将大的<code>cluster</code>进行分割。一般用的多的是从下而上地聚类。</p>
<p>自下而上的聚类就是，每次找到距离最短的两个<code>cluster</code>，然后将其合并成一个大的<code>cluster</code>，直至全部合并为一个<code>cluster</code>。</p>
<p>==Canopy==算法的主要过程是：</p>
<p>a. 定义两个具体$T_1$和$T_2$，$T_1&gt;T_2$。从初始的点的集合S中随机移除一个点P；</p>
<p>b. 对于还在S中的每个点$I$，计算出該点$I$与点$P$之间的距离；</p>
<p>如果距离小于$T_1$，则将点$I$加入到点$P$所代表的Canopy中；</p>
<p>如果距离小于$T_2$，则将点$I$从集合$S$中移除，并将点$I$加入到点$P$所代表的Canopy中。</p>
<p>c. 迭代一次后，重新从集合$S$中随机选择一个点作为新的点$P$，然后重复执行以上步骤。</p>
<p>Canopy算法执行完毕后会得到很多Canopy，可以认为每个Canopy都是一个Cluster。</p>
<p>（3）平均质心距离的加权平均值</p>
<p>首先随机选出一个点，然后选取与这个点距离最大的点作为第二个点，再选出与这两个点的最近距离作为第三个点。依次类推，选出K个点。</p>
<h6 id="K值的确定"><a href="#K值的确定" class="headerlink" title="K值的确定"></a>K值的确定</h6><p>调试K值并对结果进行评测，从而判断最优K值，并将其应用到实际模型中。给定一个合适的簇类指标，如平均半径或直径。</p>
<p>簇类的直径是指簇类内任意两个点之间的最大距离；簇类的半径是指簇类内所有点到簇类中心距离的最大值。</p>
<h6 id="最近原则"><a href="#最近原则" class="headerlink" title="最近原则"></a>最近原则</h6><p>即两条数据之间的相似度。</p>
<h6 id="更新簇类中心"><a href="#更新簇类中心" class="headerlink" title="更新簇类中心"></a>更新簇类中心</h6><p>更新簇类中心的办法是求平均值。</p>
<p>这里的平均值并不一定是真实存在的数据，很有可能是一个虚拟数据。</p>
<h6 id="停止簇类的条件"><a href="#停止簇类的条件" class="headerlink" title="停止簇类的条件"></a>停止簇类的条件</h6><p>一般来说，停止簇类的条件是：簇类中心更新前后不发生变化。</p>
<p>其他约束条件是中心误差和迭代次数。</p>
<h5 id="基于KMeans算法进行商品价格聚类"><a href="#基于KMeans算法进行商品价格聚类" class="headerlink" title="基于KMeans算法进行商品价格聚类"></a>基于KMeans算法进行商品价格聚类</h5><p>在店上网站中，商品数目很多，对应商品价格很多。但用户来说，并不是所有价格都感兴趣。因此需要对商品价格进行聚类，进而求出用户感兴趣的价格段，从而提高推荐系统的准确度和可信赖度。</p>
<ol>
<li><p>准备数据</p>
<p>新建一个<code>kMeans</code>类，并加载数据集。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="keyword">import</span> pandas <span class="keyword">as</span> pd</span><br><span class="line"><span class="keyword">import</span> random</span><br><span class="line"></span><br><span class="line"><span class="keyword">class</span> <span class="title class_">kMeans</span>:</span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__init__</span>(<span class="params">self</span>):</span><br><span class="line">        <span class="keyword">pass</span></span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">loadData</span>(<span class="params">self, file</span>):</span><br><span class="line">        <span class="keyword">return</span> pd.read_csv(file, header=<span class="number">0</span>, sep=<span class="string">&quot;,&quot;</span>)</span><br><span class="line">    </span><br></pre></td></tr></table></figure></li>
<li><p>去除异常值</p>
<p>在实际场景中，商品价格范围很大。那些价格过高或者过低的价格，对用户来说是没意义的。</p>
<p>在本次实验中，去除异常值的办法是：使用正态分布的99.73%的置信区间，即$(\mu-3\sigma,\mu+3\sigma)$。另外，还可以手动设置最大异常值边界和最小异常值边界。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">def</span> <span class="title function_">filterAnomalyValue</span>(<span class="params">self, data</span>):</span><br><span class="line">    upper = np.mean(data[<span class="string">&quot;price&quot;</span>]) + <span class="number">3</span> * np.std(data[<span class="string">&quot;price&quot;</span>])</span><br><span class="line">    lower = np.mean(data[<span class="string">&quot;price&quot;</span>]) - <span class="number">3</span> * np.std(data[<span class="string">&quot;price&quot;</span>])</span><br><span class="line">    upper_limit = upper <span class="keyword">if</span> upper &gt; <span class="number">5000</span> <span class="keyword">else</span> <span class="number">5000</span></span><br><span class="line">    lower_limit = lower <span class="keyword">if</span> lower &gt; <span class="number">1</span> <span class="keyword">else</span> <span class="number">1</span></span><br><span class="line">    <span class="built_in">print</span>(<span class="string">&quot;最大异常值为：&#123;&#125;, 最小异常值为：&#123;&#125;&quot;</span>.<span class="built_in">format</span>(upper_limit,lower_limit))</span><br><span class="line">    newData = data[(data[<span class="string">&quot;price&quot;</span>] &lt; upper_limit) &amp; (data[<span class="string">&quot;price&quot;</span>] &gt; lower_limit)]</span><br><span class="line">    <span class="keyword">return</span> newData, upper_limit, lower_limit</span><br></pre></td></tr></table></figure></li>
<li><p>初始化聚类中心</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">def</span> <span class="title function_">initCenters</span>(<span class="params">self, values, K,Cluster</span>):</span><br><span class="line">    random.seed(<span class="number">100</span>)</span><br><span class="line">    oldCenters = <span class="built_in">list</span>()</span><br><span class="line">    <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(K):</span><br><span class="line">        index = random.randint(<span class="number">0</span>, <span class="built_in">len</span>(values))</span><br><span class="line">        Cluster.setdefault(i, &#123;&#125;)</span><br><span class="line">        Cluster[i][<span class="string">&quot;center&quot;</span>] = values[index]</span><br><span class="line">        Cluster[i][<span class="string">&quot;values&quot;</span>] = []</span><br><span class="line">        </span><br><span class="line">        oldCenters.append(values[index])</span><br><span class="line">    <span class="keyword">return</span> oldCenters, Cluster</span><br></pre></td></tr></table></figure></li>
<li><p>进行聚类</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">def</span> <span class="title function_">distance</span>(<span class="params">self, price1, price2</span>):</span><br><span class="line">    <span class="keyword">return</span> np.emath.sqrt(<span class="built_in">pow</span>(price1 - price2, <span class="number">2</span>))</span><br><span class="line">   </span><br><span class="line"><span class="keyword">def</span> <span class="title function_">kMeans</span>(<span class="params">self, data, K, maxIters</span>):</span><br><span class="line">    Cluster = <span class="built_in">dict</span>() <span class="comment">#最终结果</span></span><br><span class="line">    oldCenters, Cluster = self.initCenters(data, K, Cluster)</span><br><span class="line">    <span class="built_in">print</span>(<span class="string">&quot;初始的簇类中心为：&#123;&#125;&quot;</span>.<span class="built_in">format</span>(oldCenters))</span><br><span class="line">    clusterChanged = <span class="literal">True</span> <span class="comment">#标志变量，控制继续迭代。</span></span><br><span class="line">    i = <span class="number">0</span></span><br><span class="line">    <span class="keyword">while</span> clusterChanged:</span><br><span class="line">        <span class="keyword">for</span> price <span class="keyword">in</span> data:</span><br><span class="line">            minDistance = np.inf</span><br><span class="line">            min_Index = -<span class="number">1</span></span><br><span class="line">            <span class="keyword">for</span> key <span class="keyword">in</span> Cluster.keys():</span><br><span class="line">                <span class="comment">#计算每天数据到簇类中心的距离</span></span><br><span class="line">                dis = self.distance(price, Cluster[key][<span class="string">&quot;center&quot;</span>])</span><br><span class="line">                <span class="keyword">if</span> dis &lt; minDistance:</span><br><span class="line">                    minDistance = dis</span><br><span class="line">                    min_Index = key</span><br><span class="line">            Cluster[min_Index][<span class="string">&quot;values&quot;</span>].append(price)</span><br><span class="line">   </span><br><span class="line">        newCenters = <span class="built_in">list</span>()</span><br><span class="line">        <span class="keyword">for</span> key <span class="keyword">in</span> Cluster.keys():</span><br><span class="line">            newCenter = np.mean(Cluster[key][<span class="string">&quot;values&quot;</span>])</span><br><span class="line">            Cluster[key][<span class="string">&quot;center&quot;</span>] = newCenter</span><br><span class="line">            newCenters.append(newCenter)</span><br><span class="line">        <span class="built_in">print</span>(<span class="string">&quot;第&#123;&#125;次迭代后的簇类中心为：&#123;&#125;&quot;</span>.<span class="built_in">format</span>(i ,newCenters))</span><br><span class="line">        <span class="keyword">if</span> oldCenters == newCenters  <span class="keyword">or</span> i &gt; maxIters:</span><br><span class="line">            clusterChanged = <span class="literal">False</span></span><br><span class="line">        <span class="keyword">else</span>:</span><br><span class="line">            oldCenters = newCenters</span><br><span class="line">            i += <span class="number">1</span></span><br><span class="line">            <span class="keyword">for</span> key <span class="keyword">in</span> Cluster.keys():</span><br><span class="line">                Cluster[key][<span class="string">&quot;values&quot;</span>] = []</span><br><span class="line">    <span class="keyword">return</span> Cluster</span><br></pre></td></tr></table></figure>

<p>主函数调用。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">if</span> __name__ == <span class="string">&quot;__main__&quot;</span>:</span><br><span class="line">    file = <span class="string">&quot;skuid_price.csv&quot;</span></span><br><span class="line">    km = kMeans()</span><br><span class="line">    data = km.loadData(file)</span><br><span class="line">    newData, upper_limit, lower_limit = km.filterAnomalyValue(data)</span><br><span class="line">    Cluster = km.kMeans(newData[<span class="string">&quot;price&quot;</span>].values, K=<span class="number">7</span>, maxIters=<span class="number">200</span>)</span><br><span class="line">    <span class="built_in">print</span>(Cluster)</span><br></pre></td></tr></table></figure></li>
</ol>
<h5 id="聚类算法的评估"><a href="#聚类算法的评估" class="headerlink" title="聚类算法的评估"></a>聚类算法的评估</h5><p>在无类别的情况下，常见的评价指标有紧密型、间隔性、戴维森堡丁指数、邓恩指数。在有标签的情况下，评价指标有准确性、兰德指数、F-Score。</p>
<h5 id="关联分析（暂时跳过）"><a href="#关联分析（暂时跳过）" class="headerlink" title="关联分析（暂时跳过）"></a>关联分析（暂时跳过）</h5><h4 id="基于用户行为特征的推荐"><a href="#基于用户行为特征的推荐" class="headerlink" title="基于用户行为特征的推荐"></a>基于用户行为特征的推荐</h4><h5 id="用户行为分类"><a href="#用户行为分类" class="headerlink" title="用户行为分类"></a>用户行为分类</h5><p>用户行为分为两种，==显性反馈行为==和==隐性反馈行为==。</p>
<p>显性反馈行为是指，用户很明显地表达出自己的喜好，如对内容评分、表示喜欢、不喜欢等。例如，豆瓣电影中的评分机制和YouTube中的“点赞”功能都是典型的显性反馈行为。==数据量小，但是表达含义明确，数据可以实时获取。==</p>
<p>隐性反馈行为是指，用户不明确表达出自己的喜好信息。==数据量大，表达含义不明确，数据获取有一定的延迟。==</p>
<h5 id="基于内容的推荐算法"><a href="#基于内容的推荐算法" class="headerlink" title="基于内容的推荐算法"></a>基于内容的推荐算法</h5><p>基于内容的推荐算法，根据用户过去一段时间内喜欢的物品，以及由此推算出来用户偏好，为用户推荐相似物品。</p>
<p><img src="image-20210716160451026.png" alt="image-20210716160451026"></p>
<h6 id="算法原理-从“构造特征”到“判断用户是否喜欢”"><a href="#算法原理-从“构造特征”到“判断用户是否喜欢”" class="headerlink" title="算法原理-从“构造特征”到“判断用户是否喜欢”"></a>算法原理-从“构造特征”到“判断用户是否喜欢”</h6><p>基于内容（Content Based, CB）的推荐原理非常简单：向用户推荐所喜欢的<code>Item</code>的<code>相似Item</code>。</p>
<p>（1）构造<code>Item</code>的特征；</p>
<p>（2）计算<code>Item</code>之间的相似度；</p>
<p>（3）评判用户是否喜欢某个<code>Item</code>。</p>
<h6 id="对手机属性进行特征建模"><a href="#对手机属性进行特征建模" class="headerlink" title="对手机属性进行特征建模"></a>对手机属性进行特征建模</h6><ol>
<li><p>认识结构化数据</p>
<p>==离散型数据==：只能采用自然数或整数单位计算的变量。例如，商品属性中的唯一编码，虽然是一个整数，但是在数值上没有意义，只是一个唯一表示。</p>
<p>==连续型数据==：在一定区间内可以任意取值的变量。例如商品属性中的长度为125.4cm，宽度为40.2cm。</p>
<table>
<thead>
<tr>
<th align="center">商品</th>
<th align="center">颜色</th>
<th align="center">尺寸</th>
<th align="center">内存</th>
<th align="center">价格</th>
</tr>
</thead>
<tbody><tr>
<td align="center">iPhone 5</td>
<td align="center">金色</td>
<td align="center">4寸</td>
<td align="center">16G</td>
<td align="center">1358元</td>
</tr>
<tr>
<td align="center">iPhone 6</td>
<td align="center">银色</td>
<td align="center">4.7寸</td>
<td align="center">32G</td>
<td align="center">2788元</td>
</tr>
<tr>
<td align="center">iPhone 6s Plus</td>
<td align="center">白色</td>
<td align="center">5.5寸</td>
<td align="center">64G</td>
<td align="center">3656元</td>
</tr>
</tbody></table>
<p>先对离散型数据（颜色和内存）进行<code>One-Hot</code>编码。</p>
<p>颜色：[金色，银色，白色]</p>
<p>内存：[16G，32G，64G]</p>
<p>对iPhone 5进行<code>One-Hot</code>编码：金色对应[1, 0, 0]，银色对应[0, 1, 0]，白色对应[0, 0, 1]；16G对应[1, 0, 0]，32G对应[0, 0, 1], 64G对应为[0, 0, 1]。</p>
<p>则iPhone 5的离散型属性特征（金色16G）的完整<code>One-Hot</code>编码为[1, 0, 0, 1, 0, 0]。</p>
<p>代码实现：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> sklearn <span class="keyword">import</span> preprocessing</span><br><span class="line"></span><br><span class="line">onehot = preprocessing.OneHotEncoder()</span><br><span class="line">onehot.fit(</span><br><span class="line">    [</span><br><span class="line">        [<span class="number">0</span>, <span class="number">0</span>], [<span class="number">0</span>, <span class="number">1</span>], [<span class="number">0</span>, <span class="number">2</span>], [<span class="number">1</span>, <span class="number">0</span>], [<span class="number">1</span>, <span class="number">1</span>], [<span class="number">1</span>, <span class="number">2</span>], [<span class="number">2</span>, <span class="number">0</span>], [<span class="number">2</span>, <span class="number">1</span>], [<span class="number">2</span>, <span class="number">2</span>]</span><br><span class="line">    ]</span><br><span class="line">)</span><br><span class="line"><span class="built_in">print</span>(onehot.transform([[<span class="number">0</span>,<span class="number">0</span>]]).toarray())</span><br></pre></td></tr></table></figure>

<p>或者只用包含数据每类属性的每个维度即可，</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> sklearn <span class="keyword">import</span> preprocessing</span><br><span class="line"></span><br><span class="line">onehot = preprocessing.OneHotEncoder()</span><br><span class="line">onehot.fit(</span><br><span class="line">    [</span><br><span class="line">        [<span class="number">0</span>, <span class="number">0</span>], [<span class="number">1</span>, <span class="number">1</span>],  [<span class="number">2</span>, <span class="number">2</span>]</span><br><span class="line">    ]</span><br><span class="line">)</span><br><span class="line"><span class="built_in">print</span>(onehot.transform([[<span class="number">0</span>,<span class="number">0</span>]]).toarray())</span><br></pre></td></tr></table></figure>

<p>输出结果：</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">[[1. 0. 0. 1. 0. 0.]]</span><br></pre></td></tr></table></figure>



<p>然后对连续型数据（尺寸和价格）进行 0-1标准化，使其特征值落入<code>0~1</code>之间。例如针对手机尺寸特征，采用<code>Min-Max标准化</code>得到iPhone 5、iPhone 6和iPhone 6s Plus的特征值为：[0, 0.4667, 1.0]。</p>
<p>代码实现：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="keyword">def</span> <span class="title function_">MaxMinNormalization</span>(<span class="params">x</span>):</span><br><span class="line">    Max = np.<span class="built_in">max</span>(x)</span><br><span class="line">    Min = np.<span class="built_in">min</span>(x)</span><br><span class="line">    new = []</span><br><span class="line">    <span class="keyword">for</span> i <span class="keyword">in</span> x:</span><br><span class="line">        l = np.<span class="built_in">round</span>(( i- Min) / (Max - Min), <span class="number">4</span> )</span><br><span class="line">        new.append(l)</span><br><span class="line">    <span class="keyword">return</span> new</span><br><span class="line"></span><br><span class="line">sizes = [<span class="number">4</span>, <span class="number">4.7</span>, <span class="number">5.5</span>]</span><br><span class="line">prices = [<span class="number">1358</span>, <span class="number">2788</span>, <span class="number">3656</span>]</span><br><span class="line">nor_size = MaxMinNormalization(sizes)</span><br><span class="line">nor_prices = MaxMinNormalization(prices)</span><br><span class="line"><span class="built_in">print</span>(<span class="string">&quot;尺寸&#123;&#125;经过最大最小标准化后为&#123;&#125;&quot;</span>.<span class="built_in">format</span>(sizes,nor_size))</span><br><span class="line"><span class="built_in">print</span>(<span class="string">&quot;价格&#123;&#125;经过最大最小标准化后为&#123;&#125;&quot;</span>.<span class="built_in">format</span>(prices,nor_prices))</span><br></pre></td></tr></table></figure>

<p>输出结果：</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">尺寸[4, 4.7, 5.5]经过最大最小标准化后为[0.0, 0.4667, 1.0]</span><br><span class="line">价格[1358, 2788, 3656]经过最大最小标准化后为[0.0, 0.6223, 1.0]</span><br></pre></td></tr></table></figure></li>
</ol>
<h5 id="一个基于内容推荐算法的电影推荐系统"><a href="#一个基于内容推荐算法的电影推荐系统" class="headerlink" title="一个基于内容推荐算法的电影推荐系统"></a>一个基于内容推荐算法的电影推荐系统</h5><p>   当<code>Item</code>数目很多时，计算每两个<code>Item</code>之间的相似度所产生的算法复杂度是很高的，所以进行以下优化：首先使用训练数据得到用户的偏好信息矩阵和物品的特征信息矩阵，然后计算用户对未进行评分电影的偏好分，选取前K个推荐给用户。</p>
<ol>
<li><p>构建电影的特征信息矩阵</p>
<p>如：</p>
<ul>
<li>A电影的类型为：<code>Animation|Children&#39;s|Comedy</code></li>
<li>B电影的类型为：<code>Adventure|Children&#39;s|Fantasy</code></li>
</ul>
</li>
</ol>
<p>   假设电影类型为[Adventure, Animation, Comedy, Children’s, Fantasy]中的一种或几种。</p>
<p>   则A电影为[0, 1, 1, 1, 0]，B电影为[1, 0, 0, 1, 1]。</p>
<ol start="2">
<li>构建用户的偏好信息<table>
<thead>
<tr>
<th align="center">姓名</th>
<th align="center">《山楂树之恋》</th>
<th align="center">《芳华》</th>
<th align="center">《战狼2》</th>
</tr>
</thead>
<tbody><tr>
<td align="center">张三</td>
<td align="center">4</td>
<td align="center">5</td>
<td align="center">3</td>
</tr>
<tr>
<td align="center">李四</td>
<td align="center"></td>
<td align="center">1</td>
<td align="center">4</td>
</tr>
</tbody></table>
可以看出，张三更喜欢《山楂树之恋》和《芳华》这两部电影。假设这两部电影都属于青春类型，那么推断张三更喜欢清纯类型的电影，这样为张三构建偏好信息。根据下面的公式计算张三对青春类型电影的偏好程度。$x_i$:所有张三打过分的青春类型电影$avg$：张三对其评分的电影的平均分$n$：所有涉及青春类型的电影的个数则张三对青春类型电影的==偏好程度==为：$$<br>avg=\frac13×(4+5+3)=4<br>$$$$<br>\frac{1}{n}\sum_{i=1}^n(x_i-avg)=\frac12×[(4-4)+(5-4)]=0.5<br>$$<br>为用户建立偏好矩阵：矩阵中每个元素都表示用户对每种电影类型的偏好程度，如张三的偏好矩阵为[0.5, …]。</li>
<li>计算用户与每部电影的距离根据以下公式计算==用户与每部电影的距离==。<br>$$<br>cos(U,I)=\frac{\sum U_a×I_a}{\sqrt{(\sum U_a^2)×\sqrt{(\sum I_a^2)}}}<br>$$<br>$U_a$：用户对电影类型 a 的偏好程度$I_a$：电影是否属于类型 a， 即“构建电影的特征信息矩阵”中对应类型 a 的特征信息矩阵。</li>
</ol>
<p>使用MovieLens数据集进行实现：</p>
<ol>
<li><p>数据格式的转换</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> pandas <span class="keyword">as</span> pd</span><br><span class="line"><span class="keyword">import</span> json</span><br><span class="line"><span class="keyword">import</span> os</span><br><span class="line"></span><br><span class="line">base_dir = <span class="string">&quot;C:\\Users\\OAOA\\Desktop\\GXX的科研\\python\\FirstRec\\ml-1m&quot;</span></span><br><span class="line">user_data_dir = os.path.join(base_dir, <span class="string">&quot;users.dat&quot;</span>)</span><br><span class="line">movies_data_dir = os.path.join(base_dir, <span class="string">&quot;movies.dat&quot;</span>)</span><br><span class="line">rating_data_dir = os.path.join(base_dir, <span class="string">&quot;ratings.dat&quot;</span>)</span><br><span class="line">use_dir = os.path.join(base_dir, <span class="string">&quot;use&quot;</span>)</span><br><span class="line"></span><br><span class="line">csv_users_dir = os.path.join(use_dir, <span class="string">&quot;users.csv&quot;</span>)</span><br><span class="line">csv_movies_dir = os.path.join(use_dir, <span class="string">&quot;movies.csv&quot;</span>)</span><br><span class="line">csv_ratings_dir = os.path.join(use_dir, <span class="string">&quot;rating.csv&quot;</span>)</span><br><span class="line"></span><br><span class="line">item_profile_json_dir = os.path.join(base_dir, <span class="string">&quot;item_profile.json&quot;</span>)</span><br><span class="line">user_profile_json_dir = os.path.join(base_dir, <span class="string">&quot;user_profile.json&quot;</span>)</span><br><span class="line"></span><br><span class="line"><span class="keyword">try</span>:</span><br><span class="line">    os.mkdir(use_dir)</span><br><span class="line"><span class="keyword">except</span>:</span><br><span class="line">    <span class="keyword">pass</span></span><br><span class="line"><span class="keyword">class</span> <span class="title class_">DataProcessing</span>:</span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__init__</span>(<span class="params">self</span>):</span><br><span class="line">        <span class="keyword">pass</span></span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">process_user_data</span>(<span class="params">self, file= user_data_dir</span>):</span><br><span class="line">        fp = pd.read_table(file, sep=<span class="string">&quot;::&quot;</span>, engine=<span class="string">&#x27;python&#x27;</span>, names=[<span class="string">&quot;UserID&quot;</span>, <span class="string">&quot;Gender&quot;</span>, <span class="string">&quot;Age&quot;</span>, <span class="string">&quot;Occupation&quot;</span>, <span class="string">&quot;Zip-code&quot;</span>])</span><br><span class="line">        fp.to_csv(csv_users_dir, index=<span class="literal">False</span>)</span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">process_movies_data</span>(<span class="params">self, file= movies_data_dir</span>):</span><br><span class="line">        fp = pd.read_table(file, sep=<span class="string">&quot;::&quot;</span>, engine=<span class="string">&#x27;python&#x27;</span>, names=[<span class="string">&quot;MovieID&quot;</span>, <span class="string">&quot;Title&quot;</span>, <span class="string">&quot;Genres&quot;</span>])</span><br><span class="line">        fp.to_csv(csv_movies_dir, index=<span class="literal">False</span>)</span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">process_rating_data</span>(<span class="params">self, file= rating_data_dir</span>):</span><br><span class="line">        fp = pd.read_table(file, sep=<span class="string">&quot;::&quot;</span>, engine=<span class="string">&#x27;python&#x27;</span>, names=[<span class="string">&quot;UserID&quot;</span>, <span class="string">&quot;MovieID&quot;</span>, <span class="string">&quot;Rating&quot;</span>, <span class="string">&quot;Timestamp&quot;</span>])</span><br><span class="line">        fp.to_csv(csv_ratings_dir, index=<span class="literal">False</span>)</span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">process</span>(<span class="params">self</span>):</span><br><span class="line">        <span class="built_in">print</span>(<span class="string">&quot;开始转换用户数据（users.dat）...&quot;</span>)</span><br><span class="line">        self.process_user_data()</span><br><span class="line">        <span class="built_in">print</span>(<span class="string">&quot;开始转换电影数据（movies.dat）...&quot;</span>)</span><br><span class="line">        self.process_movies_data()</span><br><span class="line">        <span class="built_in">print</span>(<span class="string">&quot;开始转换用户对电影评分数据（ratings.dat）...&quot;</span>)</span><br><span class="line">        self.process_rating_data()</span><br><span class="line">        <span class="built_in">print</span>(<span class="string">&quot;Over!&quot;</span>)</span><br><span class="line"><span class="keyword">if</span> __name__ == <span class="string">&quot;__main__&quot;</span>:</span><br><span class="line">    dp = DataProcessing()</span><br><span class="line">    dp.process()</span><br></pre></td></tr></table></figure>

<p>输出结果：</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"></span><br><span class="line">开始转换用户数据（users.dat）...</span><br><span class="line">开始转换电影数据（movies.dat）...</span><br><span class="line">开始转换用户对电影评分数据（ratings.dat）...</span><br><span class="line">Over!</span><br></pre></td></tr></table></figure>
<p>2.计算电影的特征信息矩阵</p>
</li>
</ol>
<p>​      </p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">def</span> <span class="title function_">prepare_item_profile</span>(<span class="params">self, file=csv_movies_dir</span>):</span><br><span class="line">    items = pd.read_csv(file)</span><br><span class="line">    item_ids = <span class="built_in">set</span>(items[<span class="string">&quot;MovieID&quot;</span>].values)</span><br><span class="line">    self.item_dict = &#123;&#125;</span><br><span class="line">    genres_all = <span class="built_in">list</span>()</span><br><span class="line">    <span class="keyword">for</span> item <span class="keyword">in</span> item_ids:</span><br><span class="line">        genres = items[items[<span class="string">&quot;MovieID&quot;</span>]==item][<span class="string">&quot;Genres&quot;</span>].values[<span class="number">0</span>].split(<span class="string">&quot;|&quot;</span>)</span><br><span class="line">        self.item_dict.setdefault(item, []).extend(genres)</span><br><span class="line">        genres_all.extend(genres)</span><br><span class="line">    self.genres_all = <span class="built_in">set</span>(genres_all)</span><br><span class="line">    self.item_matrix = &#123;&#125;</span><br><span class="line">    <span class="keyword">for</span> item <span class="keyword">in</span> self.item_dict.keys():</span><br><span class="line">        self.item_matrix[<span class="built_in">str</span>(item)] = [<span class="number">0</span>] * <span class="built_in">len</span>(<span class="built_in">set</span>(self.genres_all))</span><br><span class="line">        <span class="keyword">for</span> genre <span class="keyword">in</span> self.item_dict[item]:</span><br><span class="line">            index = <span class="built_in">list</span>(<span class="built_in">set</span>(genres_all)).index(genre)</span><br><span class="line">            self.item_matrix[<span class="built_in">str</span>(item)][index] = <span class="number">1</span></span><br><span class="line">    <span class="comment">#item_profile_json_dir = os.path.join(base_dir, &quot;item_profile.json&quot;)</span></span><br><span class="line">    json.dump(self.item_matrix, <span class="built_in">open</span>(item_profile_json_dir, <span class="string">&#x27;w&#x27;</span>))</span><br><span class="line">    <span class="built_in">print</span>(<span class="string">&quot;item 信息计算完成， 保存路径为：&#123;&#125;&quot;</span>.<span class="built_in">format</span>(item_profile_json_dir))</span><br><span class="line"></span><br></pre></td></tr></table></figure>

 <figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">item 信息计算完成， 保存路径为：C:\Users\OAOA\Desktop\GXX的科研\python\FirstRec\ml-1m\item_profile.json</span><br></pre></td></tr></table></figure>

<ol start="3">
<li><p>计算用户的偏好矩阵</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">def</span> <span class="title function_">prepare_user_profile</span>(<span class="params">self,file=csv_ratings_dir</span>):</span><br><span class="line">    users = pd.read_csv(file)</span><br><span class="line">    user_ids = <span class="built_in">set</span>(users[<span class="string">&quot;UserID&quot;</span>].values)</span><br><span class="line">    users_rating_dict=&#123;&#125;</span><br><span class="line">    <span class="keyword">for</span> user <span class="keyword">in</span> user_ids:</span><br><span class="line">        users_rating_dict.setdefault(<span class="built_in">str</span>(user), &#123;&#125;)</span><br><span class="line">    <span class="keyword">with</span> <span class="built_in">open</span>(file, <span class="string">&quot;r&quot;</span>) <span class="keyword">as</span> fr:</span><br><span class="line">        <span class="keyword">for</span> line <span class="keyword">in</span> fr.readlines():</span><br><span class="line">            <span class="keyword">if</span> <span class="keyword">not</span> line.startswith(<span class="string">&quot;UserID&quot;</span>):</span><br><span class="line">                (user, item, rate) = line.split(<span class="string">&quot;,&quot;</span>)[:<span class="number">3</span>]</span><br><span class="line">                users_rating_dict[user][item]=<span class="built_in">int</span>(rate)</span><br><span class="line">    self.user_matrix=&#123;&#125;</span><br><span class="line">    <span class="keyword">for</span> user <span class="keyword">in</span> users_rating_dict.keys():</span><br><span class="line">        <span class="built_in">print</span>(<span class="string">&quot;user is &#123;&#125;&quot;</span>.<span class="built_in">format</span>(user))</span><br><span class="line">        score_list = users_rating_dict[user].values()</span><br><span class="line">        avg = <span class="built_in">sum</span>(score_list) / <span class="built_in">len</span>(score_list)</span><br><span class="line">        self.user_matrix[user] = []</span><br><span class="line">        <span class="keyword">for</span> genre <span class="keyword">in</span> self.genres_all:</span><br><span class="line">            score_all = <span class="number">0.0</span></span><br><span class="line">            score_len = <span class="number">0</span></span><br><span class="line">            <span class="keyword">for</span> item <span class="keyword">in</span> users_rating_dict[user].keys():</span><br><span class="line">                <span class="keyword">if</span> genre <span class="keyword">in</span> self.item_dict[<span class="built_in">int</span>(item)]:</span><br><span class="line">                    score_all += (users_rating_dict[user][item] - avg)</span><br><span class="line">                    score_len += <span class="number">1</span></span><br><span class="line">            <span class="keyword">if</span> score_len == <span class="number">0</span>:</span><br><span class="line">                self.user_matrix[user].append(<span class="number">0.0</span>)</span><br><span class="line">            <span class="keyword">else</span>:</span><br><span class="line">                self.user_matrix[user].append(score_all / score_len)</span><br><span class="line">    <span class="comment">#json_dir = os.path.join(base_dir, &quot;user_profile.json&quot;)</span></span><br><span class="line">    json.dump(self.user_matrix, <span class="built_in">open</span>(user_profile_json_dir, <span class="string">&quot;w&quot;</span>))</span><br><span class="line">    <span class="built_in">print</span>(<span class="string">&quot;User信息计算完成，保存路径为&#123;&#125;&quot;</span>.<span class="built_in">format</span>(user_profile_json_dir))</span><br></pre></td></tr></table></figure>

<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">user is 1</span><br><span class="line">user is 2</span><br><span class="line">user is 3</span><br><span class="line">user is 4</span><br><span class="line">user is 5</span><br><span class="line">...</span><br><span class="line">user is 6039</span><br><span class="line">user is 6040</span><br><span class="line">User信息计算完成，保存路径为C:\Users\OAOA\Desktop\GXX的科研\python\FirstRec\ml-1m\user_profile.json</span><br></pre></td></tr></table></figure></li>
<li><p>算法选择</p>
<p>选择基于内容的推荐算法，选用杰卡德相似系数来衡量两个<code>item</code>之间的相似度。</p>
</li>
<li><p>模型训练</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">class</span> <span class="title class_">CBRecommend</span>:</span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__init__</span>(<span class="params">self, K</span>):</span><br><span class="line">        self.K = K</span><br><span class="line">        self.item_profile = json.load(<span class="built_in">open</span>(item_profile_json_dir, <span class="string">&quot;r&quot;</span>))</span><br><span class="line">        self.user_profile = json.load(<span class="built_in">open</span>(user_profile_json_dir, <span class="string">&quot;r&quot;</span>))</span><br><span class="line"></span><br><span class="line">    <span class="comment">#获取用户未进行评分的item列表</span></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">get_none_score_item</span>(<span class="params">self, user</span>):</span><br><span class="line">        items = pd.read_csv(csv_movies_dir)[<span class="string">&quot;MovieID&quot;</span>].values</span><br><span class="line">        data = pd.read_csv(csv_ratings_dir)</span><br><span class="line">        have_score_items = data[data[<span class="string">&quot;UserID&quot;</span>]==user][<span class="string">&quot;MovieID&quot;</span>].values</span><br><span class="line">        none_score_items = <span class="built_in">set</span>(items) - <span class="built_in">set</span>(have_score_items)</span><br><span class="line">        <span class="keyword">return</span> none_score_items</span><br><span class="line"></span><br><span class="line">    <span class="comment">#获取用户对item的喜好程度</span></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">cosUI</span>(<span class="params">self, user, item</span>):</span><br><span class="line">        Uia = <span class="built_in">sum</span>(</span><br><span class="line"></span><br><span class="line">            np.array(self.user_profile[<span class="built_in">str</span>(user)])</span><br><span class="line">            *</span><br><span class="line">            np.array(self.item_profile[<span class="built_in">str</span>(item)])</span><br><span class="line">        )</span><br><span class="line">        Ua = math.sqrt(</span><br><span class="line">            <span class="built_in">sum</span>( [math.<span class="built_in">pow</span>(one, <span class="number">2</span>) <span class="keyword">for</span> one <span class="keyword">in</span> self.user_profile[<span class="built_in">str</span>(user)]])</span><br><span class="line">        )</span><br><span class="line">        Ia = math.sqrt(</span><br><span class="line">            <span class="built_in">sum</span>([math.<span class="built_in">pow</span>(one, <span class="number">2</span>) <span class="keyword">for</span> one <span class="keyword">in</span> self.item_profile[<span class="built_in">str</span>(item)]])</span><br><span class="line">        )</span><br><span class="line">        <span class="keyword">return</span> Uia / (Ua * Ia)</span><br><span class="line"></span><br><span class="line">    <span class="comment">#为用户进行电影推荐</span></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">recommend</span>(<span class="params">self, user</span>):</span><br><span class="line">        user_result = &#123;&#125;</span><br><span class="line">        item_list = self.get_none_score_item(user)</span><br><span class="line">        <span class="keyword">for</span> item <span class="keyword">in</span> item_list:</span><br><span class="line">            user_result[item] = self.cosUI(user, item)</span><br><span class="line">        <span class="keyword">if</span> self.K <span class="keyword">is</span> <span class="literal">None</span>:</span><br><span class="line">            result = <span class="built_in">sorted</span>(user_result.items(), key= <span class="keyword">lambda</span> k:k[<span class="number">1</span>], reverse=<span class="literal">True</span>)</span><br><span class="line">        <span class="keyword">else</span>:</span><br><span class="line">            result = <span class="built_in">sorted</span>(user_result.items(), key= <span class="keyword">lambda</span> k:k[<span class="number">1</span>], reverse=<span class="literal">True</span>)[:self.K]</span><br><span class="line">        <span class="built_in">print</span>(result)</span><br><span class="line"></span><br><span class="line"><span class="keyword">if</span> __name__ == <span class="string">&quot;__main__&quot;</span>:</span><br><span class="line">    cb = CBRecommend(K=<span class="number">8</span>)</span><br><span class="line">    cb.recommend(<span class="number">1</span>)</span><br></pre></td></tr></table></figure>

<p>输出结果：</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">[(632, 0.6832725491451497), (665, 0.6832725491451497), (760, 0.6832725491451497), (777, 0.6832725491451497), (1450, 0.6832725491451497), (1927, 0.6832725491451497), (2669, 0.6832725491451497), (2670, 0.6832725491451497)]</span><br></pre></td></tr></table></figure></li>
<li><p>效果评估</p>
<p>评价指标是：给用户推荐的电影和用户本身评分电影的交集与用户本身评分电影的数目比。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br></pre></td><td class="code"><pre><span class="line">    <span class="comment">#效果评估</span></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">evaluate</span>(<span class="params">self</span>):</span><br><span class="line">        evas = []</span><br><span class="line">        data = pd.read_csv(csv_ratings_dir)</span><br><span class="line">        <span class="comment">#随机选取20个用户进行效果评估</span></span><br><span class="line">        <span class="keyword">for</span> user <span class="keyword">in</span> random.sample([one <span class="keyword">for</span> one <span class="keyword">in</span> <span class="built_in">range</span>(<span class="number">1</span>,<span class="number">6041</span>)], <span class="number">20</span>):</span><br><span class="line">            have_score_items = data[data[<span class="string">&quot;UserID&quot;</span>] == user][<span class="string">&quot;MovieID&quot;</span>].values</span><br><span class="line">            items = pd.read_csv(csv_movies_dir)[<span class="string">&quot;MovieID&quot;</span>].values</span><br><span class="line">            user_result = &#123;&#125;</span><br><span class="line">            <span class="keyword">for</span> item <span class="keyword">in</span> items:</span><br><span class="line">                user_result[item] = self.cosUI(user, item)</span><br><span class="line">            results = <span class="built_in">sorted</span>(user_result.items(), key=<span class="keyword">lambda</span> k:k[<span class="number">1</span>], reverse=<span class="literal">True</span>)[:<span class="built_in">len</span>(have_score_items)]</span><br><span class="line">            rec_items = []</span><br><span class="line">            <span class="keyword">for</span> one <span class="keyword">in</span> results:</span><br><span class="line">                rec_items.append(one[<span class="number">0</span>])</span><br><span class="line">            eva = <span class="built_in">len</span>(<span class="built_in">set</span>(rec_items) &amp; <span class="built_in">set</span>(have_score_items)) / <span class="built_in">len</span>(have_score_items)</span><br><span class="line">            evas.append(eva)</span><br><span class="line">        <span class="keyword">return</span> <span class="built_in">sum</span>(evas) / <span class="built_in">len</span>(evas)</span><br><span class="line"><span class="keyword">if</span> __name__ == <span class="string">&quot;__main__&quot;</span>:</span><br><span class="line">    cb = CBRecommend(K=<span class="number">8</span>)</span><br><span class="line">    ans = cb.evaluate()</span><br><span class="line">    <span class="built_in">print</span>(<span class="string">&quot;基于内容推荐的算法的效果为&#123;&#125;%&quot;</span>.<span class="built_in">format</span>(ans * <span class="number">100</span>))</span><br></pre></td></tr></table></figure>

<p>输出结果为：</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">基于内容推荐的算法的效果为5.190809333481404%</span><br></pre></td></tr></table></figure></li>
</ol>
<h5 id="基于近邻的推荐算法"><a href="#基于近邻的推荐算法" class="headerlink" title="基于近邻的推荐算法"></a>基于近邻的推荐算法</h5><p>基于近邻的推荐算法是比较基础的推荐算法。</p>
<p>==基于近邻==的==协同过滤（Collaborative Filtering）==算法分为：</p>
<ul>
<li>基于用户的协同过滤（==User-CF-Based==）算法</li>
<li>基于物品的协同过滤（==Item-CF-Based==）算法</li>
</ul>
<p>协同过滤的核心思想就是寻找和用户品位差不多的用户进行推荐。</p>
<h6 id="UserCF的原理–先找到相似用户，再找到喜欢的物品"><a href="#UserCF的原理–先找到相似用户，再找到喜欢的物品" class="headerlink" title="UserCF的原理–先找到相似用户，再找到喜欢的物品"></a>UserCF的原理–先找到相似用户，再找到喜欢的物品</h6><p>基于用户的协同过滤通过用户的历史行为数据发现用户喜欢的物品，并对这些偏好进行度量和打分，然后根据不同用户对相同物品的评分或偏好程度来评测用户之间的相似性，对有相同偏好的用户进行推荐。</p>
<p><img src="image-20210717105706237.png" alt="image-20210717105706237"></p>
<p>   假设有A、B、C、D四个用户，分别对a、b、c、d、e五个物品表达了自己的喜好程度（通过评分的高低来表现自己的偏好程度），现在要为C用户推荐物品：</p>
<p>（1）计算得到用户C的相似用户</p>
<p>（2）找到这些相似用户喜欢的但是C没有进行评分的物品并推荐给C</p>
<p>==实现过程==：</p>
<ol>
<li><p>构建用户物品评分表</p>
<table>
<thead>
<tr>
<th align="center">用户</th>
<th align="center">物品a</th>
<th align="center">物品b</th>
<th align="center">物品c</th>
<th align="center">物品d</th>
<th align="center">物品e</th>
</tr>
</thead>
<tbody><tr>
<td align="center">A</td>
<td align="center">3.0</td>
<td align="center">4.0</td>
<td align="center">0</td>
<td align="center">3.5</td>
<td align="center">0</td>
</tr>
<tr>
<td align="center">B</td>
<td align="center">4.0</td>
<td align="center">0</td>
<td align="center">4.5</td>
<td align="center">0</td>
<td align="center">3.5</td>
</tr>
<tr>
<td align="center">C</td>
<td align="center">0</td>
<td align="center">3.5</td>
<td align="center">0</td>
<td align="center">0</td>
<td align="center">3</td>
</tr>
<tr>
<td align="center">D</td>
<td align="center">0</td>
<td align="center">4</td>
<td align="center">0</td>
<td align="center">3.5</td>
<td align="center">3</td>
</tr>
</tbody></table>
</li>
<li><p>相似度计算</p>
<p>计算用户之间相似度的方法有很多，这里选择的是余弦相似度。<br>$$<br>W_{uv}=\frac{N(u)\cap N(v)}{\sqrt{|N(u)||N(v)|}}<br>$$<br>针对用户u和用户v，上述参数如下：</p>
<ul>
<li>$N(u)$：用户u有过评分的物品集合</li>
<li>$N(v)$：用户v有过评分的物品集合</li>
<li>$W_{uv}$：用户u和用户v的余弦相似度</li>
</ul>
<p>$$<br>W_{CA}=\frac{|b,e|\cap |a,b,d|}{\sqrt{|b,e||a,b,d|}}=\frac{1}{\sqrt6}<br>$$</p>
<p>$$<br>W_{CB}=\frac{|b,e|\cap |a,c,e|}{\sqrt{|b,e||a,c,e|}}=\frac{1}{\sqrt{6}}<br>$$</p>
<p>$$<br>W_{CD}=\frac{|b,e|\cap |b,d,e|}{|b,e||b,d,e|}=\frac{2}{\sqrt6}<br>$$</p>
<p>从计算结果来看，D用户和C用户相似度最大。</p>
<p>从表中也可以直接看出，用户D和用户都在b和e上进行了评分，用户A和用户C在物品b上进行了评分，用户B和用户C在物品e上进行了评分。</p>
</li>
<li><p>计算推荐结果</p>
<p>用户C进行评分的物品是b和e，接下来计算用户C对物品a，c，d的偏好程度。</p>
<p>计算公式为：<br>$$<br>P(u,i)=\sum_{v\in S(u,K)\cap N(i)}W_{uv}r_{vi}<br>$$</p>
<ul>
<li>$P(u,i)$：用户 $u$ 对物品$i$的感兴趣程度</li>
<li>$S(u,K)$：和用户 $u$ 最接近的$K$个用户</li>
<li>$N(i)$：对物品 $i$ 有过行为的用户集合</li>
<li>$W_{uv}$：用户 $u$ 和用户 $v$ 的兴趣相似度</li>
<li>$r_{vi}$：用户 $v$ 对物品 $i$ 的兴趣，即用户对物品的评分</li>
</ul>
<p>$$<br>P(C,a)=W_{CA}×3.0+W_{CB}×4.0+W_{CD}×0=2.858<br>$$</p>
<p>$$<br>P(C,c)=W_{CA}×0+W_{CB}×4.5+W_{CD}×0=1.837<br>$$</p>
<p>$$<br>P(C,d)=W_{CA}×3.5+W_{CB}×0+W_{CD}×3.5=4.287<br>$$</p>
<p>在用户C没有进行评分的物品中排序为$d&gt;a&gt;c$。这样就可以根据需要取前K个物品推荐给C用户。</p>
</li>
</ol>
<p>==代码实现==：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> math</span><br><span class="line"></span><br><span class="line"><span class="keyword">class</span> <span class="title class_">UserCF</span>:</span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__init__</span>(<span class="params">self</span>):</span><br><span class="line">        self.user_score_dict = self.initUserScore()</span><br><span class="line">        self.users_sim = self.userSimilarity()</span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">initUserScore</span>(<span class="params">self</span>):</span><br><span class="line">        user_score_dict = &#123;</span><br><span class="line">            <span class="string">&quot;A&quot;</span>:&#123;<span class="string">&quot;a&quot;</span>:<span class="number">3.0</span>, <span class="string">&quot;b&quot;</span>:<span class="number">4.0</span>, <span class="string">&quot;c&quot;</span>:<span class="number">0.0</span>, <span class="string">&quot;d&quot;</span>:<span class="number">3.5</span>, <span class="string">&quot;e&quot;</span>:<span class="number">0.0</span>&#125;,</span><br><span class="line">            <span class="string">&quot;B&quot;</span>:&#123;<span class="string">&quot;a&quot;</span>:<span class="number">4.0</span>, <span class="string">&quot;b&quot;</span>:<span class="number">0.0</span>, <span class="string">&quot;c&quot;</span>:<span class="number">4.5</span>, <span class="string">&quot;d&quot;</span>:<span class="number">0.0</span>, <span class="string">&quot;e&quot;</span>:<span class="number">3.5</span>&#125;,</span><br><span class="line">            <span class="string">&quot;C&quot;</span>:&#123;<span class="string">&quot;a&quot;</span>:<span class="number">0.0</span>, <span class="string">&quot;b&quot;</span>:<span class="number">3.5</span>, <span class="string">&quot;c&quot;</span>:<span class="number">0.0</span>, <span class="string">&quot;d&quot;</span>:<span class="number">0.0</span>, <span class="string">&quot;e&quot;</span>:<span class="number">3.0</span>&#125;,</span><br><span class="line">            <span class="string">&quot;D&quot;</span>:&#123;<span class="string">&quot;a&quot;</span>:<span class="number">0.0</span>, <span class="string">&quot;b&quot;</span>:<span class="number">4.0</span>, <span class="string">&quot;c&quot;</span>:<span class="number">0.0</span>, <span class="string">&quot;d&quot;</span>:<span class="number">3.5</span>, <span class="string">&quot;e&quot;</span>:<span class="number">3.0</span>&#125;</span><br><span class="line">        &#125;</span><br><span class="line">        <span class="keyword">return</span> user_score_dict</span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">userSimilarity</span>(<span class="params">self</span>):</span><br><span class="line">        W = <span class="built_in">dict</span>()</span><br><span class="line">        <span class="keyword">for</span> u <span class="keyword">in</span> self.user_score_dict.keys():</span><br><span class="line">            W.setdefault(u, &#123;&#125;)</span><br><span class="line">            <span class="keyword">for</span> v <span class="keyword">in</span> self.user_score_dict.keys():</span><br><span class="line">                <span class="keyword">if</span> u == v:</span><br><span class="line">                    <span class="keyword">continue</span></span><br><span class="line">                <span class="keyword">else</span>:</span><br><span class="line">                    u_set = <span class="built_in">set</span>(</span><br><span class="line">                        [key <span class="keyword">for</span> key <span class="keyword">in</span> self.user_score_dict[u].keys() <span class="keyword">if</span> self.user_score_dict[u][key] &gt; <span class="number">0</span>]</span><br><span class="line">                    )</span><br><span class="line">                    v_set = <span class="built_in">set</span>(</span><br><span class="line">                        [key <span class="keyword">for</span> key <span class="keyword">in</span> self.user_score_dict[v].keys() <span class="keyword">if</span> self.user_score_dict[v][key] &gt; <span class="number">0</span>]</span><br><span class="line">                    )</span><br><span class="line">                    W[u][v] = <span class="built_in">float</span>(</span><br><span class="line">                        <span class="built_in">len</span>(u_set &amp; v_set)</span><br><span class="line">                    ) / math.sqrt(<span class="built_in">len</span>(u_set) * <span class="built_in">len</span>(v_set))</span><br><span class="line"></span><br><span class="line">        <span class="keyword">return</span> W</span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">preUserItemScore</span>(<span class="params">self, userA, item</span>):</span><br><span class="line">        score = <span class="number">0.0</span></span><br><span class="line">        <span class="keyword">for</span> user <span class="keyword">in</span> self.users_sim[userA].keys():</span><br><span class="line">            <span class="keyword">if</span> user != userA:</span><br><span class="line">                score += self.users_sim[userA][user] * self.user_score_dict[user][item]</span><br><span class="line">        <span class="keyword">return</span> score</span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">recommend</span>(<span class="params">self, userA</span>):</span><br><span class="line">        user_item_score_dict = <span class="built_in">dict</span>()</span><br><span class="line">        <span class="keyword">for</span> item <span class="keyword">in</span> self.user_score_dict[userA].keys():</span><br><span class="line">            <span class="keyword">if</span> self.user_score_dict[userA][item] &lt;= <span class="number">0</span>:</span><br><span class="line">                user_item_score_dict[item] = self.preUserItemScore(userA, item)</span><br><span class="line">        <span class="keyword">return</span> <span class="built_in">sorted</span>(user_item_score_dict.items(), key= <span class="keyword">lambda</span> k:k[<span class="number">1</span>],reverse=<span class="literal">True</span>)</span><br></pre></td></tr></table></figure>

<p>输出结果：</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">[(<span class="string">&#x27;e&#x27;</span>, 4.3914115380582555), (<span class="string">&#x27;c&#x27;</span>, 1.5)]</span><br><span class="line">[(<span class="string">&#x27;b&#x27;</span>, 4.095535683290187), (<span class="string">&#x27;d&#x27;</span>, 2.333333333333333)]</span><br><span class="line">[(<span class="string">&#x27;d&#x27;</span>, 4.286607049870562), (<span class="string">&#x27;a&#x27;</span>, 2.8577380332470415), (<span class="string">&#x27;c&#x27;</span>, 1.8371173070873839)]</span><br><span class="line">[(<span class="string">&#x27;a&#x27;</span>, 3.333333333333333), (<span class="string">&#x27;c&#x27;</span>, 1.5)]</span><br></pre></td></tr></table></figure>
<ol start="4">
<li>算法复杂度优化<br>但是由于要计算每一对用户的相似度，算法复杂度为$O(|U|*|U|)$。</li>
</ol>
<p>在实际生产环境中，很多用户之间并没有交集，也就是没有对同一样物品产生过行为，所以很多情况下，分子为0，这样的系数数据就没有计算的必要。因此可以进行==优化==。</p>
<p>（1）计算出$N(u)\cap N(v)\neq0$的用户对$(u,v)$</p>
<p>（2）对其除以分母得到$u$和$v$的相似度</p>
<p>==思路==：</p>
<p>（1）建立物品到用户的倒排表$T$，表示该物品被哪些用户产生过行为</p>
<p>（2）根据倒排表$T$，建立用户相似度矩阵W</p>
<ul>
<li>在$T$中，对于每个物品$i$，设其对应的用户为$j$、$k$</li>
<li>在$W$中，更新对应位置的元素值，$W[j][k]=W[j][k]+1,W[k][j]=W[k][j]+1$</li>
</ul>
<p>依次，在扫描完倒排表$T$之后，就能得到一个完整的用户相似度矩阵$W$了。再将$W$除以分母，就能得到两个用户的兴趣相似度。</p>
<p>（1）由用户的评分数据得到每个物品被哪些用户评价过</p>
<p><img src="image-20210717134651630.png" alt="image-20210717134651630"></p>
<p>（2）建立用户相似度矩阵$W$</p>
<p><img src="image-20210717135315387.png" alt="image-20210717135315387"></p>
<p>得到的相似度矩阵$W$对应的是两两用户相似度的分子部分，然后除以分母得到的便是两两用户的相似度。</p>
<p> 以用户C为例，A 、B用户与C用户相似度计算的分子都为1，D用户与C用户相似度的分子为2。</p>
<p>因此得到其他用户与C用户的相似度为：<br>$$<br>W_{CA}=\frac1{\sqrt6},W_{CB}=\frac1{\sqrt6},W_{CD}=\frac2{\sqrt6}<br>$$<br>之后，计算用户C对物品a、c、d的可能评分：<br>$$<br>   P(C,a)=W_{CA}×3.0+W_{CB}×4.0+W_{CD}×0=2.858<br>$$</p>
<p>$$<br>   P(C,c)=W_{CA}×0+W_{CB}×4.5+W_{CD}×0=1.837<br>$$</p>
<p>$$<br>P(C,d)=W_{CA}×3.5+W_{CB}×0+W_{CD}×3.5=4.287<br>$$</p>
<p>==代码实现优化==：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">def</span> <span class="title function_">userSimilarityBetter</span>(<span class="params">self</span>):</span><br><span class="line">       <span class="comment">#得到每个item都被哪些user评价过</span></span><br><span class="line">       item_users = <span class="built_in">dict</span>()</span><br><span class="line">       <span class="keyword">for</span> u, items <span class="keyword">in</span> self.user_score_dict.items():</span><br><span class="line">           <span class="keyword">for</span> i <span class="keyword">in</span> items.keys():</span><br><span class="line">               item_users.setdefault(i, <span class="built_in">set</span>())</span><br><span class="line">               <span class="keyword">if</span> self.user_score_dict[u][i] &gt; <span class="number">0</span>:</span><br><span class="line">                   item_users[i].add(u)</span><br><span class="line">       <span class="comment"># 构建倒排表</span></span><br><span class="line">       C = <span class="built_in">dict</span>()</span><br><span class="line">       N = <span class="built_in">dict</span>()</span><br><span class="line">       <span class="keyword">for</span> i, users <span class="keyword">in</span> item_users.items():</span><br><span class="line">           <span class="keyword">for</span> u <span class="keyword">in</span> users:</span><br><span class="line">               N.setdefault(u, <span class="number">0</span>)</span><br><span class="line">               N[u] += <span class="number">1</span></span><br><span class="line">               C.setdefault(u, &#123;&#125;)</span><br><span class="line">               <span class="keyword">for</span> v <span class="keyword">in</span> users:</span><br><span class="line">                   C[u].setdefault(v, <span class="number">0</span>)</span><br><span class="line">                   <span class="keyword">if</span> u == v:</span><br><span class="line">                       <span class="keyword">continue</span></span><br><span class="line">                   C[u][v] += <span class="number">1</span></span><br><span class="line">       <span class="built_in">print</span>(C)</span><br><span class="line">       <span class="built_in">print</span>(N)</span><br><span class="line">       <span class="comment">#构建相似度矩阵</span></span><br><span class="line">       W = <span class="built_in">dict</span>()</span><br><span class="line">       <span class="keyword">for</span> u, related_users <span class="keyword">in</span> C.items():</span><br><span class="line">           W.setdefault(u,&#123;&#125;)</span><br><span class="line">           <span class="keyword">for</span> v,cuv <span class="keyword">in</span> related_users.items():</span><br><span class="line">               <span class="keyword">if</span> u == v :</span><br><span class="line">                   <span class="keyword">continue</span></span><br><span class="line">               <span class="keyword">else</span>:</span><br><span class="line">                   W[u].setdefault(v, <span class="number">0.0</span>)</span><br><span class="line">                   W[u][v] = cuv / math.sqrt(N[u] * N[v])</span><br><span class="line">       <span class="keyword">return</span> W</span><br></pre></td></tr></table></figure>

<p>输出结果：</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">&#123;<span class="string">&#x27;B&#x27;</span>: &#123;<span class="string">&#x27;B&#x27;</span>: 0, <span class="string">&#x27;A&#x27;</span>: 1, <span class="string">&#x27;C&#x27;</span>: 1, <span class="string">&#x27;D&#x27;</span>: 1&#125;, <span class="string">&#x27;A&#x27;</span>: &#123;<span class="string">&#x27;B&#x27;</span>: 1, <span class="string">&#x27;A&#x27;</span>: 0, <span class="string">&#x27;C&#x27;</span>: 1, <span class="string">&#x27;D&#x27;</span>: 2&#125;, <span class="string">&#x27;C&#x27;</span>: &#123;<span class="string">&#x27;C&#x27;</span>: 0, <span class="string">&#x27;D&#x27;</span>: 2, <span class="string">&#x27;A&#x27;</span>: 1, <span class="string">&#x27;B&#x27;</span>: 1&#125;, <span class="string">&#x27;D&#x27;</span>: &#123;<span class="string">&#x27;C&#x27;</span>: 2, <span class="string">&#x27;D&#x27;</span>: 0, <span class="string">&#x27;A&#x27;</span>: 2, <span class="string">&#x27;B&#x27;</span>: 1&#125;&#125;</span><br><span class="line">&#123;<span class="string">&#x27;B&#x27;</span>: 3, <span class="string">&#x27;A&#x27;</span>: 3, <span class="string">&#x27;C&#x27;</span>: 2, <span class="string">&#x27;D&#x27;</span>: 3&#125;</span><br><span class="line">[(<span class="string">&#x27;e&#x27;</span>, 4.3914115380582555), (<span class="string">&#x27;c&#x27;</span>, 1.5)]</span><br><span class="line">[(<span class="string">&#x27;b&#x27;</span>, 4.095535683290187), (<span class="string">&#x27;d&#x27;</span>, 2.333333333333333)]</span><br><span class="line">[(<span class="string">&#x27;d&#x27;</span>, 4.286607049870562), (<span class="string">&#x27;a&#x27;</span>, 2.8577380332470415), (<span class="string">&#x27;c&#x27;</span>, 1.8371173070873839)]</span><br><span class="line">[(<span class="string">&#x27;a&#x27;</span>, 3.333333333333333), (<span class="string">&#x27;c&#x27;</span>, 1.5)]</span><br></pre></td></tr></table></figure>
<ol start="5">
<li><p>惩罚热门商品</p>
<p>如果用户都购买了《新华字典》，这并不能说明他们兴趣相同；但是如果用户都购买了《机器学习实战》，那么可以认为他们的兴趣相似。</p>
<p>==两个用户对冷门物品采取同样的行为更能说明他们兴趣的相似度。==</p>
<p>==John S. Breese==在论文提出了下面的公式来根据用户行为计算用户的兴趣相似度：<br>$$<br>W_{uv}=\frac{\sum_{i\in N(u)\cap N(v)}\frac1{lg(1+|N(i)|)}}{\sqrt{|N(u)||N(v)|}}<br>$$</p>
</li>
</ol>
<ul>
<li>分子中的倒数部分，惩罚了用户 $u$ 和用户 $v$ 共同兴趣列表中热门物品，减小了热门物品对用户相似度的影响。</li>
<li>$N(i)$是对物品 $i$ 有过行为的用户集合。物品 $i$ 越热门，$N(i)$ 越大。</li>
</ul>
<p>==代码实现==：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">def</span> <span class="title function_">userSimilarityBest</span>(<span class="params">self</span>):</span><br><span class="line">    item_users = <span class="built_in">dict</span>()</span><br><span class="line">    <span class="keyword">for</span> u, items <span class="keyword">in</span> self.user_score_dict.items():</span><br><span class="line">        <span class="keyword">for</span> i <span class="keyword">in</span> items.keys():</span><br><span class="line">            item_users.setdefault(i, <span class="built_in">set</span>())</span><br><span class="line">            <span class="keyword">if</span> self.user_score_dict[u][i] &gt; <span class="number">0</span>:</span><br><span class="line">                item_users[i].add(u)</span><br><span class="line">    <span class="comment">#构建倒排表</span></span><br><span class="line">    C = <span class="built_in">dict</span>()</span><br><span class="line">    N = <span class="built_in">dict</span>()</span><br><span class="line">    <span class="keyword">for</span> i, users <span class="keyword">in</span> item_users.items():</span><br><span class="line">        <span class="keyword">for</span> u <span class="keyword">in</span> users:</span><br><span class="line">            N.setdefault(u, <span class="number">0</span>)</span><br><span class="line">            N[u] += <span class="number">1</span></span><br><span class="line">            C.setdefault(u, &#123;&#125;)</span><br><span class="line">            <span class="keyword">for</span> v <span class="keyword">in</span> users:</span><br><span class="line">                C[u].setdefault(v, <span class="number">0</span>)</span><br><span class="line">                <span class="keyword">if</span> u == v:</span><br><span class="line">                    <span class="keyword">continue</span></span><br><span class="line">                <span class="keyword">else</span>:</span><br><span class="line">                    C[u][v] += <span class="number">1</span> / math.log(<span class="number">1</span> + <span class="built_in">len</span> (users))</span><br><span class="line">    <span class="comment">#构建相似度矩阵</span></span><br><span class="line">    W = <span class="built_in">dict</span>()</span><br><span class="line">    <span class="keyword">for</span> u, related_users <span class="keyword">in</span> C.items():</span><br><span class="line">        W.setdefault(u, &#123;&#125;)</span><br><span class="line">        <span class="keyword">for</span> v, cuv <span class="keyword">in</span> related_users.items():</span><br><span class="line">            <span class="keyword">if</span> u == v:</span><br><span class="line">                <span class="keyword">continue</span></span><br><span class="line">            W[u].setdefault(v, <span class="number">0.0</span>)</span><br><span class="line">            W[u][v] = cuv / math.sqrt(N[u] * N[v])</span><br><span class="line">    <span class="keyword">return</span> W</span><br></pre></td></tr></table></figure>

<p>输出结果：</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">[(<span class="string">&#x27;e&#x27;</span>, 3.5769991876247142), (<span class="string">&#x27;c&#x27;</span>, 1.3653588399402559)]</span><br><span class="line">[(<span class="string">&#x27;b&#x27;</span>, 3.2061601182764137), (<span class="string">&#x27;d&#x27;</span>, 1.9035178715832055)]</span><br><span class="line">[(<span class="string">&#x27;d&#x27;</span>, 3.092133366543965), (<span class="string">&#x27;a&#x27;</span>, 2.0614222443626433), (<span class="string">&#x27;c&#x27;</span>, 1.3252000142331277)]</span><br><span class="line">[(<span class="string">&#x27;a&#x27;</span>, 2.5933834409972945), (<span class="string">&#x27;c&#x27;</span>, 1.0820212806667224)]</span><br></pre></td></tr></table></figure>

<h6 id="基于UserCF算法的电影推荐系统"><a href="#基于UserCF算法的电影推荐系统" class="headerlink" title="基于UserCF算法的电影推荐系统"></a>基于UserCF算法的电影推荐系统</h6><p>==实现思路==：</p>
<p>首先使用训练数据集得到用户的偏好信息矩阵和物品的特征信息矩阵，然后计算用户对未进行评分电影的偏好分，选取前K个推荐给用户。</p>
<p>（1）准备数据</p>
<p>（2）构建基于UserCF算法的模型</p>
<p>（3）模型训练</p>
<p>（4）效果评估</p>
<p>实现过程：</p>
<ol>
<li><p>准备数据</p>
<p>使用MovieLens数据集。</p>
</li>
<li><p>选择算法</p>
<p>算法使用==基于用户的协同过滤算法==，相似度计算选择==优化后的余项相似度==。</p>
</li>
<li><p>模型训练</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br></pre></td><td class="code"><pre><span class="line">import random</span><br><span class="line">import math</span><br><span class="line">import json</span><br><span class="line">import os</span><br><span class="line"></span><br><span class="line">base_dir =  <span class="string">&quot;C:\\Users\\OAOA\\Desktop\\GXX的科研\\python\\FirstRec\\ml-1m&quot;</span></span><br><span class="line">user_sim_json_dir = os.path.join(base_dir, <span class="string">&quot;user_sim.json&quot;</span>)</span><br><span class="line">class UserCFRec:</span><br><span class="line">    def __init__(self, datafile):</span><br><span class="line">        self.datafile = datafile</span><br><span class="line">        self.data = self.loadData()</span><br><span class="line">        self.trainData,self.testData = self.splitData(5, 40)</span><br><span class="line">        self.users_sim = self.UserSimilarityBest()</span><br><span class="line"></span><br><span class="line">    <span class="comment">#加载数据集</span></span><br><span class="line">    def loadData(self):</span><br><span class="line">        <span class="built_in">print</span>(<span class="string">&quot;加载数据...&quot;</span>)</span><br><span class="line">        data = []</span><br><span class="line">        <span class="keyword">for</span> line <span class="keyword">in</span> open(self.datafile):</span><br><span class="line">            userid, itemid, record, _ = line.split(<span class="string">&quot;::&quot;</span>)</span><br><span class="line">            data.append((userid, itemid, int(record)))</span><br><span class="line">        <span class="built_in">return</span> data</span><br><span class="line"></span><br><span class="line">    <span class="comment">#拆分数据集</span></span><br><span class="line">    def splitData(self, k, seed, M=10):</span><br><span class="line">        <span class="comment">#k:参数</span></span><br><span class="line">        <span class="comment">#seed:随机种子</span></span><br><span class="line">        <span class="comment">#M:随机数上限</span></span><br><span class="line">        <span class="built_in">print</span>(<span class="string">&quot;训练集和测试集切分...&quot;</span>)</span><br><span class="line">        train, <span class="built_in">test</span> = &#123;&#125;, &#123;&#125;</span><br><span class="line">        random.seed(seed)</span><br><span class="line">        <span class="keyword">for</span> user, item, record <span class="keyword">in</span> self.data:</span><br><span class="line">            <span class="keyword">if</span> random.randint(0,M) == k:</span><br><span class="line">                test.setdefault(user, &#123;&#125;)</span><br><span class="line">                <span class="built_in">test</span>[user][item] = record</span><br><span class="line">            <span class="keyword">else</span>:</span><br><span class="line">                train.setdefault(user, &#123;&#125;)</span><br><span class="line">                train[user][item] = record</span><br><span class="line">        <span class="built_in">return</span> train,<span class="built_in">test</span></span><br><span class="line"></span><br><span class="line">    <span class="comment">#计算用户之间的相似度，采用惩罚热门商品和优化算法复杂度的算法</span></span><br><span class="line">    def UserSimilarityBest(self):</span><br><span class="line">        <span class="built_in">print</span>(<span class="string">&quot;开始计算用户之间的相似度...&quot;</span>)</span><br><span class="line">        <span class="keyword">if</span> os.path.exists(user_sim_json_dir):</span><br><span class="line">            <span class="built_in">print</span>(<span class="string">&quot;从文件中加载用户相似度&quot;</span>)</span><br><span class="line">            userSim = json.load(open(user_sim_json_dir, <span class="string">&quot;r&quot;</span>))</span><br><span class="line">        <span class="keyword">else</span>:</span><br><span class="line">            <span class="comment">#得到每个item都被哪些user评价过</span></span><br><span class="line">            item_users = dict()</span><br><span class="line">            <span class="keyword">for</span> u, items <span class="keyword">in</span> self.trainData.items():</span><br><span class="line">                <span class="keyword">for</span> i <span class="keyword">in</span> items.keys():</span><br><span class="line">                    item_users.setdefault(i, <span class="built_in">set</span>())</span><br><span class="line">                    <span class="keyword">if</span> self.trainData[u][i] &gt; 0:</span><br><span class="line">                        item_users[i].add(u)</span><br><span class="line">            <span class="comment">#构建倒排表</span></span><br><span class="line">            count = dict()</span><br><span class="line">            user_item_count = dict()</span><br><span class="line">            <span class="keyword">for</span> i, <span class="built_in">users</span> <span class="keyword">in</span> item_users.items():</span><br><span class="line">                <span class="keyword">for</span> u <span class="keyword">in</span> <span class="built_in">users</span>:</span><br><span class="line">                    user_item_count.setdefault(u, 0)</span><br><span class="line">                    user_item_count[u] += 1</span><br><span class="line">                    count.setdefault(u, &#123;&#125;)</span><br><span class="line">                    <span class="keyword">for</span> v <span class="keyword">in</span> <span class="built_in">users</span>:</span><br><span class="line">                        count[u].setdefault(v, 0)</span><br><span class="line">                        <span class="keyword">if</span> u == v:</span><br><span class="line">                            <span class="built_in">continue</span></span><br><span class="line">                        count[u][v] += 1 / math.log(1 + len(<span class="built_in">users</span>))</span><br><span class="line">            <span class="comment">#构建相似度矩阵</span></span><br><span class="line">            userSim = dict()</span><br><span class="line">            <span class="keyword">for</span> u, related_users <span class="keyword">in</span> count.items():</span><br><span class="line">                userSim.setdefault(u, &#123;&#125;)</span><br><span class="line">                <span class="keyword">for</span> v, cuv <span class="keyword">in</span> related_users.items():</span><br><span class="line">                    <span class="keyword">if</span> u == v:</span><br><span class="line">                        <span class="built_in">continue</span></span><br><span class="line">                    userSim[u].setdefault(v, 0.0)</span><br><span class="line">                    userSim[u][v] = cuv / math.sqrt(user_item_count[u] * user_item_count[v])</span><br><span class="line">            json.dump(userSim, open(user_sim_json_dir, <span class="string">&quot;w&quot;</span>))</span><br><span class="line">        <span class="built_in">return</span> userSim</span><br><span class="line"></span><br><span class="line">    <span class="comment">#推荐</span></span><br><span class="line">    def recommend(self, user, k=8, nitems=40):</span><br><span class="line">        result = dict()</span><br><span class="line">        have_score_items = self.trainData.get(user, &#123;&#125;)</span><br><span class="line">        <span class="keyword">for</span> v,wuv <span class="keyword">in</span> sorted(self.users_sim[user].items(), key=lambda  x:x[1], reverse=True)[0:k]:</span><br><span class="line">            <span class="keyword">for</span> i, rvi <span class="keyword">in</span> self.trainData[v].items():</span><br><span class="line">                <span class="keyword">if</span> i <span class="keyword">in</span> have_score_items:</span><br><span class="line">                    <span class="built_in">continue</span></span><br><span class="line">                result.setdefault(i, 0)</span><br><span class="line">                result[i] += wuv * rvi</span><br><span class="line">        <span class="built_in">return</span> dict(sorted(result.items(),key=lambda x:x[1], reverse=True))[0:nitems]</span><br><span class="line"></span><br><span class="line"><span class="keyword">if</span> __name__ == <span class="string">&quot;__main__&quot;</span>:</span><br><span class="line">    ratings_dir = os.path.join(base_dir, <span class="string">&quot;ratings.dat&quot;</span>)</span><br><span class="line">    cf = UserCFRec(ratings_dir)</span><br><span class="line">    user = <span class="string">&quot;1&quot;</span></span><br><span class="line">    result = cf.recommend(user)</span><br><span class="line">    <span class="built_in">print</span>(<span class="string">&quot;用户&#123;&#125;的推荐结果为&#123;&#125;&quot;</span>.format(user, result))</span><br></pre></td></tr></table></figure>

<p>输出结果为：</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">加载数据...</span><br><span class="line">训练集和测试集切分...</span><br><span class="line">开始计算用户之间的相似度...</span><br><span class="line">从文件中加载用户相似度</span><br><span class="line">用户1的推荐结果为&#123;<span class="string">&#x27;2081&#x27;</span>: 1.6469599790207905, <span class="string">&#x27;1022&#x27;</span>: 1.5628170086116397, <span class="string">&#x27;2096&#x27;</span>: 1.2513084657114166, <span class="string">&#x27;2078&#x27;</span>: 1.2365159185246708, <span class="string">&#x27;2085&#x27;</span>: 1.0935717172311947, <span class="string">&#x27;1282&#x27;</span>: 1.044996637061893, <span class="string">&#x27;1032&#x27;</span>: 1.0349559580081986, <span class="string">&#x27;2080&#x27;</span>: 0.9801758674308475, <span class="string">&#x27;364&#x27;</span>: 0.9703565188587941, <span class="string">&#x27;593&#x27;</span>: 0.8948935450838191&#125;</span><br><span class="line">开始计算准确率...</span><br><span class="line">推荐的准确率为:16.28476821192053%</span><br><span class="line"></span><br></pre></td></tr></table></figure></li>
<li><p>效果评估</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">#效果评估</span></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">precision</span>(<span class="params">self, k=<span class="number">8</span>,nitems=<span class="number">10</span></span>):</span><br><span class="line">    <span class="built_in">print</span>(<span class="string">&quot;开始计算准确率...&quot;</span>)</span><br><span class="line">    hit = <span class="number">0</span></span><br><span class="line">    precision = <span class="number">0</span></span><br><span class="line">    <span class="keyword">for</span> user <span class="keyword">in</span> self.trainData.keys():</span><br><span class="line">        tu = self.testData.get(user, &#123;&#125;)</span><br><span class="line">        rank = self.recommend(user, k=k, nitems= nitems)</span><br><span class="line">        <span class="keyword">for</span> item,rate <span class="keyword">in</span> rank.items():</span><br><span class="line">            <span class="keyword">if</span> item <span class="keyword">in</span> tu:</span><br><span class="line">                hit += <span class="number">1</span></span><br><span class="line">        precision += nitems</span><br><span class="line">    <span class="keyword">return</span> hit / (precision * <span class="number">1.0</span>)</span><br></pre></td></tr></table></figure>

<p>输出结果为：</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">开始计算准确率...</span><br><span class="line">推荐的准确率为:16.28476821192053%</span><br></pre></td></tr></table></figure></li>
</ol>
<h6 id="ItemCF算法的原理–先找到用户喜欢的物品，再找到喜欢物品的相似物品"><a href="#ItemCF算法的原理–先找到用户喜欢的物品，再找到喜欢物品的相似物品" class="headerlink" title="ItemCF算法的原理–先找到用户喜欢的物品，再找到喜欢物品的相似物品"></a>ItemCF算法的原理–先找到用户喜欢的物品，再找到喜欢物品的相似物品</h6><p>基于物品的协同过滤推荐则通过不同对<code>item</code>的评分来评测<code>item</code>之间的相似性，从而基于<code>item</code>的相似性做推荐。</p>
<p>就是==给用户推荐他之前喜欢物品的相似物品==。</p>
<p><img src="image-20210718130132232.png" alt="image-20210718130132232"></p>
<p>   关键是==如何衡量两个物品的相似度==。</p>
<table>
<thead>
<tr>
<th align="center">用户</th>
<th align="center">物品a</th>
<th align="center">物品b</th>
<th align="center">物品c</th>
<th align="center">物品d</th>
<th align="center">物品e</th>
</tr>
</thead>
<tbody><tr>
<td align="center">A</td>
<td align="center">3.0</td>
<td align="center">4.0</td>
<td align="center">0</td>
<td align="center">3.5</td>
<td align="center">0</td>
</tr>
<tr>
<td align="center">B</td>
<td align="center">4.0</td>
<td align="center">0</td>
<td align="center">4.5</td>
<td align="center">0</td>
<td align="center">3.5</td>
</tr>
<tr>
<td align="center">C</td>
<td align="center">0</td>
<td align="center">3.5</td>
<td align="center">0</td>
<td align="center">0</td>
<td align="center">3</td>
</tr>
<tr>
<td align="center">D</td>
<td align="center">0</td>
<td align="center">4</td>
<td align="center">0</td>
<td align="center">3.5</td>
<td align="center">3</td>
</tr>
</tbody></table>
<p>   ==基于物品的协同过滤算法==主要有三步：</p>
<ol>
<li><p>计算物品之间的相似度</p>
<p>（1） 建立用户物品倒排表</p>
<p><img src="image-20210718130604147.png" alt="image-20210718130604147"></p>
<p>（2）构建同现矩阵<br>同现矩阵表示同时喜欢两个物品的用户数，是根据用户物品倒排表计算出来的。</p>
<table>
<thead>
<tr>
<th align="center"></th>
<th align="center">a</th>
<th align="center">b</th>
<th align="center">c</th>
<th align="center">d</th>
<th align="center">e</th>
</tr>
</thead>
<tbody><tr>
<td align="center">a</td>
<td align="center">0</td>
<td align="center">1</td>
<td align="center">1</td>
<td align="center">1</td>
<td align="center">1</td>
</tr>
<tr>
<td align="center">b</td>
<td align="center">1</td>
<td align="center">0</td>
<td align="center">0</td>
<td align="center">2</td>
<td align="center">2</td>
</tr>
<tr>
<td align="center">c</td>
<td align="center">1</td>
<td align="center">0</td>
<td align="center">0</td>
<td align="center">0</td>
<td align="center">1</td>
</tr>
<tr>
<td align="center">d</td>
<td align="center">1</td>
<td align="center">2</td>
<td align="center">0</td>
<td align="center">0</td>
<td align="center">1</td>
</tr>
<tr>
<td align="center">e</td>
<td align="center">1</td>
<td align="center">2</td>
<td align="center">1</td>
<td align="center">1</td>
<td align="center">0</td>
</tr>
</tbody></table>
<p>同现矩阵对角线全为0，且是实对称稀疏矩阵。</p>
<p>采用以下公式==计算item之间的相似度==：<br>$$<br>w_{ij}=\frac{|N(i) \cap N(j)|}{|N(i)|}<br>$$</p>
<ul>
<li>分母$N(i)$是喜欢物品 $i$ 的用户数</li>
<li>分子$|N(i)\cap N(j)|$，是同时喜欢物品 $i$ 和 $j$ 的用户数</li>
</ul>
<p>公式78可以理解为喜欢物品 $i$ 的用户中有多少比例的用户也喜欢物品 $j$。</p>
<p>统计每个物品有行为的用户数为：</p>
<p><img src="image-20210718131954377.png" alt="image-20210718131954377"></p>
<table>
<thead>
<tr>
<th align="center">物品</th>
<th align="center">有行为用户数</th>
</tr>
</thead>
<tbody><tr>
<td align="center">a</td>
<td align="center">2</td>
</tr>
<tr>
<td align="center">b</td>
<td align="center">3</td>
</tr>
<tr>
<td align="center">c</td>
<td align="center">1</td>
</tr>
<tr>
<td align="center">d</td>
<td align="center">2</td>
</tr>
<tr>
<td align="center">e</td>
<td align="center">3</td>
</tr>
</tbody></table>
<p>通过计算物品之间的相似度，得到物品之间的相似度矩阵。</p>
<p>例如物品 $a$ 和物品 $b$ 之间的相似度，<br>$$<br>w_{ab}=\frac{|N(a) \cap N(b)|}{|N(a)|}=\frac{1}{2}=0.5<br>$$<br>物品 $b$ 和物品 $d$ 之间的相似度，<br>$$<br>w_{bd}=\frac{|N(b)\cap N(d)|}{|N(b)|}=\frac{2}{3}=0.67<br>$$<br>则物品之间的==相似度矩阵==。</p>
<table>
<thead>
<tr>
<th align="center"></th>
<th align="center">a</th>
<th align="center">b</th>
<th align="center">c</th>
<th align="center">d</th>
<th align="center">e</th>
</tr>
</thead>
<tbody><tr>
<td align="center">a</td>
<td align="center">0</td>
<td align="center">0.5</td>
<td align="center">0.5</td>
<td align="center">0.5</td>
<td align="center">0.5</td>
</tr>
<tr>
<td align="center">b</td>
<td align="center">0.33</td>
<td align="center">0</td>
<td align="center">0</td>
<td align="center">0.67</td>
<td align="center">0.67</td>
</tr>
<tr>
<td align="center">c</td>
<td align="center">1.0</td>
<td align="center">0</td>
<td align="center">0</td>
<td align="center">0</td>
<td align="center">1.0</td>
</tr>
<tr>
<td align="center">d</td>
<td align="center">0.5</td>
<td align="center">1.0</td>
<td align="center">0</td>
<td align="center">0</td>
<td align="center">0.5</td>
</tr>
<tr>
<td align="center">e</td>
<td align="center">0.33</td>
<td align="center">0.67</td>
<td align="center">0.33</td>
<td align="center">0.33</td>
<td align="center">0</td>
</tr>
</tbody></table>
<p>==物品 $a$ 与物品 $b$之间的相似度，物品 $b$ 与 物品 $a$之前的相似度不一样，这里是一个疑问点。==</p>
<p>（3）构建评分矩阵（以用户C为例）。</p>
<table>
<thead>
<tr>
<th align="center">物品</th>
<th align="center">评分</th>
</tr>
</thead>
<tbody><tr>
<td align="center">a</td>
<td align="center">0</td>
</tr>
<tr>
<td align="center">b</td>
<td align="center">3.5</td>
</tr>
<tr>
<td align="center">c</td>
<td align="center">0</td>
</tr>
<tr>
<td align="center">d</td>
<td align="center">0</td>
</tr>
<tr>
<td align="center">e</td>
<td align="center">3</td>
</tr>
</tbody></table>
</li>
<li><p>计算推荐结果</p>
<p>得到物品之前的相似度矩阵之后，通过以下公式计算==用户 $u$ 对物品 $i$ 的兴趣：<br>$$<br>P_{u,i}=\sum_{j\in S(i,K)\cap N(u)}w_{ij}r_{uj}<br>$$</p>
<ul>
<li>$N(u)$：用户喜欢的物品的集合</li>
<li>$S(i,K)$：和物品 $i$ 最相似的 $K$ 个物品的集合</li>
<li>$w_{ij}$：物品 $i$ 和物品 $j$ 的相似度</li>
<li>$r_{uj}$：用户 $u$ 对物品 $j$ 的兴趣（对于隐反馈数据集，如果用户 $u$ 对物品 $j$ 有过行为，即可令 $r_{uj}=1$）</li>
</ul>
<p>上述公式的含义是，和用户历史上感兴趣的物品越相似的物品，越有可能在用户的推荐列表中获得比较高的排名。</p>
<p>用户 $C$ 对于物品 $a$ 的兴趣为，<br>$$<br>P_{C,a}=\sum_{j\in S(a,K)\cap {N(C)}}w_{ij}r_{Cj}=0×0+0.5×3.5+0.5×0+0.5×0+0.5×3=3.25<br>$$<br>用户C对各个物品的兴趣即为相似度矩阵和用户Ｃ评分矩阵的乘积</p>
<table>
<thead>
<tr>
<th align="center">物品</th>
<th align="center">评分</th>
</tr>
</thead>
<tbody><tr>
<td align="center">==a==</td>
<td align="center">==3.25==</td>
</tr>
<tr>
<td align="center">b</td>
<td align="center">2.0</td>
</tr>
<tr>
<td align="center">==c==</td>
<td align="center">==3.0==</td>
</tr>
<tr>
<td align="center">==d==</td>
<td align="center">==5.0==</td>
</tr>
<tr>
<td align="center">e</td>
<td align="center">2.33</td>
</tr>
</tbody></table>
<p>去掉用户经评分的物品ｂ和ｅ，用户对物品的喜爱程度为$ｄ＞ａ＞ｃ$。</p>
<p>代码实现为：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> math</span><br><span class="line"></span><br><span class="line"><span class="keyword">class</span> <span class="title class_">ItemCF</span>:</span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__init__</span>(<span class="params">self</span>):</span><br><span class="line">        self.user_score_dict = self.initUserScore()</span><br><span class="line">        self.items_sim = self.ItemSimilarity()</span><br><span class="line"></span><br><span class="line">    <span class="comment">#初始化用户评分数据</span></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">initUserScore</span>(<span class="params">self</span>):</span><br><span class="line">        user_score_dict = &#123;</span><br><span class="line">            <span class="string">&quot;A&quot;</span>:&#123;<span class="string">&quot;a&quot;</span>:<span class="number">3.0</span>, <span class="string">&quot;b&quot;</span>:<span class="number">4.0</span>, <span class="string">&quot;c&quot;</span>:<span class="number">0.0</span>, <span class="string">&quot;d&quot;</span>:<span class="number">3.5</span>, <span class="string">&quot;e&quot;</span>:<span class="number">0.0</span>&#125;,</span><br><span class="line">            <span class="string">&quot;B&quot;</span>:&#123;<span class="string">&quot;a&quot;</span>:<span class="number">4.0</span>, <span class="string">&quot;b&quot;</span>:<span class="number">0.0</span>, <span class="string">&quot;c&quot;</span>:<span class="number">4.5</span>, <span class="string">&quot;d&quot;</span>:<span class="number">0.0</span>, <span class="string">&quot;e&quot;</span>:<span class="number">3.5</span>&#125;,</span><br><span class="line">            <span class="string">&quot;C&quot;</span>:&#123;<span class="string">&quot;a&quot;</span>:<span class="number">0.0</span>, <span class="string">&quot;b&quot;</span>:<span class="number">3.5</span>, <span class="string">&quot;c&quot;</span>:<span class="number">0.0</span>, <span class="string">&quot;d&quot;</span>:<span class="number">0.0</span>, <span class="string">&quot;e&quot;</span>:<span class="number">3.0</span>&#125;,</span><br><span class="line">            <span class="string">&quot;D&quot;</span>:&#123;<span class="string">&quot;a&quot;</span>:<span class="number">0.0</span>, <span class="string">&quot;b&quot;</span>:<span class="number">4.0</span>, <span class="string">&quot;c&quot;</span>:<span class="number">0.0</span>, <span class="string">&quot;d&quot;</span>:<span class="number">3.5</span>, <span class="string">&quot;e&quot;</span>:<span class="number">3.0</span>&#125;</span><br><span class="line">        &#125;</span><br><span class="line">        <span class="keyword">return</span> user_score_dict</span><br><span class="line"></span><br><span class="line">    <span class="comment">#计算item之间的相似度</span></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">ItemSimilarity</span>(<span class="params">self</span>):</span><br><span class="line">        itemSim = <span class="built_in">dict</span>()</span><br><span class="line">        <span class="comment">#得到每个物品有多少用户产生过行为</span></span><br><span class="line">        item_user_count = <span class="built_in">dict</span>()</span><br><span class="line">        <span class="comment">#同现矩阵</span></span><br><span class="line">        count = <span class="built_in">dict</span>()</span><br><span class="line">        <span class="keyword">for</span> user, item <span class="keyword">in</span> self.user_score_dict.items():</span><br><span class="line">            <span class="keyword">for</span> i <span class="keyword">in</span> item.keys():</span><br><span class="line">                item_user_count.setdefault(i, <span class="number">0</span>)</span><br><span class="line">                <span class="keyword">if</span> self.user_score_dict[user][i] &gt; <span class="number">0.0</span>:</span><br><span class="line">                    item_user_count[i] += <span class="number">1</span></span><br><span class="line">                <span class="keyword">for</span> j <span class="keyword">in</span> item.keys():</span><br><span class="line">                    count.setdefault(i, &#123;&#125;).setdefault(j, <span class="number">0</span>)</span><br><span class="line">                    <span class="keyword">if</span>(</span><br><span class="line">                        self.user_score_dict[user][i] &gt; <span class="number">0.0</span> <span class="keyword">and</span> self.user_score_dict[user][j] &gt; <span class="number">0.0</span> <span class="keyword">and</span> i != j</span><br><span class="line">                    ):</span><br><span class="line">                        count[i][j] += <span class="number">1</span></span><br><span class="line">        <span class="comment">#同现矩阵-&gt;相似度矩阵</span></span><br><span class="line">        <span class="keyword">for</span> i, related_items <span class="keyword">in</span> count.items():</span><br><span class="line">            itemSim.setdefault(i, <span class="built_in">dict</span>())</span><br><span class="line">            <span class="keyword">for</span> j, cuv <span class="keyword">in</span> related_items.items():</span><br><span class="line">                itemSim[i].setdefault(j, <span class="number">0</span>)</span><br><span class="line">                itemSim[i][j] = cuv / item_user_count[i]</span><br><span class="line">        <span class="keyword">return</span> itemSim</span><br><span class="line"></span><br><span class="line">    <span class="comment">#预测用户对item的评分</span></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">preUserItemScore</span>(<span class="params">self, userA, item</span>):</span><br><span class="line">        score = <span class="number">0.0</span></span><br><span class="line">        <span class="keyword">for</span> item1 <span class="keyword">in</span> self.items_sim[item].keys():</span><br><span class="line">            <span class="keyword">if</span> item == item1:</span><br><span class="line">                <span class="keyword">continue</span></span><br><span class="line">            score += (</span><br><span class="line">                self.items_sim[item][item1] * self.user_score_dict[userA][item1]</span><br><span class="line">            )</span><br><span class="line">        <span class="keyword">return</span> score</span><br><span class="line"></span><br><span class="line">    <span class="comment">#为用户推荐物品</span></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">recommend</span>(<span class="params">self, userA</span>):</span><br><span class="line">        <span class="comment">#计算userA未评分item的可能评分</span></span><br><span class="line">        user_item_score_dict = <span class="built_in">dict</span>()</span><br><span class="line">        <span class="keyword">for</span> item <span class="keyword">in</span> self.user_score_dict[userA].keys():</span><br><span class="line">            user_item_score_dict[item] = self.preUserItemScore(userA, item)</span><br><span class="line">        <span class="keyword">return</span> <span class="built_in">sorted</span>(user_item_score_dict.items(),key=<span class="keyword">lambda</span> k:k[<span class="number">1</span>], reverse=<span class="literal">True</span>)</span><br><span class="line"></span><br><span class="line"><span class="keyword">if</span> __name__ == <span class="string">&quot;__main__&quot;</span>:</span><br><span class="line">    ib = ItemCF()</span><br><span class="line">    rec_A = ib.recommend(<span class="string">&quot;A&quot;</span>)</span><br><span class="line">    rec_B = ib.recommend(<span class="string">&quot;B&quot;</span>)</span><br><span class="line">    rec_C = ib.recommend(<span class="string">&quot;C&quot;</span>)</span><br><span class="line">    rec_D = ib.recommend(<span class="string">&quot;D&quot;</span>)</span><br><span class="line">    <span class="built_in">print</span>(<span class="string">&quot;为用户&#123;&#125;推荐的结果为&#123;&#125;&quot;</span>.<span class="built_in">format</span>(<span class="string">&quot;A&quot;</span>, rec_A))</span><br><span class="line">    <span class="built_in">print</span>(<span class="string">&quot;为用户&#123;&#125;推荐的结果为&#123;&#125;&quot;</span>.<span class="built_in">format</span>(<span class="string">&quot;B&quot;</span>, rec_B))</span><br><span class="line">    <span class="built_in">print</span>(<span class="string">&quot;为用户&#123;&#125;推荐的结果为&#123;&#125;&quot;</span>.<span class="built_in">format</span>(<span class="string">&quot;C&quot;</span>, rec_C))</span><br><span class="line">    <span class="built_in">print</span>(<span class="string">&quot;为用户&#123;&#125;推荐的结果为&#123;&#125;&quot;</span>.<span class="built_in">format</span>(<span class="string">&quot;D&quot;</span>, rec_D))</span><br></pre></td></tr></table></figure>

<p>输出结果：</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">为用户A推荐的结果为[(<span class="string">&#x27;d&#x27;</span>, 5.5), (<span class="string">&#x27;e&#x27;</span>, 4.833333333333333), (<span class="string">&#x27;a&#x27;</span>, 3.75), (<span class="string">&#x27;b&#x27;</span>, 3.333333333333333), (<span class="string">&#x27;c&#x27;</span>, 3.0)]</span><br><span class="line">为用户B推荐的结果为[(<span class="string">&#x27;c&#x27;</span>, 7.5), (<span class="string">&#x27;a&#x27;</span>, 4.0), (<span class="string">&#x27;d&#x27;</span>, 3.75), (<span class="string">&#x27;b&#x27;</span>, 3.666666666666666), (<span class="string">&#x27;e&#x27;</span>, 2.833333333333333)]</span><br><span class="line">为用户C推荐的结果为[(<span class="string">&#x27;d&#x27;</span>, 5.0), (<span class="string">&#x27;a&#x27;</span>, 3.25), (<span class="string">&#x27;c&#x27;</span>, 3.0), (<span class="string">&#x27;e&#x27;</span>, 2.333333333333333), (<span class="string">&#x27;b&#x27;</span>, 2.0)]</span><br><span class="line">为用户D推荐的结果为[(<span class="string">&#x27;d&#x27;</span>, 5.5), (<span class="string">&#x27;a&#x27;</span>, 5.25), (<span class="string">&#x27;b&#x27;</span>, 4.333333333333333), (<span class="string">&#x27;e&#x27;</span>, 3.833333333333333), (<span class="string">&#x27;c&#x27;</span>, 3.0)]</span><br></pre></td></tr></table></figure></li>
<li><p>惩罚热门商品</p>
<p>上述物品的相似度矩阵有问题：如果物品 $j$ 过于热门，有很多用户进行了评分，那么计算出的相似度评分 $w_{ij}$ 就很大。</p>
<p>新的相似度计算公式为：<br>$$<br>w_{ij}=\frac{|N(i)\cap N(j)|}{\sqrt{|N(i)||N(j)|}}<br>$$</p>
<ul>
<li>分母$N(i)$ 是喜欢物品 $i$ 的用户数</li>
<li>分母 $N(j)$ 是喜欢物品 $j$ 的用户数</li>
<li>分子$|N(i)\cap N(j)|$，是同时喜欢物品 $i$ 和 $j$ 的用户数</li>
</ul>
<p>==这里解决了自己之前的疑问点，新的公式解决了物品 $a$ 与物品 $b$的相似度，物品 $b$ 与物品 $a$的相似度不一样的问题==。<br>新的物品相似度矩阵为：</p>
<table>
<thead>
<tr>
<th align="center"></th>
<th align="center">a</th>
<th align="center">b</th>
<th align="center">c</th>
<th align="center">d</th>
<th align="center">e</th>
</tr>
</thead>
<tbody><tr>
<td align="center">a</td>
<td align="center">0</td>
<td align="center">$\frac1{\sqrt6}$</td>
<td align="center">$\frac1{\sqrt2}$</td>
<td align="center">$\frac12$</td>
<td align="center">$\frac1{\sqrt6}$</td>
</tr>
<tr>
<td align="center">b</td>
<td align="center"></td>
<td align="center">0</td>
<td align="center">0</td>
<td align="center">$\frac2{\sqrt6}$</td>
<td align="center">$\frac23$</td>
</tr>
<tr>
<td align="center">c</td>
<td align="center"></td>
<td align="center"></td>
<td align="center">0</td>
<td align="center">0</td>
<td align="center">$\frac1{\sqrt3}$</td>
</tr>
<tr>
<td align="center">d</td>
<td align="center"></td>
<td align="center"></td>
<td align="center"></td>
<td align="center">0</td>
<td align="center">$\frac1{\sqrt6}$</td>
</tr>
<tr>
<td align="center">e</td>
<td align="center"></td>
<td align="center"></td>
<td align="center"></td>
<td align="center"></td>
<td align="center">0</td>
</tr>
</tbody></table>
<p>用户C的评分矩阵为：</p>
<table>
<thead>
<tr>
<th align="center">物品</th>
<th align="center">评分</th>
</tr>
</thead>
<tbody><tr>
<td align="center">a</td>
<td align="center">0</td>
</tr>
<tr>
<td align="center">b</td>
<td align="center">3.5</td>
</tr>
<tr>
<td align="center">c</td>
<td align="center">0</td>
</tr>
<tr>
<td align="center">d</td>
<td align="center">0</td>
</tr>
<tr>
<td align="center">e</td>
<td align="center">3</td>
</tr>
</tbody></table>
<p>用户 $C$ 对于物品 $a$ 的兴趣为，<br>$$<br>P_{C,a}=\sum_{j\in S(a,K)\cap {N(C)}}w_{ij}r_{Cj}=0×0+\frac1{\sqrt{6}}×3.5+\frac1{\sqrt2}×0+\frac12×0+\frac1{\sqrt6}×3=2.65361388801511<br>$$<br>用户C对各个物品的兴趣即为相似度矩阵和用户Ｃ评分矩阵的乘积</p>
<table>
<thead>
<tr>
<th align="center">物品</th>
<th align="center">评分</th>
</tr>
</thead>
<tbody><tr>
<td align="center">==a==</td>
<td align="center">==2.65==</td>
</tr>
<tr>
<td align="center">b</td>
<td align="center">2.0</td>
</tr>
<tr>
<td align="center">==c==</td>
<td align="center">==1.73==</td>
</tr>
<tr>
<td align="center">==d==</td>
<td align="center">==4.08==</td>
</tr>
<tr>
<td align="center">e</td>
<td align="center">2.33</td>
</tr>
</tbody></table>
<p>去掉用户经评分的物品ｂ和ｅ，用户对物品的喜爱程度为$ｄ＞ａ＞ｃ$。</p>
<p>修正之后与修正之前喜爱程度一致。</p>
<p>修正之后的代码为:</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">#优化后的相似度计算</span></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">ItemSimilarityBest</span>(<span class="params">self</span>):</span><br><span class="line">    itemSim = <span class="built_in">dict</span>()</span><br><span class="line">    <span class="comment">#得到每个物品有多少用户产生过行为</span></span><br><span class="line">    item_user_count = <span class="built_in">dict</span>()</span><br><span class="line">    <span class="comment"># 同现矩阵</span></span><br><span class="line">    count = <span class="built_in">dict</span>()</span><br><span class="line">    <span class="keyword">for</span> user, item <span class="keyword">in</span> self.user_score_dict.items():</span><br><span class="line">        <span class="keyword">for</span> i <span class="keyword">in</span> item.keys():</span><br><span class="line">            item_user_count.setdefault(i, <span class="number">0</span>)</span><br><span class="line">            <span class="keyword">if</span> self.user_score_dict[user][i] &gt; <span class="number">0.0</span>:</span><br><span class="line">                item_user_count[i] += <span class="number">1</span></span><br><span class="line">            <span class="keyword">for</span> j <span class="keyword">in</span> item.keys():</span><br><span class="line">                count.setdefault(i, &#123;&#125;).setdefault(j, <span class="number">0</span>)</span><br><span class="line">                <span class="keyword">if</span> (</span><br><span class="line">                        self.user_score_dict[user][i] &gt; <span class="number">0.0</span> <span class="keyword">and</span> self.user_score_dict[user][j] &gt; <span class="number">0.0</span> <span class="keyword">and</span> i != j</span><br><span class="line">                ):</span><br><span class="line">                    count[i][j] += <span class="number">1</span></span><br><span class="line">                    <span class="comment"># 同现矩阵-&gt;相似度矩阵</span></span><br><span class="line">    <span class="keyword">for</span> i, related_items <span class="keyword">in</span> count.items():</span><br><span class="line">        itemSim.setdefault(i, <span class="built_in">dict</span>())</span><br><span class="line">        <span class="keyword">for</span> j, cuv <span class="keyword">in</span> related_items.items():</span><br><span class="line">            itemSim[i].setdefault(j, <span class="number">0</span>)</span><br><span class="line">            itemSim[i][j] = cuv / math.sqrt(item_user_count[i] * item_user_count[j])</span><br><span class="line">    <span class="keyword">return</span> itemSim</span><br></pre></td></tr></table></figure>

<p>输出结果：</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">为用户A推荐的结果为[(<span class="string">&#x27;e&#x27;</span>, 5.320280554681776), (<span class="string">&#x27;d&#x27;</span>, 4.765986323710905), (<span class="string">&#x27;b&#x27;</span>, 4.08248290463863), (<span class="string">&#x27;a&#x27;</span>, 3.3829931618554525), (<span class="string">&#x27;c&#x27;</span>, 2.1213203435596424)]</span><br><span class="line">为用户B推荐的结果为[(<span class="string">&#x27;c&#x27;</span>, 4.84915306690988), (<span class="string">&#x27;a&#x27;</span>, 4.610849531962985), (<span class="string">&#x27;e&#x27;</span>, 4.2310693732087685), (<span class="string">&#x27;b&#x27;</span>, 3.9663264951887856), (<span class="string">&#x27;d&#x27;</span>, 3.428869016623521)]</span><br><span class="line">为用户C推荐的结果为[(<span class="string">&#x27;d&#x27;</span>, 4.08248290463863), (<span class="string">&#x27;a&#x27;</span>, 2.65361388801511), (<span class="string">&#x27;e&#x27;</span>, 2.333333333333333), (<span class="string">&#x27;b&#x27;</span>, 2.0), (<span class="string">&#x27;c&#x27;</span>, 1.7320508075688776)]</span><br><span class="line">为用户D推荐的结果为[(<span class="string">&#x27;b&#x27;</span>, 4.857738033247042), (<span class="string">&#x27;a&#x27;</span>, 4.607738033247042), (<span class="string">&#x27;d&#x27;</span>, 4.4907311951024935), (<span class="string">&#x27;e&#x27;</span>, 4.095535683290187), (<span class="string">&#x27;c&#x27;</span>, 1.7320508075688776)]</span><br></pre></td></tr></table></figure></li>
</ol>
<h6 id="基于ItemCF算法的电影推荐系统"><a href="#基于ItemCF算法的电影推荐系统" class="headerlink" title="基于ItemCF算法的电影推荐系统"></a>基于ItemCF算法的电影推荐系统</h6><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> random</span><br><span class="line"><span class="keyword">import</span> math</span><br><span class="line"><span class="keyword">import</span> os</span><br><span class="line"><span class="keyword">import</span> json</span><br><span class="line"></span><br><span class="line">base_dir =  <span class="string">&quot;C:\\Users\\OAOA\\Desktop\\GXX的科研\\python\\FirstRec\\ml-1m&quot;</span></span><br><span class="line">item_sim_json_dir = os.path.join(base_dir, <span class="string">&quot;item_sim.json&quot;</span>)</span><br><span class="line"></span><br><span class="line"><span class="keyword">class</span> <span class="title class_">ItemCFRec</span>:</span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__init__</span>(<span class="params">self, datafile, ratio</span>):</span><br><span class="line">        <span class="comment">#原始数据路径文件</span></span><br><span class="line">        self.datafile = datafile</span><br><span class="line">        <span class="comment">#测试集与训练集的比例</span></span><br><span class="line">        self.ratio = ratio</span><br><span class="line"></span><br><span class="line">        self.data = self.loadData()</span><br><span class="line">        self.trainData,self.testData = self.splitData(<span class="number">3</span>,<span class="number">47</span>)</span><br><span class="line">        self.items_sim = self.ItemSimilarityBest()</span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">loadData</span>(<span class="params">self</span>):</span><br><span class="line">        <span class="built_in">print</span>(<span class="string">&quot;加载数据...&quot;</span>)</span><br><span class="line">        data = []</span><br><span class="line">        <span class="keyword">for</span> line <span class="keyword">in</span> <span class="built_in">open</span>(self.datafile):</span><br><span class="line">            userid, itemid, record,_ = line.split(<span class="string">&quot;::&quot;</span>)</span><br><span class="line">            data.append((userid, itemid, <span class="built_in">int</span>(record)))</span><br><span class="line">        <span class="keyword">return</span> data</span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">splitData</span>(<span class="params">self, k ,seed, M=<span class="number">9</span></span>):</span><br><span class="line">        <span class="built_in">print</span>(<span class="string">&quot;切分训练集和测试集...&quot;</span>)</span><br><span class="line">        train,test = &#123;&#125;, &#123;&#125;</span><br><span class="line">        random.seed(seed)</span><br><span class="line">        <span class="keyword">for</span> user, item, record <span class="keyword">in</span> self.data:</span><br><span class="line">            <span class="keyword">if</span> random.randint(<span class="number">0</span>, M) == k:</span><br><span class="line">                test.setdefault(user, &#123;&#125;)</span><br><span class="line">                test[user][item] = record</span><br><span class="line">            <span class="keyword">else</span>:</span><br><span class="line">                train.setdefault(user, &#123;&#125;)</span><br><span class="line">                train[user][item] = record</span><br><span class="line">        <span class="keyword">return</span> train, test</span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">ItemSimilarityBest</span>(<span class="params">self</span>):</span><br><span class="line">        <span class="built_in">print</span>(<span class="string">&quot;开始计算物品之间的相似度...&quot;</span>)</span><br><span class="line">        <span class="keyword">if</span> os.path.exists(item_sim_json_dir):</span><br><span class="line">            <span class="built_in">print</span>(<span class="string">&quot;从文件中加载物品相似度...&quot;</span>)</span><br><span class="line">            itemSim = json.load(<span class="built_in">open</span>(item_sim_json_dir, <span class="string">&quot;r&quot;</span>))</span><br><span class="line">        <span class="keyword">else</span>:</span><br><span class="line">            itemSim = <span class="built_in">dict</span>()</span><br><span class="line">            item_user_count = <span class="built_in">dict</span>()</span><br><span class="line">            count = <span class="built_in">dict</span>()</span><br><span class="line">            <span class="keyword">for</span> user, item <span class="keyword">in</span> self.trainData.items():</span><br><span class="line">                <span class="keyword">for</span> i <span class="keyword">in</span> item.keys():</span><br><span class="line">                    item_user_count.setdefault(i, <span class="number">0</span>)</span><br><span class="line">                    <span class="keyword">if</span> self.trainData[<span class="built_in">str</span>(user)][i] &gt; <span class="number">0.0</span>:</span><br><span class="line">                        item_user_count[i] += <span class="number">1</span></span><br><span class="line">                    <span class="keyword">for</span> j <span class="keyword">in</span> item.keys():</span><br><span class="line">                        count.setdefault(i, &#123;&#125;).setdefault(j, <span class="number">0</span>)</span><br><span class="line">                        <span class="keyword">if</span> (</span><br><span class="line">                                self.trainData[<span class="built_in">str</span>(user)][i] &gt; <span class="number">0.0</span> <span class="keyword">and</span> self.trainData[<span class="built_in">str</span>(user)][j] &gt; <span class="number">0.0</span> <span class="keyword">and</span> i != j</span><br><span class="line">                        ):</span><br><span class="line">                            count[i][j] += <span class="number">1</span></span><br><span class="line">            <span class="keyword">for</span> i, related_items <span class="keyword">in</span> count.items():</span><br><span class="line">                itemSim.setdefault(i, <span class="built_in">dict</span>())</span><br><span class="line">                <span class="keyword">for</span> j, cuv <span class="keyword">in</span> related_items.items():</span><br><span class="line">                    itemSim[i].setdefault(j, <span class="number">0</span>)</span><br><span class="line">                    itemSim[i][j] = cuv / math.sqrt(item_user_count[i] * item_user_count[j])</span><br><span class="line">            json.dump(itemSim, <span class="built_in">open</span>(item_sim_json_dir, <span class="string">&quot;w&quot;</span>))</span><br><span class="line">        <span class="keyword">return</span> itemSim</span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">recommend</span>(<span class="params">self, user, k=<span class="number">8</span>, nitems=<span class="number">40</span></span>):</span><br><span class="line">        result = <span class="built_in">dict</span>()</span><br><span class="line">        u_items = self.trainData.get(user, &#123;&#125;)</span><br><span class="line">        <span class="keyword">for</span> i, pi <span class="keyword">in</span> u_items.items():</span><br><span class="line">            <span class="keyword">for</span> j, wj <span class="keyword">in</span> <span class="built_in">sorted</span>(self.items_sim[i].items(), key=<span class="keyword">lambda</span> x:x[<span class="number">1</span>], reverse=<span class="literal">True</span>)[<span class="number">0</span>:k]:</span><br><span class="line">                <span class="keyword">if</span> j <span class="keyword">in</span> u_items:</span><br><span class="line">                    <span class="keyword">continue</span></span><br><span class="line">                result.setdefault(j, <span class="number">0</span>)</span><br><span class="line">                result[j] += pi * wj</span><br><span class="line">        <span class="keyword">return</span> <span class="built_in">dict</span>(<span class="built_in">sorted</span>(result.items(), key=<span class="keyword">lambda</span>  x:x[<span class="number">1</span>], reverse=<span class="literal">True</span>)[<span class="number">0</span>:nitems])</span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">precision</span>(<span class="params">self, k=<span class="number">8</span>, nitems=<span class="number">10</span></span>):</span><br><span class="line">        <span class="built_in">print</span>(<span class="string">&quot;开始计算准确率...&quot;</span>)</span><br><span class="line">        hit = <span class="number">0</span></span><br><span class="line">        precision = <span class="number">0</span></span><br><span class="line">        <span class="keyword">for</span> user <span class="keyword">in</span> self.testData.keys():</span><br><span class="line">            u_items = self.testData.get(user, &#123;&#125;)</span><br><span class="line">            result = self.recommend(user, k=k,nitems=nitems)</span><br><span class="line">            <span class="keyword">for</span> item, rate <span class="keyword">in</span> result.items():</span><br><span class="line">                <span class="keyword">if</span> item <span class="keyword">in</span> u_items:</span><br><span class="line">                    hit += <span class="number">1</span></span><br><span class="line">            precision += nitems</span><br><span class="line">        <span class="keyword">return</span> hit / (precision * <span class="number">1.0</span>)</span><br><span class="line"><span class="keyword">if</span> __name__ == <span class="string">&quot;__main__&quot;</span>:</span><br><span class="line">    rating_dir = os.path.join(base_dir, <span class="string">&quot;ratings.dat&quot;</span>)</span><br><span class="line">    ib = ItemCFRec(rating_dir,  <span class="number">9</span>)</span><br><span class="line">    <span class="built_in">print</span>(<span class="string">&quot;为用户&#123;&#125;推荐的结果为：&#123;&#125;&quot;</span>.<span class="built_in">format</span>(<span class="number">1</span>,ib.recommend(<span class="string">&quot;1&quot;</span>)))</span><br><span class="line">    <span class="built_in">print</span>(<span class="string">&quot;准确率为&#123;&#125;%&quot;</span>.<span class="built_in">format</span>(ib.precision() * <span class="number">100</span>))</span><br></pre></td></tr></table></figure>

<p>输出结果为：</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">加载数据...</span><br><span class="line">切分训练集和测试集...</span><br><span class="line">开始计算物品之间的相似度...</span><br><span class="line">从文件中加载物品相似度...</span><br><span class="line">为用户1推荐的结果为：&#123;<span class="string">&#x27;1196&#x27;</span>: 17.22324153978063, <span class="string">&#x27;318&#x27;</span>: 14.8218906371964, <span class="string">&#x27;2716&#x27;</span>: 13.932507077429019, <span class="string">&#x27;364&#x27;</span>: 13.35235698820404, <span class="string">&#x27;2858&#x27;</span>: 13.325911191816022, <span class="string">&#x27;1&#x27;</span>: 12.914848064503321, <span class="string">&#x27;296&#x27;</span>: 12.512414763950453, <span class="string">&#x27;2080&#x27;</span>: 11.670146741436719, <span class="string">&#x27;2571&#x27;</span>: 10.792597977281147, <span class="string">&#x27;593&#x27;</span>: 10.446304556182827, <span class="string">&#x27;2096&#x27;</span>: 10.368979592758734, <span class="string">&#x27;596&#x27;</span>: 10.13725849369314, <span class="string">&#x27;2081&#x27;</span>: 9.921090783980166, <span class="string">&#x27;1210&#x27;</span>: 9.325669846740483, <span class="string">&#x27;1240&#x27;</span>: 9.28336273387751, <span class="string">&#x27;2174&#x27;</span>: 9.039510454479082, <span class="string">&#x27;1282&#x27;</span>: 8.789133141522845, <span class="string">&#x27;1307&#x27;</span>: 8.641579396655672, <span class="string">&#x27;2087&#x27;</span>: 7.940266033456998, <span class="string">&#x27;1247&#x27;</span>: 7.589628194850254, <span class="string">&#x27;1617&#x27;</span>: 6.58142482058723, <span class="string">&#x27;1225&#x27;</span>: 6.311592187999355, <span class="string">&#x27;1198&#x27;</span>: 6.288333941479948, <span class="string">&#x27;50&#x27;</span>: 6.2856030521067, <span class="string">&#x27;1246&#x27;</span>: 5.877072937999628, <span class="string">&#x27;1302&#x27;</span>: 5.787231467335493, <span class="string">&#x27;2396&#x27;</span>: 5.744579546093331, <span class="string">&#x27;1380&#x27;</span>: 5.636006024806621, <span class="string">&#x27;589&#x27;</span>: 5.176021124227352, <span class="string">&#x27;2565&#x27;</span>: 5.156414479326834, <span class="string">&#x27;1265&#x27;</span>: 5.13537979616685, <span class="string">&#x27;2078&#x27;</span>: 5.021461088379507, <span class="string">&#x27;1213&#x27;</span>: 4.920525721942344, <span class="string">&#x27;1032&#x27;</span>: 4.826989015765321, <span class="string">&#x27;2997&#x27;</span>: 4.788489269736071, <span class="string">&#x27;1394&#x27;</span>: 4.547365232425783, <span class="string">&#x27;1079&#x27;</span>: 4.376070358831856, <span class="string">&#x27;1073&#x27;</span>: 4.15288382260949, <span class="string">&#x27;1947&#x27;</span>: 4.024178692829672, <span class="string">&#x27;1704&#x27;</span>: 3.967846111216935&#125;</span><br><span class="line">开始计算准确率...</span><br></pre></td></tr></table></figure>





<h6 id="UserCF算法和ItemCF算法的对比"><a href="#UserCF算法和ItemCF算法的对比" class="headerlink" title="UserCF算法和ItemCF算法的对比"></a>UserCF算法和ItemCF算法的对比</h6><ol>
<li><p>在适用场景上的比较</p>
<p>在一个非社交网站上，要给用户推荐一本书，有两种情况：</p>
<ul>
<li>如果利用<code>UserCF</code>算法，系统给出的解释是“和你有相似兴趣的某某也看了该书”，这很难让用户信服。因为被推荐者可能根本不认识这里的“某某”。</li>
<li>如果利用<code>ItemCF</code>算法，系统给出的解释是“这本书和你之前看的某本书相似”，显然更加合理，用户可能就会接受系统的推荐。</li>
</ul>
</li>
<li><p>在推荐系统多样性上的比较</p>
<ul>
<li>单用户的多样性方面：<code>ItemCF</code>算法不如<code>UserCF</code>算法多样性丰富。因为，<code>ItemCF</code>算法推荐的是和之前有行为物品的相似物品，物品覆盖面比较小，丰富度低。</li>
<li>系统的多样性方面：<code>ItemCF</code>算法的多样性要远远好于<code>UserCF</code>算法。因为，<code>UserCF</code>算法更加注重推荐热门商品。</li>
</ul>
<p>系统多样性也称为==覆盖率==，指一个推荐系统能否给用户提供更多的选择。</p>
</li>
<li><p>在用户特点上的比较</p>
<ul>
<li><p><code>UserCF</code>算法推荐的原则是“假设用户喜欢那些和他有相同喜好的用户喜欢的东西”，但是，如果用户暂时找不到兴趣相同的邻居，那么基于用户的推荐效果就打了折扣了。</p>
<p>因此用户是否适应<code>UserCF</code>，==与他有多少邻居是成正比的==。</p>
</li>
<li><p>基于物品的协同过滤算法的前提是“用户喜欢和他以前购买过的物品类型相同的物品”，可以计算一个用户喜欢的物品的自相似度。</p>
</li>
</ul>
<p>一个用户喜欢物品的自相似度大，即用户喜欢的物品的相关度大，则说明他喜欢的东西是比较相似的。即，==这个用户比较符合<code>ItemCF</code>算法的基本假设，他对<code>ItemCF</code>算法的适应度比较好。</p>
<p>反之，如果自相似度小，即用户喜欢的物品的相关度小，就说明这个用户的喜好习惯并不满足<code>ItemCF</code>算法的基本假设，那么用<code>ItemCF</code>算法所做出的推荐对于这种用户来说效果就可能不是很好。</p>
</li>
</ol>
<h5 id="基于隐语义模型的推荐算法"><a href="#基于隐语义模型的推荐算法" class="headerlink" title="基于隐语义模型的推荐算法"></a>基于隐语义模型的推荐算法</h5><p>隐语义模型（Latent Factor Model，LFM）属于机器学习算法，其中包含了隐含因子，类似于神经网络中的隐藏层，所以很难解释隐含因子与最终结果有什么直观的联系。但这并不妨碍训练模型，只需要根据现有的数据训练出合适的隐含因子，使得目标函数最优化，那么模型就是可用的。</p>
<p>隐语义模型的基本原理。</p>
<p>假设现在有A，B两个用户，A用户喜欢读《三国演义》，B用户喜欢读《从你的全世界路过》，现在对A、B两个用户进行书籍推荐：</p>
<ul>
<li><code>User-Based</code>的思想是，找到与他们相似的用户，将相似的用户喜欢的书籍推荐给他们</li>
<li><code>Item-Based</code>的思想是，找到他们当前喜欢的书籍，将相似的书籍推荐给他们</li>
<li>隐语义模型的思想是，找到用户的偏好特征，将该类偏好特征对应的书籍推荐给他们</li>
</ul>
<p>《三国演义》属于历史书，那么可以把历史书相关书籍推荐给A用户。而《从你的全世界路过》属于青春文学书籍，那么可以把该类别下的书籍推荐给B用户。</p>
<p>这就是隐语义模型的原理——==依据兴趣这一隐含特征将用户与物品进行连接==。这里的兴趣，是指对==物品类型的一个分类==。</p>
<h6 id="LFM原理分析"><a href="#LFM原理分析" class="headerlink" title="LFM原理分析"></a>LFM原理分析</h6><p><img src="image-20210719101453175.png" alt="image-20210719101453175"></p>
<ul>
<li>$R$ 矩阵表示用户对物品的偏好信息。其中， $R_{ij}$ 代表 User $i$ 对 Item $j$ 的兴趣度。</li>
<li>$P$ 矩阵表示用户对各物品类别的偏好信息。其中， $P_{ij}$ 代表User $i$ 对 Class $j$ 的兴趣度。</li>
<li>$Q$ 矩阵表示各个物品归属到各个类别的信息。其中， $Q_{ij}$代表Item $j$ 在Class $i$ 中的权重或概率。</li>
</ul>
<p>隐语义模型就是要将矩阵 $R$ 分解为 $P$ 和 $Q$ 的乘积，即通过矩阵中的物品类别 class 将用户 User 和物品 Item联系起来。实际上需要根据用户当前的物品偏好信息 $R$进行计算，从而得到对应的矩阵 $P$ 和矩阵 $Q$。</p>
<p>因此可以得到隐语义模型计算用户对物品兴趣度的公式：<br>$$<br>R(u,i)=\sum_{k=1}^KP_{u,k}Q_{i,k}<br>$$<br>其中：</p>
<ul>
<li>$P_{u,k}$：用户 $u$ 兴趣和第 $k$ 个隐类的关系</li>
<li>$Q_{i,k}$：第 $k$ 个隐类和物品 $i$ 的关系</li>
<li>$K$：隐类的数量</li>
<li>$R$：用户对物品的兴趣度</li>
</ul>
<p>举例：LFM把所有的电影分为三类[武打片，动画片，爱情片]，用户A非常喜欢武打片，用户A的$P(u,k)$向量可以表示为$[1,0,0]$。</p>
<p>现在有两部电影：</p>
<ul>
<li>《天龙八部》，其中$Q(i,k)$向量表示为$[1,0,0]^T$</li>
<li>《天线宝宝》，其中$Q(i,k)$向量表示为$[0,1,0]^T$</li>
</ul>
<p>那么就可以计算用户A对这两部电影的兴趣度了：</p>
<ul>
<li>$R(A,天龙八部)=P(u,k)×Q(i,k)=[1,0,0]×[1,0,0]^T=[1,0,0]×\begin{bmatrix}1\0\0\end{bmatrix}=1$</li>
<li>$R(A,天线宝宝)=P(u,k)×Q(i,k)=[1,0,0]×[0,1,0]^T=[1,0,0]×\begin{bmatrix}0\1\0\end{bmatrix}=0$</li>
</ul>
<p>这样就可以判断用户A对于电影《天龙八部》的兴趣度要比《天线宝宝》高，更应该给A推荐《天龙八部》。</p>
<h6 id="LFM需要解决的问题"><a href="#LFM需要解决的问题" class="headerlink" title="LFM需要解决的问题"></a>LFM需要解决的问题</h6><p>要想实现隐语义模型，需要解决如下几个问题：</p>
<p>（1）如何对物品进行分类，分为几类？</p>
<p>（2）如何确定用户对哪些物品类别有兴趣？兴趣度是多少？</p>
<p>（3）对于一个给定的类别，选择这个类别下的哪些物品进行推荐？如何确定物品在该类别中的权重？</p>
<p>对于问题（1），如果找专家进行物品分类，将会面临两个问题：</p>
<p>1）不同专家对物品的认知不一样，会将同一个物品分为不同的类别。</p>
<p>2）很难把控类别的粒度。</p>
<p>对于问题（2），可以人为标注短期内的用户兴趣类别，但是随着时间的推移，用户的兴趣是会发生变化的，很难稳定且确定地知道用户的兴趣类别。</p>
<p>对于问题3），一个物品可能属于多个类别，但是同一个物品在不同的类别下权重是不一样的，很难确定一个物品在某一分类中的权重。</p>
<p>隐语义模型是==从用户的偏好数据出发进行个性推荐的==，即==基于用户的行为统计进行自动聚类==，所以能够解决上述问题。</p>
<p>（1）隐语义模型是基于用户的行为数据进行自动聚类的，能反映用户对物品的分类意见，可以指定将物品聚类的类别数 $K$，$K$越大，则粒度越细。</p>
<p>（2）隐语义模型能够动态获取用户的兴趣类别和程度，因为它是基于用户的行为数据进行的统计分析。</p>
<p>（3）隐语义模型能计算出物品在各个类别中的权重，这是根据用户的行为数据统计的，不会只将其归到一类中。隐语义模型得到的物品类别不是基于同一个维度的，它的维度是由用户的共同兴趣决定的。</p>
<h6 id="LFM的样本问题"><a href="#LFM的样本问题" class="headerlink" title="LFM的样本问题"></a>LFM的样本问题</h6><ol>
<li><p>显性反馈数据集</p>
<p>用户在电商平台上对物品进行“收藏”、“点赞”、“分享”等行为，就是显性反馈数据的来源。隐语义模型在显性反馈数据上能==解决评分预测问题==并达到了很好的精度。</p>
</li>
<li><p>隐性反馈数据集</p>
<p>隐性反馈数据比较难获取。</p>
<p>如果把用户经常浏览的商品作为某个隐分类的正反馈数据集，应该在热门推荐系统的基础上，选择一些热门但是用户没有浏览过或表达偏好的商品，当做用户不喜欢的商品。因为热门商品应该是经常被用户看到的，在这个前提下，用户却没有产生交互，因此可以断定用户不喜欢这一类型的商品。</p>
<p>对于显性反馈数据和隐形反馈数据，都应该==选取适当的负反馈数据==。正反馈样本数和负反馈样本数的比例$ratio$==需要在不断实验中得到最合适的值==。</p>
</li>
</ol>
<h6 id="LFM推导"><a href="#LFM推导" class="headerlink" title="LFM推导"></a>LFM推导</h6><p>通过$R(u,i)=\sum_{k=1}^KP_{u,k}Q_{i,k}$ 可知，LFM最终求的是 $P\text{(用户对某个类别的兴趣度)}$ 和 $Q \text{(物品属于某个分类的权重)}$。一般采用最优化损失函数来求解 $P$ 和 $Q$。</p>
<p>损失函数为：<br>$$<br>c=\sum_{(u,i)\in S}(R_{ui}-\hat{R_{ui}})^2=\sum_{(u,i)\in S}(R_{ui}-\sum_{k=1}^K(P_{uk}Q_{ik}))^2+\lambda||P_{u}||^2+\lambda||Q_i||^2<br>$$<br>损失函数的意义是，==用户 $u$ 对物品 $i$ 的真实兴趣度与推算出来的兴趣度的误差平方和==。如果使模型最优，则误差平方和必然应该最小。</p>
<p>其中，$\lambda||P_{u}||^2+\lambda||Q_i||^2$ 是用来防止过拟合的正则项，==$\lambda$ 需要在实际场景中反复进行实验以得到合适的值==。</p>
<p>关于损失函数求最小值，可以使用梯度下降算法，梯度下降算法分为：</p>
<ul>
<li>批量梯度下降算法（Batch Gradient Descent Algorithm， BGD）</li>
<li>随机梯度下降算法（Stochastic Gradient Descent Algorithm，SGD）</li>
<li>小批量梯度下降算法（Mini-batch Gradient Descent Algorithm，MBGD）</li>
</ul>
<p>使用最多、最广的便是<code>SGD</code>。</p>
<p>使用随机梯度下降算法对损失函数进行优化的步骤如下：</p>
<p>对两组未知参数进行求偏导，<br>$$<br>\frac{\partial c}{\partial P_{uk}}=-2\sum_{(u,i)\in S}(R_{ui}-\sum_{i=1}^KP_{uk}Q_{ki})Q_{ki}+2\lambda P_{uk}<br>$$</p>
<p>$$<br>\frac{\partial c}{\partial Q_{ki}}=-2\sum_{(u,i)\in S}(R_{ui}-\sum_{i=1}^KP_{uk}Q_{ki})P_{uk}+2\lambda Q_{ki}<br>$$</p>
<p>迭代计算，不断优化参数（迭代的次数人为设定），直至参数收敛，迭代形式如下：<br>$$<br>P_{uk}=P_{uk}+\alpha (\sum_{(u,i)\in S}(R_{ui}-\sum_{k=1}^KP_{uk}Q_{ki})Q_{ki}-\lambda P_{uk})<br>$$</p>
<p>$$<br>Q_{ki}=Q_{ki}+\alpha (\sum_{(u,i)\in S}(R_{ui}-\sum_{k=1}^KP_{uk}Q_{ki})P_{uk}-\lambda Q_{ki})<br>$$</p>
<p>其中，$\alpha$ 是学习速率， $\alpha$ 越大，迭代下降得越快。</p>
<p>==$\alpha$ 和$\lambda$ 一样，不宜过大，也不宜过小。==过大会产生振荡而导致很难求得最小值；过小则会造成计算速度下降。</p>
<p>在隐语义模型中，重要的参数是：</p>
<ul>
<li>$K$ ：隐分类的个数</li>
<li>$\alpha$：梯度下降过程中的步长（学习速率）</li>
<li>$\alpha$：损失惩罚函数中的惩罚因子</li>
<li>$ratio$ ：正反馈样本数和负反馈样本数的比例</li>
</ul>
<p>==这四个参数需要在试验过程中不断调整以获得最合适的值==。其中， $K,\lambda,ratio$需要以系统的<code>准确率</code>、<code>召回率</code>、<code>覆盖率</code>和<code>流行度</code>为参考，而==$\alpha$== 要参考模型的训练效率。</p>
<h6 id="LFM优缺点"><a href="#LFM优缺点" class="headerlink" title="LFM优缺点"></a>LFM优缺点</h6><p>隐语义模型在实际应用中有一个问题——很难实现==实时推荐==。</p>
<ul>
<li>经典的隐语义模型每次训练时都需要扫描所有的用户行为记录，这样才能计算出用户对每个隐分类的兴趣度矩阵 $P$，以及每个物品与每个隐分类的匹配度矩阵 $P$。</li>
<li>隐语义模型的训练需要在用户行为记录上反复迭代，这样才能获得较好的性能。</li>
</ul>
<p>LFM的每次训练，一般在实际应用中只能每天训练一次，并且计算出所有用户的推荐结果。</p>
<p>因此，隐语义模型不能因为用户行为的变化而实时地调整推荐结果来满足用户最近的行为。</p>
<h6 id="基于LFM的电影推荐系统"><a href="#基于LFM的电影推荐系统" class="headerlink" title="基于LFM的电影推荐系统"></a>基于LFM的电影推荐系统</h6><ol>
<li><p>数据格式转换</p>
<p>将<code>dat</code>格式的数据转换为<code>csv</code>格式。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> pandas <span class="keyword">as</span> pd</span><br><span class="line"><span class="keyword">import</span> json</span><br><span class="line"><span class="keyword">import</span> os</span><br><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="keyword">import</span> math</span><br><span class="line"><span class="keyword">import</span> random</span><br><span class="line"></span><br><span class="line">base_dir = <span class="string">&quot;C:\\Users\\OAOA\\Desktop\\GXX的科研\\python\\FirstRec\\ml-1m&quot;</span></span><br><span class="line">user_data_dir = os.path.join(base_dir, <span class="string">&quot;users.dat&quot;</span>)</span><br><span class="line">movies_data_dir = os.path.join(base_dir, <span class="string">&quot;movies.dat&quot;</span>)</span><br><span class="line">rating_data_dir = os.path.join(base_dir, <span class="string">&quot;ratings.dat&quot;</span>)</span><br><span class="line">use_dir = os.path.join(base_dir, <span class="string">&quot;use&quot;</span>)</span><br><span class="line"></span><br><span class="line">csv_users_dir = os.path.join(use_dir, <span class="string">&quot;users.csv&quot;</span>)</span><br><span class="line">csv_movies_dir = os.path.join(use_dir, <span class="string">&quot;movies.csv&quot;</span>)</span><br><span class="line">csv_ratings_dir = os.path.join(use_dir, <span class="string">&quot;ratings.csv&quot;</span>)</span><br><span class="line"></span><br><span class="line">item_profile_json_dir = os.path.join(base_dir, <span class="string">&quot;item_profile.json&quot;</span>)</span><br><span class="line">user_profile_json_dir = os.path.join(base_dir, <span class="string">&quot;user_profile.json&quot;</span>)</span><br><span class="line"></span><br><span class="line"><span class="keyword">try</span>:</span><br><span class="line">    os.mkdir(use_dir)</span><br><span class="line"><span class="keyword">except</span>:</span><br><span class="line">    <span class="keyword">pass</span></span><br><span class="line"><span class="keyword">class</span> <span class="title class_">DataProcessing</span>:</span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__init__</span>(<span class="params">self</span>):</span><br><span class="line">        <span class="keyword">pass</span></span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">process_user_data</span>(<span class="params">self, file= user_data_dir</span>):</span><br><span class="line">        fp = pd.read_table(file, sep=<span class="string">&quot;::&quot;</span>, engine=<span class="string">&#x27;python&#x27;</span>, names=[<span class="string">&quot;UserID&quot;</span>, <span class="string">&quot;Gender&quot;</span>, <span class="string">&quot;Age&quot;</span>, <span class="string">&quot;Occupation&quot;</span>, <span class="string">&quot;Zip-code&quot;</span>])</span><br><span class="line">        fp.to_csv(csv_users_dir, index=<span class="literal">False</span>)</span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">process_movies_data</span>(<span class="params">self, file= movies_data_dir</span>):</span><br><span class="line">        fp = pd.read_table(file, sep=<span class="string">&quot;::&quot;</span>, engine=<span class="string">&#x27;python&#x27;</span>, names=[<span class="string">&quot;MovieID&quot;</span>, <span class="string">&quot;Title&quot;</span>, <span class="string">&quot;Genres&quot;</span>])</span><br><span class="line">        fp.to_csv(csv_movies_dir, index=<span class="literal">False</span>)</span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">process_rating_data</span>(<span class="params">self, file= rating_data_dir</span>):</span><br><span class="line">        fp = pd.read_table(file, sep=<span class="string">&quot;::&quot;</span>, engine=<span class="string">&#x27;python&#x27;</span>, names=[<span class="string">&quot;UserID&quot;</span>, <span class="string">&quot;MovieID&quot;</span>, <span class="string">&quot;Rating&quot;</span>, <span class="string">&quot;Timestamp&quot;</span>])</span><br><span class="line">        fp.to_csv(csv_ratings_dir, index=<span class="literal">False</span>)</span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">process</span>(<span class="params">self</span>):</span><br><span class="line">        <span class="built_in">print</span>(<span class="string">&quot;开始转换用户数据（users.dat）...&quot;</span>)</span><br><span class="line">        self.process_user_data()</span><br><span class="line">        <span class="built_in">print</span>(<span class="string">&quot;开始转换电影数据（movies.dat）...&quot;</span>)</span><br><span class="line">        self.process_movies_data()</span><br><span class="line">        <span class="built_in">print</span>(<span class="string">&quot;开始转换用户对电影评分数据（ratings.dat）...&quot;</span>)</span><br><span class="line">        self.process_rating_data()</span><br><span class="line">        <span class="built_in">print</span>(<span class="string">&quot;Over!&quot;</span>)</span><br><span class="line"></span><br><span class="line"><span class="keyword">if</span> __name__ == <span class="string">&quot;__main__&quot;</span>:</span><br><span class="line">    dp = DataProcessing()</span><br><span class="line">    dp.process()</span><br></pre></td></tr></table></figure>

<p>LFM模型是为了寻找合适的 $P$ 和 $Q$，从而预测用户对未评分电影的评分。因此需要准备一份训练数据，该数据表示的是每个用户是否有过行为，有行为则标记为1，没有则标记为0。</p>
<p>为用户的行为打标记。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">#对用户进行有行为电影和无行为电影数据标记</span></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">get_pos_neg_item</span>(<span class="params">self, file_path=csv_ratings_dir</span>):</span><br><span class="line">    <span class="keyword">if</span> <span class="keyword">not</span> os.path.exists(lfm_items_dict_dir):</span><br><span class="line">        self.items_dict_path = lfm_items_dict_dir</span><br><span class="line">   </span><br><span class="line">        self.uiscores = pd.read_csv(file_path)</span><br><span class="line">        self.user_ids = <span class="built_in">set</span>(self.uiscores[<span class="string">&quot;UserID&quot;</span>].values)</span><br><span class="line">        self.item_ids = <span class="built_in">set</span>(self.uiscores[<span class="string">&quot;MovieID&quot;</span>].values)</span><br><span class="line">        self.items_dict = &#123;user_id: self.get_one(user_id) <span class="keyword">for</span> user_id <span class="keyword">in</span> <span class="built_in">list</span>(self.user_ids)&#125;</span><br><span class="line">   </span><br><span class="line">        fw = <span class="built_in">open</span>(self.items_dict_path, <span class="string">&quot;wb&quot;</span>)</span><br><span class="line">        pickle.dump(self.items_dict, fw)</span><br><span class="line">        fw.close()</span><br><span class="line">   </span><br><span class="line"><span class="comment">#定义单个用户的正向和负向数据</span></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">get_one</span>(<span class="params">self, user_id</span>):</span><br><span class="line">    <span class="built_in">print</span>(<span class="string">&quot;正在为用户&#123;&#125;准备正向和负向数据...&quot;</span>.<span class="built_in">format</span>(user_id))</span><br><span class="line">    pos_item_ids = <span class="built_in">set</span>(self.uiscores[self.uiscores[<span class="string">&quot;UserID&quot;</span>] == user_id][<span class="string">&#x27;MovieID&#x27;</span>])</span><br><span class="line">    <span class="comment">#对称差</span></span><br><span class="line">    neg_item_ids = self.item_ids ^ pos_item_ids</span><br><span class="line">    neg_item_ids = <span class="built_in">list</span>(neg_item_ids)[:<span class="built_in">len</span>(pos_item_ids)]</span><br><span class="line">    item_dict = &#123;&#125;</span><br><span class="line">    <span class="keyword">for</span> item <span class="keyword">in</span> pos_item_ids:</span><br><span class="line">        item_dict[item] = <span class="number">1</span></span><br><span class="line">    <span class="keyword">for</span> item <span class="keyword">in</span> neg_item_ids:</span><br><span class="line">        item_dict[item] = <span class="number">0</span></span><br><span class="line">    <span class="keyword">return</span> item_dict</span><br></pre></td></tr></table></figure>

<p>输出结果</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line">开始转换用户数据（users.dat）...</span><br><span class="line">开始转换电影数据（movies.dat）...</span><br><span class="line">开始转换用户对电影评分数据（ratings.dat）...</span><br><span class="line">Over!</span><br><span class="line">正在为用户1准备正向和负向数据...</span><br><span class="line">正在为用户2准备正向和负向数据...</span><br><span class="line">正在为用户3准备正向和负向数据...</span><br><span class="line">正在为用户4准备正向和负向数据...</span><br><span class="line">正在为用户5准备正向和负向数据...</span><br><span class="line">正在为用户6准备正向和负向数据...</span><br><span class="line">...</span><br><span class="line">正在为用户6039准备正向和负向数据...</span><br><span class="line">正在为用户6040准备正向和负向数据...</span><br></pre></td></tr></table></figure></li>
<li><p>选择算法</p>
<p>使用==隐语义模型（LFM）==和==随机梯度下降算法（SGD）==。</p>
</li>
<li><p>加载数据</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">class</span> <span class="title class_">LFM</span>:</span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__init__</span>(<span class="params">self</span>):</span><br><span class="line">        self.class_count = <span class="number">5</span></span><br><span class="line">        self.iter_count = <span class="number">5</span></span><br><span class="line">        self.lr = <span class="number">0.02</span></span><br><span class="line">        self.lam = <span class="number">0.01</span></span><br><span class="line">        self._init_model()</span><br><span class="line"></span><br><span class="line">    <span class="string">&quot;&quot;&quot;</span></span><br><span class="line"><span class="string">    初始化参数</span></span><br><span class="line"><span class="string">    randn: 从标准正态分布中返回n个值</span></span><br><span class="line"><span class="string">    pd.DataFrame: columns指定列顺序，index指定索引</span></span><br><span class="line"><span class="string">    &quot;&quot;&quot;</span></span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">_init_model</span>(<span class="params">self</span>):</span><br><span class="line">        file_path = csv_ratings_dir</span><br><span class="line">        pos_neg_path = lfm_items_dict_dir</span><br><span class="line"></span><br><span class="line">        self.uiscores = pd.read_csv(file_path)</span><br><span class="line">        self.user_ids = <span class="built_in">set</span>(self.uiscores[<span class="string">&#x27;UserID&#x27;</span>].values)</span><br><span class="line">        self.item_ids = <span class="built_in">set</span>(self.uiscores[<span class="string">&#x27;MovieID&#x27;</span>].values)</span><br><span class="line">        self.items_dict = pickle.load(<span class="built_in">open</span>(pos_neg_path, <span class="string">&#x27;rb&#x27;</span>))</span><br><span class="line"></span><br><span class="line">        array_p = np.random.randn(<span class="built_in">len</span>(self.user_ids), self.class_count)</span><br><span class="line">        array_q = np.random.randn(<span class="built_in">len</span>(self.item_ids), self.class_count)</span><br><span class="line">        self.p = pd.DataFrame(array_p, columns=<span class="built_in">range</span>(<span class="number">0</span>, self.class_count), index=<span class="built_in">list</span>(self.user_ids))</span><br><span class="line">        self.q = pd.DataFrame(array_q, columns=<span class="built_in">range</span>(<span class="number">0</span>, self.class_count), index=<span class="built_in">list</span>(self.item_ids))</span><br></pre></td></tr></table></figure></li>
<li><p>准备模型</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">def</span> <span class="title function_">_predict</span>(<span class="params">self, user_id, item_id</span>):</span><br><span class="line">    p = np.mat(self.p.ix[user_id].values)</span><br><span class="line">    q = np.mat(self.q.ix[item_id].values).T</span><br><span class="line">    r = (p * q).<span class="built_in">sum</span>()</span><br><span class="line">    logit = <span class="number">1.0</span> / (<span class="number">1</span> + math.exp(-r)) <span class="comment">#即sigmoid函数</span></span><br><span class="line">    <span class="keyword">return</span> logit <span class="comment"># 返回兴趣</span></span><br><span class="line">   </span><br><span class="line"><span class="comment"># 使用误差平方和(SSE)作为损失函数</span></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">_loss</span>(<span class="params">self, user_id, item_id, y, step</span>):</span><br><span class="line">    e = y - self._predict(user_id, item_id)</span><br><span class="line">    <span class="built_in">print</span>(<span class="string">&quot;Step: &#123;&#125;, user_id: &#123;&#125;, item_id: &#123;&#125;, y: &#123;&#125;, loss: &#123;&#125;&quot;</span>.<span class="built_in">format</span>(step, user_id, item_id, y, e))</span><br><span class="line">    <span class="keyword">return</span> e</span><br><span class="line">   </span><br><span class="line"><span class="string">&quot;&quot;&quot;</span></span><br><span class="line"><span class="string">使用随机梯度下降求解参数，同时使用L2正则化防止过拟合</span></span><br><span class="line"><span class="string">&quot;&quot;&quot;</span></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">_optimize</span>(<span class="params">self, user_id, item_id, e</span>):</span><br><span class="line">    gradient_p = -e * self.q.ix[item_id].values</span><br><span class="line">    l2_p = self.lam * self.p.ix[user_id].values</span><br><span class="line">    delta_p = self.lr * (gradient_p + l2_p)</span><br><span class="line">   </span><br><span class="line">    gradient_q = -e * self.p.ix[user_id].values</span><br><span class="line">    l2_q = self.lam * self.q.ix[item_id].values</span><br><span class="line">    delta_q = self.lr * (gradient_q + l2_q)</span><br><span class="line">   </span><br><span class="line">    self.p.loc[user_id] -= delta_p</span><br><span class="line">    self.q.loc[item_id] -= delta_q</span><br><span class="line">   </span><br><span class="line"><span class="comment">#训练模型</span></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">train</span>(<span class="params">self</span>):</span><br><span class="line">    <span class="keyword">for</span> step <span class="keyword">in</span> <span class="built_in">range</span>(<span class="number">0</span>, self.iter_count):</span><br><span class="line">        time.sleep(<span class="number">30</span>)</span><br><span class="line">        <span class="keyword">for</span> user_id, item_dict <span class="keyword">in</span> self.items_dict.items():</span><br><span class="line">            <span class="built_in">print</span>(<span class="string">&quot;Step: &#123;&#125;, user_id: &#123;&#125;&quot;</span>.<span class="built_in">format</span>(step, user_id))</span><br><span class="line">            item_ids = <span class="built_in">list</span>(item_dict.keys())</span><br><span class="line">            random.shuffle(item_ids)</span><br><span class="line">            <span class="keyword">for</span> item_id <span class="keyword">in</span> item_ids:</span><br><span class="line">                e = self._loss(user_id, item_id, item_dict[item_id], step)</span><br><span class="line">                self._optimize(user_id, item_id, e)</span><br><span class="line">        self.lr *= <span class="number">0.9</span></span><br><span class="line">    self.save()</span><br><span class="line">   </span><br><span class="line"><span class="comment">#保存模型</span></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">save</span>(<span class="params">self</span>):</span><br><span class="line">    f = <span class="built_in">open</span>(lfm_model_dir, <span class="string">&quot;wb&quot;</span>)</span><br><span class="line">    pickle.dump((self.p, self.q), f)</span><br><span class="line">    f.close()</span><br><span class="line">   </span><br><span class="line"><span class="comment">#加载模型</span></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">load</span>(<span class="params">self</span>):</span><br><span class="line">    f = <span class="built_in">open</span>(lfm_model_dir, <span class="string">&#x27;rb&#x27;</span>)</span><br><span class="line">    self.p, self.q = pickle.load(f)</span><br><span class="line">    f.close()</span><br></pre></td></tr></table></figure></li>
<li><p>预测单用户</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">#计算用户未评分过的电影，并取top N返回给用户</span></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">predict</span>(<span class="params">self, user_id, top_N=<span class="number">10</span></span>):</span><br><span class="line">    self.load()</span><br><span class="line">    user_item_ids = <span class="built_in">set</span>(self.uiscores[self.uiscores[<span class="string">&quot;UserID&quot;</span>] == user_id][<span class="string">&quot;MovieID&quot;</span>])</span><br><span class="line">    other_item_ids = self.item_ids ^ user_item_ids</span><br><span class="line">    interest_list = [self._predict(user_id, item_id) <span class="keyword">for</span> item_id <span class="keyword">in</span> other_item_ids]</span><br><span class="line">    candidates = <span class="built_in">sorted</span>(<span class="built_in">zip</span>(<span class="built_in">list</span>(other_item_ids), interest_list), key=<span class="keyword">lambda</span> x:x[<span class="number">1</span>], reverse=<span class="literal">True</span>)</span><br><span class="line">    <span class="keyword">return</span> candidates[:top_N]</span><br></pre></td></tr></table></figure></li>
<li><p>评估效果</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br></pre></td><td class="code"><pre><span class="line">   </span><br><span class="line">#效果评估</span><br><span class="line">def evaluate(self):</span><br><span class="line">    self.load()</span><br><span class="line">    users = random.sample(self.user_ids, 10)</span><br><span class="line">    user_dict = &#123;&#125;</span><br><span class="line">    for user in users:</span><br><span class="line">        user_item_ids = set(self.uiscores[self.uiscores[&quot;UserID&quot;] == user][&quot;MovieID&quot;])</span><br><span class="line">        _sum = 0.0</span><br><span class="line">        for item_id in user_item_ids:</span><br><span class="line">            p = np.mat(self.p.loc[user].values)</span><br><span class="line">            q = np.mat(self.q.loc[item_id].values).T</span><br><span class="line">            _r = (p * q).sum()</span><br><span class="line">            r = self.uiscores[(self.uiscores[&#x27;UserID&#x27;] == user) &amp; (self.uiscores[&quot;MovieID&quot;]==item_id)][&quot;Rating&quot;].values[0]</span><br><span class="line">            _sum += abs(r - _r)</span><br><span class="line">        user_dict[user] = _sum / len(user_item_ids)</span><br><span class="line">        print(&quot;UserID: &#123;&#125;, AE: &#123;&#125;&quot;.format(user, user_dict[user]))</span><br><span class="line">   </span><br><span class="line">    return sum(user_dict.values()) / len(user_dict.keys())</span><br></pre></td></tr></table></figure></li>
</ol>
<h4 id="基于标签的推荐"><a href="#基于标签的推荐" class="headerlink" title="基于标签的推荐"></a>基于标签的推荐</h4><p>推荐系统的目的是==联系用户和物品==。</p>
<h5 id="数据标注与关键词提取"><a href="#数据标注与关键词提取" class="headerlink" title="数据标注与关键词提取"></a>数据标注与关键词提取</h5><p>数据标注就是利用人工或AI技术对数据进行标注。</p>
<p>标注的类型有：</p>
<ul>
<li>分类标注：即打标签，常用在图像和文本中。一般是从既定的标签中选择数据对应的标签，得到的结果是一个封闭的集合。</li>
<li>框框标注：常用在图像识别中，如在图片中框出所有的车辆。</li>
<li>区域标注：常用在自动驾驶中，</li>
<li>其他标注：除上述之外，还有其他的个性化需求。如自动摘要、用户或商品的标签。</li>
</ul>
<p>数据标注的一般步骤：</p>
<p>（1）确定标注标准：设置标注样例和模板。对于模棱两可的数据，制定统一的处理方式。</p>
<p>（2）确定标注形式：标注形式一般由算法人员确定。例如，垃圾问题识别，垃圾问题标注为1，正常问题标注为0</p>
<p>（3）确定标注方法：可以使用人工标注，也可以针对不同的标注类型采用相应的工具进行标注。</p>
<p>数据标注在推荐系统中的应用：</p>
<p>包括==数据前期的过滤==和==使用过程中的特征表示==。</p>
<p>推荐系统的主体是用户和事物。在电商网站中，会遇到刷单、恶意评价的用户。那么在采集训练模型所用数据时，应该过滤该部分数据集。过滤的有效办法就是进行身份标注。具体做法为：</p>
<p>（1）从海量用户中过滤得到可以用户，即去除掉那些明显无可疑行为的用户。</p>
<p>（2）准备判别是否是“垃圾”用户的特征因素，如注册时间、活跃天数、下单次数等</p>
<p>（3）进行人工判断，并标注是否为垃圾用户</p>
<p>（4）积累数据，生成训练数据，使用算法对用户身份进行标注</p>
<p>关键词就是能够反映文本语料主题的词语或短语。</p>
<p>关键词提取在推荐系统中的应用：</p>
<p>关键词在推荐系统中主要用于==用户物品召回（根据用户对关键词的行为偏好，召回相应关键词下的物品）==和==特征属性构造（对物品的属性进行补充）==。</p>
<p>在推荐系统中，不管是==数据标注==还是==关键词提取==，其目的都是==得到用户或物品的标签==。</p>
<p>对于社会化标签在标示项目方面的功能，Golder和Huberman将其归纳为：</p>
<ul>
<li>标示对象的内容。此类标签一般为名词，如IBM，音乐，房产销售等</li>
<li>标示对象的类别。例如标示对象为文章，日志，书籍等</li>
<li>标示对象的创建者或所有者。例如博客文章的作者署名、论文作者的署名等</li>
<li>标示对象的品质和特征。例如有趣、幽默等</li>
<li>用户参考用到的标签。例如“myPhoto”，“myFavorite”等</li>
<li>分类提炼用的标签。用数字化标签对现有分类进一步细化，如一个人收藏的技术博客，按照难度等级分为1，2，3，4</li>
<li>用于任务组织的标签。如“to read”，“IT blog”</li>
</ul>
<h5 id="基于TF-IDF算法提取商品标题的关键词"><a href="#基于TF-IDF算法提取商品标题的关键词" class="headerlink" title="基于TF-IDF算法提取商品标题的关键词"></a>基于TF-IDF算法提取商品标题的关键词</h5><h6 id="TF-IDF算法介绍"><a href="#TF-IDF算法介绍" class="headerlink" title="TF-IDF算法介绍"></a><code>TF-IDF</code>算法介绍</h6><p><code>TF-IDF（Term Frequency-Inverse Document Frequency）</code>是一种用于==资讯检索==与==文本挖掘==的常用加权技术。</p>
<p><code>TF-IDF</code>算法的主要思想是：如果某个词或短语在一篇文章出现的频率<code>TF</code>高，并且在其他文章中很少出现，则认为此词或短语具有很好的类别区分能力，适合用来分类。</p>
<p><code>TF（Term Frequency）</code>表示词条 $t$ 在文档 $D_i$中出现的频率。计算公式为：<br>$$<br>TF_{t,D_i}=\frac{count(t)}{|D_i|}<br>$$<br>其中，$count(t)$ 表示词条 $t$ 出现的次数， $|D_i|$ 表示文档中所有词条的个数。</p>
<p><code>IDF（Inverse Document Frequency）</code>表示词条 $t$ 在整个语料库中的区分能力，计算公式为：<br>$$<br>IDF_t=lg\frac{N}{\sum_{i=1}^NI(t,D_i)}<br>$$<br>其中，$N$ 为所有的文档数，$I(t,D_i)$表示文档 $D_i$ 是否包含词条 $t$，若包含则为1，不包含则为0。</p>
<p>如果词条 $t$ 在所有文档中都没有出现，则上述公式分母为0，此时就需要对<code>IDF</code>做平滑处理。改善后的公式为：<br>$$<br>IDF_t=lg\frac{N}{1+\sum_{i=1}^NI(t,D_i)}<br>$$<br>最终词条 $t$ 在文档 $D_i$ 中的 $TF-IDF$ 值为：<br>$$<br>TF-IDF_{t,D_i}=TF_{t,D_i}×IDF_t<br>$$<br>从 $TF-IDF$ 的计算过程中可以看出：一个词条在文档中出现的频率越高，且新鲜度越低（即普遍度越低），则其对应的 $TF-IDF$ 值越高。</p>
<p>举例：</p>
<p>现在有一个资料库，包含了100篇（==N==）论文，其中涉及包含推荐系统（==t==）这个词条的有20篇，在第一篇论文（==$D_1$==）中共有200个技术词汇（==$D_i$==），其中推荐系统出现了15次（==$count(t)$==）。则，推荐系统这个词条在第一篇论文（==$D_1$==）中的$TF-IDF$ 值为：<br>$$<br>TF-IDF_{推荐系统}=TF_{推荐系统,D_1}×IDF_{推荐系统}=\frac{count(推荐系统)}{|D_i|}=\frac{15}{200}×lg\frac{100}{1+20}=0.051<br>$$</p>
<h6 id="提取关键词"><a href="#提取关键词" class="headerlink" title="提取关键词"></a>提取关键词</h6><ol>
<li><p>准备数据</p>
<p>使用商品和对应的短标题数据作为数据集。</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">5594	小米 红米6Pro 异形全面屏， 后置1200万双摄， 4000mAh超大电池</span><br><span class="line">5363	小米粿x20S刘海屏 全网通4G智能手机游戏6G运行128G 千元指纹人脸</span><br><span class="line">7901	Xiaomi/小米 小米6手机6骁龙835手机陶瓷尊享版米8全网通4G白蓝色</span><br><span class="line">7059	小米粿X9 -8全面屏6寸智能正品手机游戏6G运行128G 指纹人脸解锁</span><br><span class="line">7020	直降100元 官方正品一加6 OnePlus/一加 A6000 一加6手机一加6t 一加六 一加5 1+6限量全网通</span><br><span class="line">...</span><br></pre></td></tr></table></figure></li>
<li><p>对标题分词并去除停用词</p>
<p>使用<code>jieba</code>作为中文分词工具，并在对标题分词之后做去除停用词处理。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> jieba</span><br><span class="line"><span class="keyword">import</span> math</span><br><span class="line"><span class="keyword">import</span> jieba.analyse</span><br><span class="line"></span><br><span class="line"><span class="keyword">class</span> <span class="title class_">TF_IDF</span>:</span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__init__</span>(<span class="params">self, file, stop_file</span>):</span><br><span class="line">        self.file = file</span><br><span class="line">        self.stop_file = stop_file</span><br><span class="line">        self.stop_words = self.getStopWords()</span><br><span class="line"></span><br><span class="line">    <span class="comment">#获取停用词列表</span></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">getStopWords</span>(<span class="params">self</span>):</span><br><span class="line">        swlist = <span class="built_in">list</span>()</span><br><span class="line">        <span class="keyword">for</span> line <span class="keyword">in</span> <span class="built_in">open</span>(self.stop_file, <span class="string">&quot;r&quot;</span>, encoding=<span class="string">&quot;utf-8&quot;</span>).readlines():</span><br><span class="line">            swlist.append(line.strip())</span><br><span class="line">        <span class="built_in">print</span>(<span class="string">&quot;加载停用词完成...&quot;</span>)</span><br><span class="line">        <span class="keyword">return</span> swlist</span><br><span class="line"></span><br><span class="line">    <span class="comment"># 加载商品和其对应的短标题，使用jieba进行分词并去除停留词</span></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">loadData</span>(<span class="params">self</span>):</span><br><span class="line">        dMap = <span class="built_in">dict</span>()</span><br><span class="line">        <span class="keyword">for</span> line <span class="keyword">in</span> <span class="built_in">open</span>(self.file, <span class="string">&quot;r&quot;</span>, encoding=<span class="string">&quot;utf-8&quot;</span>).readlines():</span><br><span class="line">            <span class="built_in">id</span>, title = line.strip().split(<span class="string">&quot;\t&quot;</span>)</span><br><span class="line">            dMap.setdefault(<span class="built_in">id</span>, [])</span><br><span class="line">            <span class="keyword">for</span> word <span class="keyword">in</span> <span class="built_in">list</span>(jieba.cut(<span class="built_in">str</span>(title).replace(<span class="string">&quot; &quot;</span>, <span class="string">&quot;&quot;</span>),cut_all=<span class="literal">False</span>)):<span class="comment">#消除空格</span></span><br><span class="line">                <span class="keyword">if</span> word <span class="keyword">not</span> <span class="keyword">in</span> self.stop_words:</span><br><span class="line">                    dMap[<span class="built_in">id</span>].append(word)</span><br><span class="line">        <span class="built_in">print</span>(<span class="string">&quot;加载商品和对应的短标题，并使用jieba分词和去除停留词完成...&quot;</span>)</span><br><span class="line">        <span class="keyword">return</span> dMap</span><br><span class="line"></span><br><span class="line"><span class="keyword">if</span> __name__ == <span class="string">&quot;__main__&quot;</span>:</span><br><span class="line">    file = <span class="string">r&quot;C:\Users\OAOA\Desktop\数据-002\数据\data\phone-title\id_title.txt&quot;</span></span><br><span class="line">    stop_file = <span class="string">r&quot;C:\Users\OAOA\Desktop\数据-002\数据\data\phone-title\stop_words.txt&quot;</span></span><br><span class="line">    tf = TF_IDF(file, stop_file)</span><br><span class="line">    dMap = tf.loadData()</span><br><span class="line">    <span class="built_in">print</span>(dMap)</span><br><span class="line"></span><br></pre></td></tr></table></figure>

<p>输出结果：</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">&#123;<span class="string">&#x27;5594&#x27;</span>: [<span class="string">&#x27;小米&#x27;</span>, <span class="string">&#x27;红米&#x27;</span>, <span class="string">&#x27;6Pro&#x27;</span>, <span class="string">&#x27;异形&#x27;</span>, <span class="string">&#x27;屏&#x27;</span>, <span class="string">&#x27;后置&#x27;</span>, <span class="string">&#x27;1200&#x27;</span>, <span class="string">&#x27;万双&#x27;</span>, <span class="string">&#x27;摄&#x27;</span>, <span class="string">&#x27;4000mAh&#x27;</span>, <span class="string">&#x27;超大&#x27;</span>, <span class="string">&#x27;电池&#x27;</span>], <span class="string">&#x27;5363&#x27;</span>:...</span><br></pre></td></tr></table></figure></li>
<li><p>计算<code>TF-IDF</code>值</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br></pre></td><td class="code"><pre><span class="line">   </span><br><span class="line"><span class="comment">#获取一个短标题中的词频</span></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">getFreqWord</span>(<span class="params">self, words</span>):</span><br><span class="line">    freqWord = <span class="built_in">dict</span>()</span><br><span class="line">    <span class="keyword">for</span> word <span class="keyword">in</span> words:</span><br><span class="line">        freqWord.setdefault(word, <span class="number">0</span>)</span><br><span class="line">        freqWord[word] += <span class="number">1</span></span><br><span class="line">    <span class="keyword">return</span> freqWord</span><br><span class="line">   </span><br><span class="line"><span class="comment">#统计单词在所有短标题中出现的次数</span></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">getCountWordInFile</span>(<span class="params">self, word, dMap</span>):</span><br><span class="line">    count = <span class="number">0</span></span><br><span class="line">    <span class="keyword">for</span> key <span class="keyword">in</span> dMap.keys():</span><br><span class="line">        <span class="keyword">if</span> word <span class="keyword">in</span> dMap[key]:</span><br><span class="line">            count += <span class="number">1</span></span><br><span class="line">    <span class="keyword">return</span> count</span><br><span class="line">   </span><br><span class="line"><span class="comment">#计算TFIDF值</span></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">getIFIDF</span>(<span class="params">self, words, dMap</span>):</span><br><span class="line">    outDic = <span class="built_in">dict</span>()</span><br><span class="line">    freqWord = self.getFreqWord(words)</span><br><span class="line">    <span class="keyword">for</span> word <span class="keyword">in</span> words:</span><br><span class="line">        tf = freqWord[word] * <span class="number">1.0</span> / <span class="built_in">len</span>(words)</span><br><span class="line">        idf = math.log(<span class="built_in">len</span>(dMap) / (self.getCountWordInFile(word, dMap) + <span class="number">1</span>))</span><br><span class="line">        tfidf = tf * idf</span><br><span class="line">        outDic[word] = tfidf</span><br><span class="line">    orderDic = <span class="built_in">sorted</span>(outDic.items(), key=<span class="keyword">lambda</span> k:k[<span class="number">1</span>], reverse=<span class="literal">True</span>)</span><br><span class="line">    <span class="keyword">return</span> orderDic</span><br></pre></td></tr></table></figure>

<p>输出结果：</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">5594 [(<span class="string">&#x27;6Pro&#x27;</span>, 0.30740662117616135), (<span class="string">&#x27;异形&#x27;</span>, 0.30740662117616135), (<span class="string">&#x27;1200&#x27;</span>, 0.30740662117616135), (<span class="string">&#x27;万双&#x27;</span>, 0.30740662117616135), (<span class="string">&#x27;摄&#x27;</span>, 0.30740662117616135), (<span class="string">&#x27;4000mAh&#x27;</span>, 0.30740662117616135), (<span class="string">&#x27;后置&#x27;</span>, 0.2736178621671477), (<span class="string">&#x27;电池&#x27;</span>, 0.2736178621671477), (<span class="string">&#x27;超大&#x27;</span>, 0.24964435612949923), (<span class="string">&#x27;红米&#x27;</span>, 0.15809333207382342), (<span class="string">&#x27;小米&#x27;</span>, 0.10758201510963047), (<span class="string">&#x27;屏&#x27;</span>, 0.10758201510963047)]</span><br><span class="line">5363 [(<span class="string">&#x27;x20S&#x27;</span>, 0.24592529694092907), (<span class="string">&#x27;刘海&#x27;</span>, 0.24592529694092907), (<span class="string">&#x27;粿&#x27;</span>, 0.21889428973371813), (<span class="string">&#x27;手机游戏&#x27;</span>, 0.21889428973371813), (<span class="string">&#x27;屏全&#x27;</span>, 0.1997154849035994), (<span class="string">&#x27;千元&#x27;</span>, 0.1997154849035994), (<span class="string">&#x27;人脸&#x27;</span>, 0.1997154849035994), (<span class="string">&#x27;运行&#x27;</span>, 0.18483924814931874), (<span class="string">&#x27;指纹&#x27;</span>, 0.18483924814931874), (<span class="string">&#x27;6G&#x27;</span>, 0.17268447769638845), (<span class="string">&#x27;128G&#x27;</span>, 0.16240776570790455), (<span class="string">&#x27;智能&#x27;</span>, 0.0994436584518478), (<span class="string">&#x27;小米&#x27;</span>, 0.08606561208770439), (<span class="string">&#x27;4G&#x27;</span>, 0.07241265124463683), (<span class="string">&#x27;网通&#x27;</span>, 0.05511190487896453)]</span><br><span class="line">7901 [(<span class="string">&#x27;陶瓷&#x27;</span>, 0.24592529694092907), (<span class="string">&#x27;尊享&#x27;</span>, 0.24592529694092907), (<span class="string">&#x27;版米&#x27;</span>, 0.24592529694092907), (<span class="string">&#x27;蓝色&#x27;</span>, 0.24592529694092907), (<span class="string">&#x27;835&#x27;</span>, 0.21889428973371813), (<span class="string">&#x27;骁龙&#x27;</span>, 0.1997154849035994), (<span class="string">&#x27;小米&#x27;</span>, 0.17213122417540877), (<span class="string">&#x27;\xa0&#x27;</span>, 0.16240776570790455), (<span class="string">&#x27;Xiaomi&#x27;</span>, 0.09583917703382941), (<span class="string">&#x27;4G&#x27;</span>, 0.07241265124463683), (<span class="string">&#x27;全&#x27;</span>, 0.06108604879161034), (<span class="string">&#x27;网通&#x27;</span>, 0.05511190487896453), (<span class="string">&#x27;手机&#x27;</span>, 0.03615370273340937)]</span><br><span class="line"></span><br></pre></td></tr></table></figure></li>
<li><p>生成关键词</p>
<p>虽然计算生成了短标题中所有词对应的<code>TF-IDF</code>值，但是具体分词后的关键词并不能直接作为标签使用。如<code>万双</code>，<code>摄</code>等。</p>
<p>可以通过<code>卡阈值</code>、<code>人工审核</code>、<code>专业品类词库过滤</code>等方法得到真正能代表该商品的标签。</p>
</li>
<li><p><code>jieba</code>分词中的关键词提取</p>
<p>在<code>jieba</code>分词中有带有能够实现<code>TF-IDF</code>算法的关键词提取。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> jieba.analyse</span><br><span class="line">wordd = <span class="string">&quot;小米 红米6Pro 异形全面屏， 后置1200万双摄， 4000mAh超大电池&quot;</span></span><br><span class="line"><span class="built_in">print</span>(jieba.analyse.extract_tags(wordd, topK=<span class="number">20</span>, withWeight=<span class="literal">True</span>))</span><br></pre></td></tr></table></figure>

<p>输出结果：</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">[(<span class="string">&#x27;万双&#x27;</span>, 1.1173854308636364), (<span class="string">&#x27;红米&#x27;</span>, 1.0867970457181817), (<span class="string">&#x27;6Pro&#x27;</span>, 1.0867970457181817), (<span class="string">&#x27;1200&#x27;</span>, 1.0867970457181817), (<span class="string">&#x27;4000mAh&#x27;</span>, 1.0867970457181817), (<span class="string">&#x27;后置&#x27;</span>, 0.8977569055672727), (<span class="string">&#x27;异形&#x27;</span>, 0.8930127461881819), (<span class="string">&#x27;超大&#x27;</span>, 0.8556401165672728), (<span class="string">&#x27;小米&#x27;</span>, 0.8331344730527271), (<span class="string">&#x27;电池&#x27;</span>, 0.68353287587), (<span class="string">&#x27;全面&#x27;</span>, 0.5112753205954546)]</span><br></pre></td></tr></table></figure></li>
</ol>
<h5 id="基于标签的推荐系统"><a href="#基于标签的推荐系统" class="headerlink" title="基于标签的推荐系统"></a>基于标签的推荐系统</h5><h6 id="标签评分算法"><a href="#标签评分算法" class="headerlink" title="标签评分算法"></a>标签评分算法</h6><p>用户对标签的认同度可以使用二元关系表示，如“喜欢”或“不喜欢”；也可以使用“连续数值”表示喜好程度。</p>
<p>但是，二元表示方法精度不够。</p>
<p>为了计算用户对标签的喜好程度，需要将用户对物品的评分传递给这个物品所拥有的标签，传递的分值为物品与标签的相关度。</p>
<ol>
<li><p>用户对标签的喜好程度</p>
<p>假设，用户 <code>u</code> 对艺术家 <code>A</code> 的评分为 <code>5</code>星， 对艺术家 <code>B</code> 的评分为 <code>3</code>星， 对艺术家 <code>C</code> 的评分为 <code>4</code>星。</p>
<p> 艺术家 <code>A</code> 与标签 <code>1、2、3</code>的相关度分别为：<code>0.6, 0.8, 0.4</code>；</p>
<p> 艺术家 <code>B</code> 与标签 <code>1、2、3</code>的相关度分别为：<code>0.3, 0.6, 0.9</code>；</p>
<p> 艺术家 <code>C</code> 与标签 <code>1、2、3</code>的相关度分别为：<code>0.5, 0.7, 0.6</code>。</p>
<p>对应的用户 <code>u</code> 对标签 <code>t</code> 的喜好程度计算公式为：<br>$$<br>rate(u,t)=\frac{\sum_{i\in I_u}{rate(u,i)\times rel(i,t)}}{\sum_{i\in I_u}rel(i,t)}<br>$$<br>其中，</p>
<ul>
<li>$rate(u,t)$​​ 表示用户 <code>u</code> 对标签 <code>t</code> 的喜好程度</li>
<li>$rate(u,i)$ 表示用户 <code>u</code> 对艺术家 <code>i</code> 的评分</li>
<li>$rel(i,t)$ 表示艺术家 <code>i</code> 对标签 <code>t</code> 的相关度</li>
</ul>
<p>因此，</p>
<p>用户 <code>u</code> 对标签 <code>1</code> 的喜好程度为：<br>$$<br>rate(u,1)=\frac{\sum_{i\in I_u}{rate(u,i)\times rel(i,1)}}{\sum_{i\in I_u}rel(i,1)}=\frac{5\times 0.6+3\times 0.3+4\times 0.5}{0.6+0.3+0.5}=1.4<br>$$<br>用户 <code>u</code> 对标签 <code>2</code> 的喜好程度为：<br>$$<br>rate(u,2)=\frac{\sum_{i\in I_u}{rate(u,i)\times rel(i,2)}}{\sum_{i\in I_u}rel(i,2)}=\frac{5\times 0.8+3\times 0.6+4\times 0.7}{0.8+0.6+0.7}=2.1<br>$$<br>用户 <code>u</code> 对标签 <code>3</code> 的喜好程度为：<br>$$<br>rate(u,3)=\frac{\sum_{i\in I_u}{rate(u,i)\times rel(i,3)}}{\sum_{i\in I_u}rel(i,3)}=\frac{5\times 0.4+3\times 0.9+4\times 0.6}{0.4+0.9+0.6}=1.9<br>$$</p>
</li>
<li><p>优化用户对标签的喜好程度</p>
<p>如果一个用户的评分较少，就会导致预测结果存在误差。例如：</p>
<ul>
<li>若用户 <code>u</code> 只对艺术家 <code>A</code> 有行为，那么用户 <code>u</code> 对标签 <code>1, 2, 3</code> 的喜好程度分别为： <code>5， 5， 5</code></li>
<li>若用户 <code>u</code> 只对艺术家 <code>B</code> 有行为，那么用户 <code>u</code> 对标签 <code>1, 2, 3</code> 的喜好程度分别为： <code>3， 3， 3</code></li>
</ul>
<p>因此为了减少评分行为较少时因此的预测误差，引入<code>平滑因子</code>，对应的计算公式为：<br>$$<br>rate(u,t)=\frac{\sum_{i\in I_u}{rate(u,i)\times rel(i,t)}+\bar r_u\times k}{\sum_{i\in I_u}rel(i,t)+k}<br>$$<br>其中，$k$ 是平滑因子，$\bar r_u$ 为用户 <code>u</code> 的所有评分的平均值。</p>
<p>因此，</p>
<p>用户 <code>u</code> 对标签 <code>1</code> 的喜好程度为：<br>$$<br>rate(u,1)=\frac{5\times 0.6+3\times 0.3+4\times 0.5+\frac13\sum(5+3+4)\times 1}{0.6+0.3+0.5+1}=4.125<br>$$<br>用户 <code>u</code> 对标签 <code>2</code> 的喜好程度为：<br>$$<br>rate(u,2)=\frac{5\times 0.8+3\times 0.6+4\times0.5+\frac13\sum(5+3+4)\times 1}{0.8+0.6+0.7+1}\approx3.81<br>$$<br>用户 <code>u</code> 对标签 <code>3</code> 的喜好程度为：<br>$$<br>rate(u,3)=\frac{5\times 0.4+3\times 0.9+4\times 0.6+\frac13\sum(5+3+4)\times 1}{0.4+0.9+0.6+1}\approx3.83<br>$$</p>
</li>
</ol>
<h6 id="标签评分算法改进"><a href="#标签评分算法改进" class="headerlink" title="标签评分算法改进"></a>标签评分算法改进</h6><p>用户对标签的喜好程度，所传达的是用户主观意见，即从用户角度进行分析。但是一个标签被用户标记的次数越多，则说明用户对该标签的依赖程度越大。</p>
<ol>
<li><p>用户对标签的依赖程度</p>
<p>使用<code>TF-IDF</code> 算法来计算每个标签的权重，用该权重来表达用户对标签的依赖程度。<br>$$<br>TF(u,t)=\frac{n(u,t)}{\sum_{t_i\in T}n(u,t_i)}<br>$$</p>
<ul>
<li>$n(u,t_i)$ 表示用户 <code>u</code> 对标签 <code>t_i</code> 标记的次数</li>
<li>$\sum_{t_i\in T}n(u,t_i)$ 表示用户 <code>u</code> 使用所有标签标记的次数和</li>
<li>$TF(u,t)$ 表示用户 <code>u</code> 对标签 <code>t</code> 的依赖程度，也是用户 <code>u</code> 使用标签 <code>t</code> 的频率</li>
</ul>
</li>
<li><p>优化用户对标签的依赖程度</p>
<p>为了抑制“强者愈强，弱者愈弱”的现象，更好地体现用户的个性化，使用 <code>逆向文件频率（IDF）</code>来对那些热门标签进行惩罚。</p>
<p>每个用户标记的标签对应的 <code>IDF</code> 值的计算公式为：<br>$$<br>IDF(u,t)=\lg\frac{\sum_{u_i\in U}\sum_{t_j\in T}n(u_i,t_j)}{\sum_{u_i\in U}n(u_i,t)+1}<br>$$<br> 其中，</p>
<ul>
<li>$\sum_{u_i\in U}\sum_{t_j\in T}n(u_i,t_j)$ 表示所有用户对所有标签的标记计数和</li>
<li>$\sum_{u_i\in U}n(u_i,t)+1$ 表示所有用户对标签 <code>t</code> 的标记计数和</li>
<li>$IDF(u,t)$ 表示标签 <code>t</code> 的热门程度，即一个标签被不同用户使用的概率</li>
</ul>
<p>对于一个标签而言，如果使用过它的用户数量很少，但某个用户经常使用它，说明这个用户与标签的关系很紧密。</p>
</li>
<li><p>用户对标签的兴趣度</p>
<p>用户 <code>u</code> 对标签 <code>t</code> 的依赖度为：<br>$$<br>TF-IDF(u,t)=TF(u,t)\times IDF(u,t)=\frac{n(u,t)}{\sum_{t_i\in T}n(u,t_i)}\times \lg\frac{\sum_{u_i\in U}\sum_{t_j\in T}n(u_i,t_j)}{\sum_{u_i\in U}n(u_i,t)+1}<br>$$<br>用户 <code>u</code> 对标签 <code>t</code> 的兴趣度为：<br>$$<br>Pre(u,t)=rate(u,t)\times TF_IDF(u,t)<br>$$</p>
</li>
</ol>
<h6 id="标签基因"><a href="#标签基因" class="headerlink" title="标签基因"></a>标签基因</h6><p>标签基因是 <code>GroupLens</code> 研究组的一个项目。</p>
<p>在社会化标签系统中，每个物品都可以被看作与其相关的标签的集合， $rel(i,t)$ 以从0（完全不相关）到1（完全正相关）的连续值衡量一个标签与一个物品的符合程度。</p>
<p>如：</p>
<ul>
<li>$rel(艺术家A，标签1)=0.6$</li>
<li>$rel(艺术家A，标签2)=0.8$</li>
<li>$rel(艺术家A，标签3)=0.4$</li>
</ul>
<p>采用标签基因可以为每个艺术家 <code>i</code> 计算一个标签向量 $rel(i)$，其元素是 <code>i</code> 与 <code>T</code> 中所有标签的相关度。 这里， $rel(i)$ 相当于以标签为基因描绘出了不同物品的基因图谱。形式化的表达为：<br>$$<br>rel(i)=[rel(i,t_1),rel(i,t_2),rel(i,t_3),\dots,rel(i,t_p)],\forall t_k\in T<br>$$<br>因此，艺术家 <code>A</code> 的标签基因为：$rel(\text{艺术家A})=[0.6,0.8,0.4]$</p>
<p>选用标签基因来表示标签与物品的关系有以下三个原因：</p>
<ol>
<li>提供了从0到1的连续数值</li>
<li>关系矩阵是稠密的，它定义了每个标签 $t\in T$ 与每个物品 $i\in I$ 的相关度</li>
<li>基于真实数据构建的</li>
</ol>
<h6 id="用户兴趣建模"><a href="#用户兴趣建模" class="headerlink" title="用户兴趣建模"></a>用户兴趣建模</h6><p>根据训练数据，可以构建所有商品的标签基因矩阵 $T_i$ 和用户最终对标签的兴趣度 $T_u$，则用户对商品的可能的喜好程度为：<br>$$<br>T(u,i)=T_u\times T_i^T<br>$$<br>其中，</p>
<ul>
<li>$T_u$：用户 <code>u</code> 对所有标签的兴趣度矩阵（1行 m列，m为标签的个数）</li>
<li>$T_i^T$：所有商品的标签基因矩阵 $T_i$ 的转置矩阵（m行m列，m为标签个数，n为商品个数）</li>
<li>$T(u,i)$：用户 <code>u</code> 对所有商品的喜好程度矩阵（1行n列，n为商品个数）</li>
</ul>
<p>最终从计算结果中选取前K个推荐给用户。</p>
<h5 id="利用标签推荐算法实现艺术家的推荐"><a href="#利用标签推荐算法实现艺术家的推荐" class="headerlink" title="利用标签推荐算法实现艺术家的推荐"></a>利用标签推荐算法实现艺术家的推荐</h5><p>使用<code>Last.fm</code>数据集作为基础数据，根据用户已经标记过的标签进行标签兴趣建模，进而为用户推荐喜好标签下最相关的艺术家。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br><span class="line">101</span><br><span class="line">102</span><br><span class="line">103</span><br><span class="line">104</span><br><span class="line">105</span><br><span class="line">106</span><br><span class="line">107</span><br><span class="line">108</span><br><span class="line">109</span><br><span class="line">110</span><br><span class="line">111</span><br><span class="line">112</span><br><span class="line">113</span><br><span class="line">114</span><br><span class="line">115</span><br><span class="line">116</span><br><span class="line">117</span><br><span class="line">118</span><br><span class="line">119</span><br><span class="line">120</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> os</span><br><span class="line"><span class="keyword">import</span> pandas <span class="keyword">as</span> pd</span><br><span class="line"><span class="keyword">import</span> math</span><br><span class="line">base_dir = <span class="string">&quot;C:\\Users\\OAOA\\Desktop\\GXX的科研\\python\\FirstRec\\Last.fm&quot;</span></span><br><span class="line"></span><br><span class="line">user_artists_dir = os.path.join(base_dir, <span class="string">&quot;user_artists.dat&quot;</span>)</span><br><span class="line">user_taggedartists_dir = os.path.join(base_dir, <span class="string">&quot;user_taggedartists.dat&quot;</span>)</span><br><span class="line">artists_dir = os.path.join(base_dir, <span class="string">&quot;artists.dat&quot;</span>)</span><br><span class="line"></span><br><span class="line"><span class="keyword">class</span> <span class="title class_">RecBasedTag</span>:</span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__init__</span>(<span class="params">self</span>):</span><br><span class="line">        self.user_rate_file = user_artists_dir</span><br><span class="line">        self.user_tag_file = user_taggedartists_dir</span><br><span class="line">        self.artistsAll = <span class="built_in">list</span>(pd.read_table(artists_dir,delimiter=<span class="string">&quot;\t&quot;</span>)[<span class="string">&quot;id&quot;</span>].values)</span><br><span class="line">        self.userRateDict = self.getUserRate()</span><br><span class="line">        self.artistsTagsDict = self.getArtistsTags()</span><br><span class="line">        self.userTagDict, self.tagUserDict = self.getUserTagNum()</span><br><span class="line">        self.userTagPre = self.getUserTagPre()</span><br><span class="line"></span><br><span class="line">    <span class="comment"># 获取用户对艺术家的评分新消息</span></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">getUserRate</span>(<span class="params">self</span>):</span><br><span class="line">        userRateDict = <span class="built_in">dict</span>()</span><br><span class="line">        fr = <span class="built_in">open</span>(self.user_rate_file, <span class="string">&quot;r&quot;</span>, encoding=<span class="string">&quot;utf-8&quot;</span>)</span><br><span class="line">        <span class="keyword">for</span> line <span class="keyword">in</span> fr.readlines():</span><br><span class="line">            <span class="keyword">if</span> <span class="keyword">not</span> line.startswith(<span class="string">&quot;userID&quot;</span>):</span><br><span class="line">                userID, artistID, weight = line.split(<span class="string">&quot;\t&quot;</span>)</span><br><span class="line">                userRateDict.setdefault(<span class="built_in">int</span>(userID), &#123;&#125;)</span><br><span class="line">                userRateDict[<span class="built_in">int</span>(userID)][<span class="built_in">int</span>(artistID)] = <span class="built_in">float</span>(weight) / <span class="number">10000</span></span><br><span class="line">        <span class="keyword">return</span> userRateDict</span><br><span class="line"></span><br><span class="line">    <span class="comment"># 获取每个用户打标的标签和每个标签被所有用户打标的次数</span></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">getUserTagNum</span>(<span class="params">self</span>):</span><br><span class="line">        userTagDict = <span class="built_in">dict</span>()</span><br><span class="line">        tagUserDict = <span class="built_in">dict</span>()</span><br><span class="line">        <span class="keyword">for</span> line <span class="keyword">in</span> <span class="built_in">open</span>(self.user_tag_file, <span class="string">&quot;r&quot;</span>, encoding=<span class="string">&quot;utf-8&quot;</span>):</span><br><span class="line">            <span class="keyword">if</span> <span class="keyword">not</span> line.startswith(<span class="string">&quot;userID&quot;</span>):</span><br><span class="line">                userID, artistID, tagID = line.strip().split(<span class="string">&quot;\t&quot;</span>)[:<span class="number">3</span>]</span><br><span class="line">                <span class="keyword">if</span> <span class="built_in">int</span>(tagID) <span class="keyword">in</span> tagUserDict.keys():</span><br><span class="line">                    tagUserDict[<span class="built_in">int</span>(tagID)] += <span class="number">1</span></span><br><span class="line">                <span class="keyword">else</span>:</span><br><span class="line">                    tagUserDict[<span class="built_in">int</span>(tagID)] = <span class="number">1</span></span><br><span class="line">                userTagDict.setdefault(<span class="built_in">int</span>(userID),&#123;&#125;)</span><br><span class="line">                <span class="keyword">if</span> <span class="built_in">int</span>(tagID) <span class="keyword">in</span> userTagDict[<span class="built_in">int</span>(userID)].keys():</span><br><span class="line">                    userTagDict[<span class="built_in">int</span>(userID)][<span class="built_in">int</span>(tagID)] += <span class="number">1</span></span><br><span class="line">                <span class="keyword">else</span>:</span><br><span class="line">                    userTagDict[<span class="built_in">int</span>(userID)][<span class="built_in">int</span>(tagID)] = <span class="number">1</span></span><br><span class="line">        <span class="keyword">return</span> userTagDict, tagUserDict</span><br><span class="line"></span><br><span class="line">    <span class="comment"># 获取艺术家对应的标签基因</span></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">getArtistsTags</span>(<span class="params">self</span>):</span><br><span class="line">        artistsTagsDict = <span class="built_in">dict</span>()</span><br><span class="line">        <span class="keyword">for</span> line <span class="keyword">in</span> <span class="built_in">open</span>(self.user_tag_file, <span class="string">&quot;r&quot;</span>, encoding=<span class="string">&quot;utf-8&quot;</span>):</span><br><span class="line">            <span class="keyword">if</span> <span class="keyword">not</span> line.startswith(<span class="string">&quot;userID&quot;</span>):</span><br><span class="line">                artistID, tagID = line.split(<span class="string">&quot;\t&quot;</span>)[<span class="number">1</span>:<span class="number">3</span>]</span><br><span class="line">                artistsTagsDict.setdefault(<span class="built_in">int</span>(artistID), &#123;&#125;)</span><br><span class="line">                artistsTagsDict[<span class="built_in">int</span>(artistID)][<span class="built_in">int</span>(tagID)] = <span class="number">1</span></span><br><span class="line">        <span class="keyword">return</span> artistsTagsDict</span><br><span class="line"></span><br><span class="line">    <span class="comment"># 获取用户对标签的最终兴趣度</span></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">getUserTagPre</span>(<span class="params">self</span>):</span><br><span class="line">        userTagPre = <span class="built_in">dict</span>()</span><br><span class="line">        userTagCount = <span class="built_in">dict</span>()</span><br><span class="line">        Num = <span class="built_in">len</span>(<span class="built_in">open</span>(self.user_tag_file, <span class="string">&quot;r&quot;</span>, encoding=<span class="string">&quot;utf-8&quot;</span>).readlines())</span><br><span class="line">        <span class="keyword">for</span> line <span class="keyword">in</span> <span class="built_in">open</span>(self.user_tag_file, <span class="string">&quot;r&quot;</span>, encoding=<span class="string">&quot;utf-8&quot;</span>).readlines():</span><br><span class="line">            <span class="keyword">if</span> <span class="keyword">not</span> line.startswith(<span class="string">&quot;userID&quot;</span>):</span><br><span class="line">                userID, artistID, tagID = line.split(<span class="string">&quot;\t&quot;</span>)[:<span class="number">3</span>]</span><br><span class="line">                userTagPre.setdefault(<span class="built_in">int</span>(userID), &#123;&#125;)</span><br><span class="line">                userTagCount.setdefault(<span class="built_in">int</span>(userID), &#123;&#125;)</span><br><span class="line">                rate_ui = (</span><br><span class="line">                    self.userRateDict[<span class="built_in">int</span>(userID)][<span class="built_in">int</span>(artistID)] <span class="keyword">if</span> <span class="built_in">int</span>(artistID) <span class="keyword">in</span> self.userRateDict[<span class="built_in">int</span>(userID)].keys() <span class="keyword">else</span> <span class="number">0</span></span><br><span class="line">                )</span><br><span class="line">                <span class="keyword">if</span> <span class="built_in">int</span>(tagID) <span class="keyword">not</span> <span class="keyword">in</span> userTagPre[<span class="built_in">int</span>(userID)].keys():</span><br><span class="line">                    userTagPre[<span class="built_in">int</span>(userID)][<span class="built_in">int</span>(tagID)] = (rate_ui * self.artistsTagsDict[<span class="built_in">int</span>(artistID)][<span class="built_in">int</span>(tagID)])</span><br><span class="line">                    userTagCount[<span class="built_in">int</span>(userID)][<span class="built_in">int</span>(tagID)] = <span class="number">1</span></span><br><span class="line">                <span class="keyword">else</span>:</span><br><span class="line">                    userTagPre[<span class="built_in">int</span>(userID)][<span class="built_in">int</span>(tagID)] += (rate_ui * self.artistsTagsDict[<span class="built_in">int</span>(artistID)][<span class="built_in">int</span>(tagID)])</span><br><span class="line">                    userTagCount[<span class="built_in">int</span>(userID)][<span class="built_in">int</span>(tagID)] += <span class="number">1</span></span><br><span class="line">        <span class="keyword">for</span> userID <span class="keyword">in</span> userTagPre.keys():</span><br><span class="line">            <span class="keyword">for</span> tagID <span class="keyword">in</span> userTagPre[userID].keys():</span><br><span class="line">                tf_ut = self.userTagDict[<span class="built_in">int</span>(userID)][<span class="built_in">int</span>(tagID)] / <span class="built_in">sum</span>(self.userTagDict[<span class="built_in">int</span>(userID)].values())</span><br><span class="line">                idf_ut = math.log(Num * <span class="number">1.0</span> / (self.tagUserDict[<span class="built_in">int</span>(tagID)] + <span class="number">1</span>))</span><br><span class="line">                userTagPre[userID][tagID] = (userTagPre[userID][tagID] / userTagCount[userID][tagID] * tf_ut * idf_ut)</span><br><span class="line"></span><br><span class="line">        <span class="keyword">return</span> userTagPre</span><br><span class="line"></span><br><span class="line">    <span class="comment"># 为用户进行艺术家推荐</span></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">recommendForUser</span>(<span class="params">self, user, K, flag=<span class="literal">True</span></span>):</span><br><span class="line">        userArtistPreDict = <span class="built_in">dict</span>()</span><br><span class="line">        <span class="keyword">for</span> artist <span class="keyword">in</span> self.artistsAll:</span><br><span class="line">            <span class="keyword">if</span> <span class="built_in">int</span>(artist) <span class="keyword">in</span> self.artistsTagsDict.keys():</span><br><span class="line">                <span class="keyword">for</span> tag <span class="keyword">in</span> self.userTagPre[<span class="built_in">int</span>(user)].keys():</span><br><span class="line">                    rate_ut = self.userTagPre[<span class="built_in">int</span>(user)][<span class="built_in">int</span>(tag)]</span><br><span class="line">                    rel_it = (<span class="number">0</span> <span class="keyword">if</span> tag <span class="keyword">not</span> <span class="keyword">in</span> self.artistsTagsDict[<span class="built_in">int</span>(artist)].keys() <span class="keyword">else</span> self.artistsTagsDict[<span class="built_in">int</span>(artist)][tag])</span><br><span class="line">                    <span class="keyword">if</span> artist <span class="keyword">in</span> userArtistPreDict.keys():</span><br><span class="line">                        userArtistPreDict[<span class="built_in">int</span>(artist)] += rate_ut * rel_it</span><br><span class="line">                    <span class="keyword">else</span>:</span><br><span class="line">                        userArtistPreDict[<span class="built_in">int</span>(artist)] = rate_ut * rel_it</span><br><span class="line">        newUserArtistPreDict = <span class="built_in">dict</span>()</span><br><span class="line">        <span class="keyword">if</span> flag:</span><br><span class="line">            <span class="comment">#过滤掉用户已经听过的推荐结果</span></span><br><span class="line">            <span class="keyword">for</span> artist <span class="keyword">in</span> userArtistPreDict.keys():</span><br><span class="line">                <span class="keyword">if</span> artist <span class="keyword">not</span> <span class="keyword">in</span> self.userRateDict[<span class="built_in">int</span>(user)].keys():</span><br><span class="line">                    newUserArtistPreDict[artist] = userArtistPreDict[<span class="built_in">int</span>(artist)]</span><br><span class="line">            <span class="keyword">return</span> <span class="built_in">sorted</span>(newUserArtistPreDict.items(), key=<span class="keyword">lambda</span> k: k[<span class="number">1</span>], reverse=<span class="literal">True</span>)[:K]</span><br><span class="line">        <span class="keyword">else</span>:</span><br><span class="line">            <span class="keyword">return</span> <span class="built_in">sorted</span>(userArtistPreDict.items(), key=<span class="keyword">lambda</span> k: k[<span class="number">1</span>], reverse=<span class="literal">True</span>)[:K]</span><br><span class="line"></span><br><span class="line">    <span class="comment">#评估效果</span></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">evaluate</span>(<span class="params">self, user</span>):</span><br><span class="line">        K = <span class="built_in">len</span>(self.userRateDict[<span class="built_in">int</span>(user)])</span><br><span class="line">        recResult = self.recommendForUser(user, K=K, flag=<span class="literal">False</span>)</span><br><span class="line">        count = <span class="number">0</span></span><br><span class="line">        <span class="keyword">for</span> (artist, pre) <span class="keyword">in</span> recResult:</span><br><span class="line">            <span class="keyword">if</span> artist <span class="keyword">in</span> self.userRateDict[<span class="built_in">int</span>(user)]:</span><br><span class="line">                count += <span class="number">1</span></span><br><span class="line">        <span class="keyword">return</span> count * <span class="number">1.0</span> / K</span><br><span class="line"><span class="keyword">if</span> __name__ == <span class="string">&quot;__main__&quot;</span>:</span><br><span class="line">    rbt = RecBasedTag()</span><br><span class="line">    <span class="built_in">print</span>(rbt.recommendForUser(<span class="string">&quot;2&quot;</span>, K=<span class="number">20</span>))</span><br><span class="line">    <span class="built_in">print</span>(rbt.evaluate(<span class="string">&quot;2&quot;</span>))</span><br></pre></td></tr></table></figure>

<p>输出结果：</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">[(5803, 0.9397784544070824), (6582, 0.9397784544070824), (18229, 0.9280932264044133), (18232, 0.9280932264044133), (1965, 0.9269016485847453), (15675, 0.9269016485847453), (1801, 0.9004958140614302), (1835, 0.9004958140614302), (2605, 0.9004958140614302), (2668, 0.9004958140614302), (4852, 0.9004958140614302), (4863, 0.9004958140614302), (3992, 0.8579588652986282), (8068, 0.8565790775053892), (748, 0.8460267445255922), (2673, 0.8460267445255922), (4316, 0.8460267445255922), (10522, 0.8460267445255922), (175, 0.8433451847266689), (10519, 0.8425740993544554)]</span><br><span class="line">0.22</span><br></pre></td></tr></table></figure>




      
    </div>
    <footer class="article-footer">
      <a data-url="http://example.com/2022/07/30/%E6%8E%A8%E8%8D%90%E7%B3%BB%E7%BB%9F%E5%AE%9E%E6%88%98/" data-id="cl690wfgt0002z4ttc875efh5" class="article-share-link">Share</a>
      
      
    </footer>
  </div>
  
    
<nav id="article-nav">
  
  
    <a href="/2022/07/30/Docker%E5%AD%A6%E4%B9%A0/" id="article-nav-older" class="article-nav-link-wrap">
      <strong class="article-nav-caption">Older</strong>
      <div class="article-nav-title">Docker学习</div>
    </a>
  
</nav>

  
</article>

</section>
        
          <aside id="sidebar">
  
    

  
    

  
    
  
    
  <div class="widget-wrap">
    <h3 class="widget-title">Archives</h3>
    <div class="widget">
      <ul class="archive-list"><li class="archive-list-item"><a class="archive-list-link" href="/archives/2022/07/">July 2022</a></li></ul>
    </div>
  </div>


  
    
  <div class="widget-wrap">
    <h3 class="widget-title">Recent Posts</h3>
    <div class="widget">
      <ul>
        
          <li>
            <a href="/2022/07/30/%E6%8E%A8%E8%8D%90%E7%B3%BB%E7%BB%9F%E5%AE%9E%E6%88%98/">推荐系统实战</a>
          </li>
        
          <li>
            <a href="/2022/07/30/Docker%E5%AD%A6%E4%B9%A0/">Docker学习</a>
          </li>
        
          <li>
            <a href="/2022/07/29/hello/">Hello World</a>
          </li>
        
      </ul>
    </div>
  </div>

  
</aside>
        
      </div>
      <footer id="footer">
  
  <div class="outer">
    <div id="footer-info" class="inner">
      &copy; 2022 John Doe<br>
      Powered by <a href="http://hexo.io/" target="_blank">Hexo</a>
    </div>
  </div>
</footer>
    </div>
    <nav id="mobile-nav">
  
    <a href="/" class="mobile-nav-link">Home</a>
  
    <a href="/archives" class="mobile-nav-link">Archives</a>
  
</nav>
    

<script src="//ajax.googleapis.com/ajax/libs/jquery/2.0.3/jquery.min.js"></script>


  
<link rel="stylesheet" href="/fancybox/jquery.fancybox.css">

  
<script src="/fancybox/jquery.fancybox.pack.js"></script>




<script src="/js/script.js"></script>




  </div>
</body>
</html>